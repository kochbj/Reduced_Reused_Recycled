{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5af1aaed-9b9a-4ea3-b52e-f2ea71345db1",
   "metadata": {},
   "source": [
    "# Dataset Construction: RQ1 and RQ2\n",
    "\n",
    "This notebook constructs the datasets used in the analyses for research questions 1 and 2. To see the actual statistical analyses, see the R scripts.\n",
    "\n",
    "First load the PWC provided data. \"evaluation-tables.json\" and \"papers-with-abstracts.json\" were downloaded from [PWC's Github](https://github.com/paperswithcode/paperswithcode-data) on 06/16/2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "096cd869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'DATASET_PATH'\n",
      "/mnt/c/Users/berna/Documents/GitHub/Life_of_a_Benchmark/Dataset_Curation\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH=\"/home/bkoch/Documents/GitHub/Life_of_a_Benchmark/Dataset_Curation\"\n",
    "%cd DATASET_PATH\n",
    "import pandas as pd\n",
    "import json\n",
    "with open('./PWC_Data/papers-with-abstracts.json') as f:\n",
    "    pwc=json.load(f)\n",
    "with open('./PWC_Data/evaluation-tables.json') as f:\n",
    "    benchmark_tables=json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dba6cb7-1125-481b-8205-a1178e8e9ea1",
   "metadata": {},
   "source": [
    "### Construct Task Ontology\n",
    "\n",
    "This block parses \"evaluation-tables.json\" to create a task ontology. Benchmarks in this file are organized by task and subtask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5118e98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rows=[] #used to construct benchmark_papers df\n",
    "parent_child_dict={} #dictionary capturing parent-child task relations used to create task_relations df\n",
    "child_parent_dict={} #inverse of above\n",
    "task_category_dict={} #captures task category relations: categories in PWC are larger domains like \"NLP\",\"CV\",\"Methodology\n",
    "paper_titles_tasks={} #paper titles to tasks\n",
    "paper_titles_parent_tasks={} #paper totiles to parent tasks\n",
    "dataset_associated_tasks={} # tasks associated with the dataset\n",
    "\n",
    "for i, task in enumerate(benchmark_tables):\n",
    "    task_dict={} # A dictionary for each task that will ultimately be a row in the benchmark_papers dataframe\n",
    "    task_dict['task']=task['task']\n",
    "    task_dict['task_categories']=task['categories']\n",
    "    task_dict['task_description']=task['description']\n",
    "    task_dict['parent_task']=task['task']\n",
    "    if task['task'] not in parent_child_dict: parent_child_dict[task['task']]=[]\n",
    "    if task['task'] not in child_parent_dict: child_parent_dict[task['task']]=[]\n",
    "    task_category_dict[task['task']]=task['categories']\n",
    "    if len(task['datasets'])!=0: #if there are datasets associated with task\n",
    "        for j,d in enumerate(task['datasets']):\n",
    "            if d['dataset'] not in dataset_associated_tasks:dataset_associated_tasks[d['dataset']]=[]\n",
    "            parent_dataset=d['dataset'] # variations of datasets can be listed as \"children\"\n",
    "            dataset_associated_tasks[d['dataset']].append(task['task'])\n",
    "            dataset_dict={}\n",
    "            dataset_dict.update(task_dict)\n",
    "            dataset_dict['dataset']=d['dataset']\n",
    "            dataset_dict['dataset_citations']=d['dataset_citations']\n",
    "            dataset_dict['dataset_links']=d['dataset_links']\n",
    "            dataset_dict['dataset_subdatasets']=d['subdatasets']\n",
    "            dataset_dict['task']=task['task']\n",
    "            for row in d['sota']['rows']:\n",
    "                for m in row['metrics']:\n",
    "                    row_dict=dict(row)\n",
    "                    row_dict['metrics']=m\n",
    "                    row_dict['score']=row['metrics'][m]\n",
    "                    row_dict.update(dataset_dict)\n",
    "                    all_rows.append(row_dict)\n",
    "                if row['paper_title'] not in paper_titles_tasks:paper_titles_tasks[row['paper_title']]=[]\n",
    "                if row['paper_title'] not in paper_titles_parent_tasks:paper_titles_parent_tasks[row['paper_title']]=[]\n",
    "                paper_titles_tasks[row['paper_title']]+=[task['task']]\n",
    "                paper_titles_parent_tasks[row['paper_title']]+=[task['task']]\n",
    "    if len(task['subtasks'])!=0: #tasks can have subtasks. This is not tree. A subtask could have multiple parents or be a parent itself.\n",
    "        for t in task['subtasks']:\n",
    "            task_dict={} #Each subtask is it's own row also\n",
    "            if t['task'] not in child_parent_dict: child_parent_dict[t['task']]=[]\n",
    "            if t['task'] not in parent_child_dict: parent_child_dict[t['task']]=[]\n",
    "            task_category_dict[t['task']]=t['categories']\n",
    "            parent_child_dict[task['task']].append(t['task'])\n",
    "            child_parent_dict[t['task']].append(task['task'])\n",
    "            \n",
    "            task_dict['parent_task']=task['task']\n",
    "            task_dict['task']=t['task']\n",
    "            task_dict['task_categories']=','.join(t['categories'])\n",
    "            task_dict['task_description']=t['description']\n",
    "            \n",
    "            if len(t['datasets'])!=0:\n",
    "                for d in t['datasets']:\n",
    "                    if d['dataset'] not in dataset_associated_tasks:dataset_associated_tasks[d['dataset']]=[]\n",
    "                    dataset_associated_tasks[d['dataset']].append(t['task'])\n",
    "                    dataset_associated_tasks[parent_dataset].append(t['task'])\n",
    "                    dataset_dict={}\n",
    "                    dataset_dict.update(task_dict)\n",
    "                    dataset_dict['dataset']=d['dataset']\n",
    "                    dataset_dict['dataset_citations']=d['dataset_citations']\n",
    "                    dataset_dict['dataset_links']=d['dataset_links']\n",
    "                    dataset_dict['dataset_subdatasets']=d['subdatasets']\n",
    "                    dataset_dict['task']=t['task']\n",
    "                    for row in d['sota']['rows']:\n",
    "                        for m in row['metrics']:\n",
    "                            row_dict=dict(row)\n",
    "                            row_dict['metrics']=m\n",
    "                            row_dict['score']=row['metrics'][m]\n",
    "                            row_dict.update(dataset_dict)\n",
    "                            all_rows.append(row_dict)\n",
    "                        if row['paper_title'] not in paper_titles_tasks:paper_titles_tasks[row['paper_title']]=[]\n",
    "                        paper_titles_tasks[row['paper_title']]+=[t['task']] \n",
    "                        if row['paper_title'] not in paper_titles_parent_tasks:paper_titles_parent_tasks[row['paper_title']]=[]\n",
    "                        paper_titles_parent_tasks[row['paper_title']]+=[task['task']] \n",
    "\n",
    "                        benchmark_papers=pd.DataFrame(all_rows)\n",
    "#This dataframe contains \n",
    "benchmark_papers['benchmark_id']=benchmark_papers.groupby(['task','dataset','metrics']).ngroup()\n",
    "benchmark_papers=benchmark_papers[['paper_title','paper_date','task','parent_task','dataset','score','benchmark_id','metrics','task_categories']]\n",
    "benchmark_papers=benchmark_papers.drop_duplicates(['paper_title','paper_date','task','parent_task','dataset','score','benchmark_id','metrics'])\n",
    "print(\"BP\",benchmark_papers.shape)\n",
    "\n",
    "sibling_dict={i:[] for i in child_parent_dict.keys()}\n",
    "for k in sibling_dict.keys():\n",
    "    parents=child_parent_dict[k]\n",
    "    for i in parents:\n",
    "        sibling_dict[k]+=parent_child_dict[i]\n",
    "    sibling_dict[k]=list(set(sibling_dict[k]))\n",
    "\n",
    "task_relations=pd.DataFrame({'categories':task_category_dict,'parents':child_parent_dict,'children':parent_child_dict,'siblings':sibling_dict})\n",
    "task_relations.index=task_relations.index.rename('task')\n",
    "task_relations=task_relations.reset_index()\n",
    "benchmark_papers['CV']=benchmark_papers.apply(lambda row: 'Computer Vision' in row['task_categories'] and len(row['task_categories'])==1,axis=1 )\n",
    "benchmark_papers['NLP']=benchmark_papers.apply(lambda row: 'Natural Language Processing' in row['task_categories'] and len(row['task_categories'])==1,axis=1 )\n",
    "paper_relations=pd.DataFrame({'all_tasks':paper_titles_tasks,'all_parent_tasks':paper_titles_parent_tasks})\n",
    "paper_relations.index=paper_relations.index.rename('title')\n",
    "paper_relations=paper_relations.reset_index()\n",
    "#print(flat_df['paper_title'].drop_duplicates().shape)\n",
    "task_relations.to_csv('task_relations.tsv',sep='\\t',quoting=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adbb0f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOT HERE\n",
      "GOT HERE\n",
      "GOT HERE\n",
      "GOT HERE\n",
      "GOT HERE\n",
      "TOTAL PWC PAPERS (137510,)\n"
     ]
    }
   ],
   "source": [
    "title=[]\n",
    "pdf_url=[]\n",
    "paper_url=[]\n",
    "date=[]\n",
    "task=[]\n",
    "all_tasks=[]\n",
    "all_parents=[]\n",
    "all_children=[]\n",
    "all_categories=[]\n",
    "all_siblings=[]\n",
    "task_hist={}\n",
    "task_age={}\n",
    "sheet_id = '1Y3DDI6ySi9A6l3ZMET29EWSxBr8Uw-kvKn8RF2zYpzQ'\n",
    "sheet_name = 'untasked_datasets'\n",
    "url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
    "manual_task_labels=pd.read_csv(url)\n",
    "manual_task_labels=manual_task_labels[~manual_task_labels.Justification.isnull()]\n",
    "#manual_task_labels=manual_task_labels[~manual_task_labels['Proposed Tasks'].isnull()]\n",
    "\n",
    "for i in pwc:\n",
    "    if i['title'] in list(manual_task_labels.title.str.strip()):\n",
    "        print(\"GOT HERE\")\n",
    "        proposed_tasks=manual_task_labels[manual_task_labels.title==i['title']]['Proposed Tasks'].iloc[0]\n",
    "        i['tasks']+=[j.strip() for j in proposed_tasks.split(',')]\n",
    "    if len(i['tasks'])==0: continue\n",
    "    ap=[]\n",
    "    [ ap.extend(child_parent_dict[t]) for t in i['tasks'] if t in child_parent_dict]\n",
    "    ac =[]\n",
    "    [ ac.extend(task_category_dict[t]) for t in i['tasks'] if t in task_category_dict]\n",
    "    ah=[]\n",
    "    [ ah.extend(parent_child_dict[t]) for t in i['tasks'] if t in parent_child_dict]\n",
    "    asib=[]\n",
    "    [ asib.extend(sibling_dict[t]) for t in i['tasks'] if t in sibling_dict]\n",
    "\n",
    "    for t in i['tasks']:\n",
    "        if t not in task_hist: task_hist[t]=0\n",
    "        task_hist[t]+=1\n",
    "        if t not in task_age: task_age[t] = pd.to_datetime(i['date']).year\n",
    "        else: task_age[t]= min(task_age[t],pd.to_datetime(i['date']).year)\n",
    "        title.append(i['title'])\n",
    "        pdf_url.append(i['url_pdf'])\n",
    "        paper_url.append(i['paper_url'])\n",
    "        date.append(i['date'])\n",
    "        task.append(t)\n",
    "        all_tasks.append(i['tasks'])\n",
    "        all_parents.append(list(set(ap)))\n",
    "        all_categories.append(list(set(ac)))\n",
    "        all_children.append(list(set(ah)))\n",
    "        all_siblings.append(list(set(asib)))\n",
    "\n",
    "for i,row in manual_task_labels.iterrows():\n",
    "    if row['title'] in title: continue\n",
    "    if type(row['Proposed Tasks'])==float:continue\n",
    "    tasks=[j.strip() for j in row['Proposed Tasks'].split(',')]\n",
    "    ap=[]\n",
    "    [ ap.extend(child_parent_dict[t]) for t in tasks if t in child_parent_dict]\n",
    "    ac =[]\n",
    "    [ ac.extend(task_category_dict[t]) for t in tasks if t in task_category_dict]\n",
    "    ah=[]\n",
    "    [ ah.extend(parent_child_dict[t]) for t in tasks if t in parent_child_dict]\n",
    "    asib=[]\n",
    "    [ asib.extend(sibling_dict[t]) for t in tasks if t in sibling_dict]\n",
    "    for t in tasks:\n",
    "        if t not in task_category_dict: print(\"TASK NOT FOUND\",t)\n",
    "\n",
    "        if t not in task_hist: task_hist[t]=0\n",
    "        task_hist[t]+=1\n",
    "        if t not in task_age: task_age[t] = pd.to_datetime(row['introduced_date']).year\n",
    "        else: task_age[t]= min(task_age[t],pd.to_datetime(row['introduced_date']).year)\n",
    "        title.append(row['title'])\n",
    "        pdf_url.append(None)\n",
    "        paper_url.append(row['paper_url'])\n",
    "        date.append(row['introduced_date'])\n",
    "        task.append(t)\n",
    "        all_tasks.append(tasks)\n",
    "        all_parents.append(list(set(ap)))\n",
    "        all_categories.append(list(set(ac)))\n",
    "        all_children.append(list(set(ah)))\n",
    "        all_siblings.append(list(set(asib)))\n",
    "\n",
    "pwc_papers=pd.DataFrame({'title':title,'pdf_url':pdf_url,'paper_url':paper_url,'date':date,'task':task,\n",
    "                         'all_tasks':all_tasks,'all_parents':all_parents,'all_children':all_children,\n",
    "                         'all_siblings':all_siblings,'all_categories':all_categories,})\n",
    "\n",
    "print(\"TOTAL PWC PAPERS\",pwc_papers['title'].drop_duplicates().shape)\n",
    "task_hist=pd.Series(task_hist)\n",
    "#task_hist=task_hist[task_hist>task_hist.quantile(.3)]\n",
    "task_age=pd.Series(task_age)\n",
    "task_age.name='task_age'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a29c596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PWC PAPERS AFTER ADDING TASKS (134312,)\n",
      "DATASET CITING PAPERS (60647,)\n",
      "TOTAL DATASET CITING PAPERS (46692,)\n",
      "TOTAL DATASET CITING PAPERS (46692,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-6bdd88d0d1bd>:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  manual_dict['Proposed Tasks']=manual_dict['Proposed Tasks'].apply(lambda x: [j.strip() for j in x.split(',')] if type(x)!=float else [])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASETS (4383,)\n",
      "DATASETS_PWC (2626,)\n",
      "MISSING DATASET CITING PAPERS (13955,)\n"
     ]
    }
   ],
   "source": [
    "benchmark_papers.to_json('./DatawithTasks/benchmarks_with_datasets.json')\n",
    "pwc_papers.to_json('./DatawithTasks/pwc_papers.json')\n",
    "\n",
    "pwc_papers_task=pd.merge(task_relations,pwc_papers,on='task')\n",
    "#pwc_papers_task=pd.merge(paper_relations,pwc_papers,on='title')\n",
    "print(\"PWC PAPERS AFTER ADDING TASKS\",pwc_papers_task['title'].drop_duplicates().shape)\n",
    "dataset_citing_papers=pd.read_csv('/home/bkoch/Projects/DataProject/analyses/04-PWC/PWC_2021_06_16/datasets_citing_papers.txt',sep='\\t')\n",
    "print(\"DATASET CITING PAPERS\",dataset_citing_papers['title'].drop_duplicates().shape)\n",
    "\n",
    "dataset_citing_papers_total=pd.merge(dataset_citing_papers,pwc_papers_task,on=['title','date'],how='left')\n",
    "dataset_citing_papers_total['date']=pd.to_datetime(dataset_citing_papers_total['date'])\n",
    "dataset_citing_papers_total.to_json('./DatawithTasks/datasets_citing_papers_total.json')\n",
    "\n",
    "\n",
    "dataset_citing_papers_pwc=pd.merge(dataset_citing_papers,pwc_papers_task,on=['title','date'])\n",
    "dataset_citing_papers_pwc['date']=pd.to_datetime(dataset_citing_papers_pwc['date'])\n",
    "print(\"TOTAL DATASET CITING PAPERS\",dataset_citing_papers_pwc['title'].drop_duplicates().shape)\n",
    "dataset_citing_papers_pwc.to_json('./DatawithTasks/datasets_citing_papers_pwc.json')\n",
    "\n",
    "#dataset_citing_papers_pwc=dataset_citing_papers_pwc[dataset_citing_papers_pwc['all_parents'].apply(lambda x: len(x)<=1)]\n",
    "#dataset_citing_papers_pwc=dataset_citing_papers_pwc[dataset_citing_papers_pwc['all_tasks'].apply(lambda x: len([i for i in x if i in parent_child_dict ]))<2]\n",
    "\n",
    "print(\"TOTAL DATASET CITING PAPERS\",dataset_citing_papers_pwc['title'].drop_duplicates().shape)\n",
    "\n",
    "with open('/home/bkoch/Projects/DataProject/analyses/04-PWC/PWC_2021_06_16/datasets.json') as f:\n",
    "    datasets=pd.DataFrame(json.load(f))\n",
    "datasets['title']=datasets['paper'].apply(lambda js: js['title'] if js is not None else None)\n",
    "datasets['paper_url']=datasets['paper'].apply(lambda js: js['url'] if js is not None else None)\n",
    "datasets['introduced_date']=pd.to_datetime(datasets['introduced_date'])\n",
    "datasets['Texts']=datasets['modalities'].apply(lambda r: 'Texts' in r)\n",
    "datasets['Images']=datasets['modalities'].apply(lambda r: 'Images' in r)\n",
    "datasets['dataset_tasks']=datasets['tasks'].apply(lambda js: [ j['task'] for j in js])\n",
    "manual_dict=manual_task_labels[['name','Proposed Tasks']]\n",
    "manual_dict['Proposed Tasks']=manual_dict['Proposed Tasks'].apply(lambda x: [j.strip() for j in x.split(',')] if type(x)!=float else [])\n",
    "manual_dict=manual_dict.set_index('name').to_dict()['Proposed Tasks']\n",
    "datasets['dataset_tasks']=datasets.apply(lambda row: row['dataset_tasks']+manual_dict[row['name']] if row['name'] in manual_dict else row['dataset_tasks'],axis=1)\n",
    "datasets=datasets.drop(['tasks','paper'],axis=1)\n",
    "all_parents=[]\n",
    "all_children=[]\n",
    "all_categories=[]\n",
    "all_siblings=[]\n",
    "for i,row in datasets.iterrows():\n",
    "    ap=[]\n",
    "    [ ap.extend(child_parent_dict[t]) for t in row['dataset_tasks'] if t in child_parent_dict]\n",
    "    ac =[]\n",
    "    [ ac.extend(task_category_dict[t]) for t in row['dataset_tasks'] if t in task_category_dict]\n",
    "    ah=[]\n",
    "    [ ah.extend(parent_child_dict[t]) for t in row['dataset_tasks'] if t in parent_child_dict]\n",
    "    asib=[]\n",
    "    [ asib.extend(sibling_dict[t]) for t in row['dataset_tasks'] if t in sibling_dict]\n",
    "    all_parents.append(ap)\n",
    "    all_categories.append(ac)\n",
    "    all_children.append(ah)\n",
    "    all_siblings.append(asib)\n",
    "datasets['dataset_tasks_parents']=all_parents\n",
    "datasets['dataset_tasks_categories']=all_categories\n",
    "datasets['dataset_tasks_children']=all_children\n",
    "datasets['dataset_tasks_siblings']=all_siblings\n",
    "datasets.to_json('./dataset_with_tasks.json')\n",
    "\n",
    "\n",
    "\n",
    "# THE PAPER AFFILIATION FOR THIS DATASET IS TOTALLY MESSEDUP\n",
    "datasets=datasets[datasets.name!='PRID2011']\n",
    "\n",
    "\n",
    "#datasets['introduced_date']=pd.to_datetime(datasets['introduced_date'])\n",
    "datasets_pwc_total=pd.merge(datasets,pwc_papers_task,on=['title','paper_url'],how='left')\n",
    "datasets_pwc_total.to_json('./DatawithTasks/datasets_total.json')\n",
    "\n",
    "print(\"DATASETS\",datasets['name'].drop_duplicates().shape)\n",
    "datasets_pwc=pd.merge(datasets,pwc_papers_task,on=['title','paper_url'])\n",
    "#datasets_pwc['all_tasks']=datasets_pwc.apply(lambda row: list(set(row['all_tasks']+row['dataset_tasks'])) if row['name'] in manual_dict else row['all_tasks'],axis=1)\n",
    "\n",
    "print(\"DATASETS_PWC\",datasets_pwc['name'].drop_duplicates().shape)\n",
    "missing_papers=dataset_citing_papers[~dataset_citing_papers.title.isin(dataset_citing_papers_pwc.title)]\n",
    "print(\"MISSING DATASET CITING PAPERS\",missing_papers['title'].drop_duplicates().shape)\n",
    "datasets_pwc.to_json('./DatawithTasks/datasets_pwc.json')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd85c82-04e9-4df2-85fb-ef70535e07f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>pwc_dataset_id</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>is_problematic</th>\n",
       "      <th>paper_count</th>\n",
       "      <th>task</th>\n",
       "      <th>categories</th>\n",
       "      <th>parents</th>\n",
       "      <th>children</th>\n",
       "      <th>siblings</th>\n",
       "      <th>pdf_url</th>\n",
       "      <th>paper_url</th>\n",
       "      <th>all_tasks</th>\n",
       "      <th>all_parents</th>\n",
       "      <th>all_children</th>\n",
       "      <th>all_siblings</th>\n",
       "      <th>all_categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>MNIST</td>\n",
       "      <td>1</td>\n",
       "      <td>Sparse, Collaborative, or Nonnegative Represen...</td>\n",
       "      <td>2018-06-12</td>\n",
       "      <td>False</td>\n",
       "      <td>4159</td>\n",
       "      <td>Face Recognition</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Robust Face Alignment, Gender Prediction, Fac...</td>\n",
       "      <td>http://arxiv.org/pdf/1806.04329v2.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/sparse-collab...</td>\n",
       "      <td>[Face Recognition, General Classification]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Constructive ...</td>\n",
       "      <td>[Robust Face Alignment, Gender Prediction, Fac...</td>\n",
       "      <td>[Methodology, Natural Language Processing, Com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>CUB-200-2011</td>\n",
       "      <td>109</td>\n",
       "      <td>Sparse, Collaborative, or Nonnegative Represen...</td>\n",
       "      <td>2018-06-12</td>\n",
       "      <td>False</td>\n",
       "      <td>920</td>\n",
       "      <td>Face Recognition</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Robust Face Alignment, Gender Prediction, Fac...</td>\n",
       "      <td>http://arxiv.org/pdf/1806.04329v2.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/sparse-collab...</td>\n",
       "      <td>[Face Recognition, General Classification]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Constructive ...</td>\n",
       "      <td>[Robust Face Alignment, Gender Prediction, Fac...</td>\n",
       "      <td>[Methodology, Natural Language Processing, Com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>USPS</td>\n",
       "      <td>1055</td>\n",
       "      <td>Sparse, Collaborative, or Nonnegative Represen...</td>\n",
       "      <td>2018-06-12</td>\n",
       "      <td>False</td>\n",
       "      <td>254</td>\n",
       "      <td>Face Recognition</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Robust Face Alignment, Gender Prediction, Fac...</td>\n",
       "      <td>http://arxiv.org/pdf/1806.04329v2.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/sparse-collab...</td>\n",
       "      <td>[Face Recognition, General Classification]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Constructive ...</td>\n",
       "      <td>[Robust Face Alignment, Gender Prediction, Fac...</td>\n",
       "      <td>[Methodology, Natural Language Processing, Com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Caltech-256</td>\n",
       "      <td>1595</td>\n",
       "      <td>Sparse, Collaborative, or Nonnegative Represen...</td>\n",
       "      <td>2018-06-12</td>\n",
       "      <td>False</td>\n",
       "      <td>264</td>\n",
       "      <td>Face Recognition</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Robust Face Alignment, Gender Prediction, Fac...</td>\n",
       "      <td>http://arxiv.org/pdf/1806.04329v2.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/sparse-collab...</td>\n",
       "      <td>[Face Recognition, General Classification]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Constructive ...</td>\n",
       "      <td>[Robust Face Alignment, Gender Prediction, Fac...</td>\n",
       "      <td>[Methodology, Natural Language Processing, Com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Extended Yale B</td>\n",
       "      <td>3537</td>\n",
       "      <td>Sparse, Collaborative, or Nonnegative Represen...</td>\n",
       "      <td>2018-06-12</td>\n",
       "      <td>False</td>\n",
       "      <td>167</td>\n",
       "      <td>Face Recognition</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Robust Face Alignment, Gender Prediction, Fac...</td>\n",
       "      <td>http://arxiv.org/pdf/1806.04329v2.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/sparse-collab...</td>\n",
       "      <td>[Face Recognition, General Classification]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Constructive ...</td>\n",
       "      <td>[Robust Face Alignment, Gender Prediction, Fac...</td>\n",
       "      <td>[Methodology, Natural Language Processing, Com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213387</th>\n",
       "      <td>Visual Question Answering</td>\n",
       "      <td>5565</td>\n",
       "      <td>Loss-rescaling VQA: Revisiting Language Prior ...</td>\n",
       "      <td>2020-10-30</td>\n",
       "      <td>False</td>\n",
       "      <td>773</td>\n",
       "      <td>Face Recognition</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Robust Face Alignment, Gender Prediction, Fac...</td>\n",
       "      <td>https://arxiv.org/pdf/2010.16010v1.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/loss-rescalin...</td>\n",
       "      <td>[Face Recognition, Image Classification, Quest...</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Logical Reasoning Question Answering, Face Qu...</td>\n",
       "      <td>[Robust Face Alignment, Gender Prediction, Fac...</td>\n",
       "      <td>[Methodology, Natural Language Processing, Com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213391</th>\n",
       "      <td>Visual Question Answering v2.0</td>\n",
       "      <td>5845</td>\n",
       "      <td>Loss-rescaling VQA: Revisiting Language Prior ...</td>\n",
       "      <td>2020-10-30</td>\n",
       "      <td>False</td>\n",
       "      <td>149</td>\n",
       "      <td>Face Recognition</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Robust Face Alignment, Gender Prediction, Fac...</td>\n",
       "      <td>https://arxiv.org/pdf/2010.16010v1.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/loss-rescalin...</td>\n",
       "      <td>[Face Recognition, Image Classification, Quest...</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Logical Reasoning Question Answering, Face Qu...</td>\n",
       "      <td>[Robust Face Alignment, Gender Prediction, Fac...</td>\n",
       "      <td>[Methodology, Natural Language Processing, Com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214080</th>\n",
       "      <td>WildestFaces</td>\n",
       "      <td>5814</td>\n",
       "      <td>Red Carpet to Fight Club: Partially-supervised...</td>\n",
       "      <td>2020-09-16</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Face Recognition</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Robust Face Alignment, Gender Prediction, Fac...</td>\n",
       "      <td>https://arxiv.org/pdf/2009.07576v1.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/red-carpet-to...</td>\n",
       "      <td>[Face Recognition]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Robust Face Alignment, Gender Prediction, Fac...</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214271</th>\n",
       "      <td>HQ-WMCA</td>\n",
       "      <td>5918</td>\n",
       "      <td>On the Effectiveness of Vision Transformers fo...</td>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>Face Recognition</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Robust Face Alignment, Gender Prediction, Fac...</td>\n",
       "      <td>https://arxiv.org/pdf/2011.08019v2.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/on-the-effect...</td>\n",
       "      <td>[Face Anti-Spoofing, Face Recognition, Transfe...</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Unsupervised Domain Expansion, Face Quality A...</td>\n",
       "      <td>[Robust Face Alignment, Gender Prediction, Fac...</td>\n",
       "      <td>[Methodology, Computer Vision]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215740</th>\n",
       "      <td>HDA Facial Tattoo and Painting Database</td>\n",
       "      <td>6310</td>\n",
       "      <td>Impact of Facial Tattoos and Paintings on Face...</td>\n",
       "      <td>2021-03-17</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Face Recognition</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Robust Face Alignment, Gender Prediction, Fac...</td>\n",
       "      <td>https://arxiv.org/pdf/2103.09939v2.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/impact-of-fac...</td>\n",
       "      <td>[Face Recognition]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Robust Face Alignment, Gender Prediction, Fac...</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2380 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           name  pwc_dataset_id  \\\n",
       "47                                        MNIST               1   \n",
       "49                                 CUB-200-2011             109   \n",
       "51                                         USPS            1055   \n",
       "53                                  Caltech-256            1595   \n",
       "55                              Extended Yale B            3537   \n",
       "...                                         ...             ...   \n",
       "213387                Visual Question Answering            5565   \n",
       "213391           Visual Question Answering v2.0            5845   \n",
       "214080                             WildestFaces            5814   \n",
       "214271                                  HQ-WMCA            5918   \n",
       "215740  HDA Facial Tattoo and Painting Database            6310   \n",
       "\n",
       "                                                    title       date  \\\n",
       "47      Sparse, Collaborative, or Nonnegative Represen... 2018-06-12   \n",
       "49      Sparse, Collaborative, or Nonnegative Represen... 2018-06-12   \n",
       "51      Sparse, Collaborative, or Nonnegative Represen... 2018-06-12   \n",
       "53      Sparse, Collaborative, or Nonnegative Represen... 2018-06-12   \n",
       "55      Sparse, Collaborative, or Nonnegative Represen... 2018-06-12   \n",
       "...                                                   ...        ...   \n",
       "213387  Loss-rescaling VQA: Revisiting Language Prior ... 2020-10-30   \n",
       "213391  Loss-rescaling VQA: Revisiting Language Prior ... 2020-10-30   \n",
       "214080  Red Carpet to Fight Club: Partially-supervised... 2020-09-16   \n",
       "214271  On the Effectiveness of Vision Transformers fo... 2020-11-16   \n",
       "215740  Impact of Facial Tattoos and Paintings on Face... 2021-03-17   \n",
       "\n",
       "        is_problematic  paper_count              task         categories  \\\n",
       "47               False         4159  Face Recognition  [Computer Vision]   \n",
       "49               False          920  Face Recognition  [Computer Vision]   \n",
       "51               False          254  Face Recognition  [Computer Vision]   \n",
       "53               False          264  Face Recognition  [Computer Vision]   \n",
       "55               False          167  Face Recognition  [Computer Vision]   \n",
       "...                ...          ...               ...                ...   \n",
       "213387           False          773  Face Recognition  [Computer Vision]   \n",
       "213391           False          149  Face Recognition  [Computer Vision]   \n",
       "214080           False            1  Face Recognition  [Computer Vision]   \n",
       "214271           False            4  Face Recognition  [Computer Vision]   \n",
       "215740           False            1  Face Recognition  [Computer Vision]   \n",
       "\n",
       "                                   parents  \\\n",
       "47      [Facial Recognition and Modelling]   \n",
       "49      [Facial Recognition and Modelling]   \n",
       "51      [Facial Recognition and Modelling]   \n",
       "53      [Facial Recognition and Modelling]   \n",
       "55      [Facial Recognition and Modelling]   \n",
       "...                                    ...   \n",
       "213387  [Facial Recognition and Modelling]   \n",
       "213391  [Facial Recognition and Modelling]   \n",
       "214080  [Facial Recognition and Modelling]   \n",
       "214271  [Facial Recognition and Modelling]   \n",
       "215740  [Facial Recognition and Modelling]   \n",
       "\n",
       "                                                 children  \\\n",
       "47      [Age-Invariant Face Recognition, Face Quality ...   \n",
       "49      [Age-Invariant Face Recognition, Face Quality ...   \n",
       "51      [Age-Invariant Face Recognition, Face Quality ...   \n",
       "53      [Age-Invariant Face Recognition, Face Quality ...   \n",
       "55      [Age-Invariant Face Recognition, Face Quality ...   \n",
       "...                                                   ...   \n",
       "213387  [Age-Invariant Face Recognition, Face Quality ...   \n",
       "213391  [Age-Invariant Face Recognition, Face Quality ...   \n",
       "214080  [Age-Invariant Face Recognition, Face Quality ...   \n",
       "214271  [Age-Invariant Face Recognition, Face Quality ...   \n",
       "215740  [Age-Invariant Face Recognition, Face Quality ...   \n",
       "\n",
       "                                                 siblings  \\\n",
       "47      [Robust Face Alignment, Gender Prediction, Fac...   \n",
       "49      [Robust Face Alignment, Gender Prediction, Fac...   \n",
       "51      [Robust Face Alignment, Gender Prediction, Fac...   \n",
       "53      [Robust Face Alignment, Gender Prediction, Fac...   \n",
       "55      [Robust Face Alignment, Gender Prediction, Fac...   \n",
       "...                                                   ...   \n",
       "213387  [Robust Face Alignment, Gender Prediction, Fac...   \n",
       "213391  [Robust Face Alignment, Gender Prediction, Fac...   \n",
       "214080  [Robust Face Alignment, Gender Prediction, Fac...   \n",
       "214271  [Robust Face Alignment, Gender Prediction, Fac...   \n",
       "215740  [Robust Face Alignment, Gender Prediction, Fac...   \n",
       "\n",
       "                                       pdf_url  \\\n",
       "47       http://arxiv.org/pdf/1806.04329v2.pdf   \n",
       "49       http://arxiv.org/pdf/1806.04329v2.pdf   \n",
       "51       http://arxiv.org/pdf/1806.04329v2.pdf   \n",
       "53       http://arxiv.org/pdf/1806.04329v2.pdf   \n",
       "55       http://arxiv.org/pdf/1806.04329v2.pdf   \n",
       "...                                        ...   \n",
       "213387  https://arxiv.org/pdf/2010.16010v1.pdf   \n",
       "213391  https://arxiv.org/pdf/2010.16010v1.pdf   \n",
       "214080  https://arxiv.org/pdf/2009.07576v1.pdf   \n",
       "214271  https://arxiv.org/pdf/2011.08019v2.pdf   \n",
       "215740  https://arxiv.org/pdf/2103.09939v2.pdf   \n",
       "\n",
       "                                                paper_url  \\\n",
       "47      https://paperswithcode.com/paper/sparse-collab...   \n",
       "49      https://paperswithcode.com/paper/sparse-collab...   \n",
       "51      https://paperswithcode.com/paper/sparse-collab...   \n",
       "53      https://paperswithcode.com/paper/sparse-collab...   \n",
       "55      https://paperswithcode.com/paper/sparse-collab...   \n",
       "...                                                   ...   \n",
       "213387  https://paperswithcode.com/paper/loss-rescalin...   \n",
       "213391  https://paperswithcode.com/paper/loss-rescalin...   \n",
       "214080  https://paperswithcode.com/paper/red-carpet-to...   \n",
       "214271  https://paperswithcode.com/paper/on-the-effect...   \n",
       "215740  https://paperswithcode.com/paper/impact-of-fac...   \n",
       "\n",
       "                                                all_tasks  \\\n",
       "47             [Face Recognition, General Classification]   \n",
       "49             [Face Recognition, General Classification]   \n",
       "51             [Face Recognition, General Classification]   \n",
       "53             [Face Recognition, General Classification]   \n",
       "55             [Face Recognition, General Classification]   \n",
       "...                                                   ...   \n",
       "213387  [Face Recognition, Image Classification, Quest...   \n",
       "213391  [Face Recognition, Image Classification, Quest...   \n",
       "214080                                 [Face Recognition]   \n",
       "214271  [Face Anti-Spoofing, Face Recognition, Transfe...   \n",
       "215740                                 [Face Recognition]   \n",
       "\n",
       "                               all_parents  \\\n",
       "47      [Facial Recognition and Modelling]   \n",
       "49      [Facial Recognition and Modelling]   \n",
       "51      [Facial Recognition and Modelling]   \n",
       "53      [Facial Recognition and Modelling]   \n",
       "55      [Facial Recognition and Modelling]   \n",
       "...                                    ...   \n",
       "213387  [Facial Recognition and Modelling]   \n",
       "213391  [Facial Recognition and Modelling]   \n",
       "214080  [Facial Recognition and Modelling]   \n",
       "214271  [Facial Recognition and Modelling]   \n",
       "215740  [Facial Recognition and Modelling]   \n",
       "\n",
       "                                             all_children  \\\n",
       "47      [Age-Invariant Face Recognition, Constructive ...   \n",
       "49      [Age-Invariant Face Recognition, Constructive ...   \n",
       "51      [Age-Invariant Face Recognition, Constructive ...   \n",
       "53      [Age-Invariant Face Recognition, Constructive ...   \n",
       "55      [Age-Invariant Face Recognition, Constructive ...   \n",
       "...                                                   ...   \n",
       "213387  [Logical Reasoning Question Answering, Face Qu...   \n",
       "213391  [Logical Reasoning Question Answering, Face Qu...   \n",
       "214080  [Age-Invariant Face Recognition, Face Quality ...   \n",
       "214271  [Unsupervised Domain Expansion, Face Quality A...   \n",
       "215740  [Age-Invariant Face Recognition, Face Quality ...   \n",
       "\n",
       "                                             all_siblings  \\\n",
       "47      [Robust Face Alignment, Gender Prediction, Fac...   \n",
       "49      [Robust Face Alignment, Gender Prediction, Fac...   \n",
       "51      [Robust Face Alignment, Gender Prediction, Fac...   \n",
       "53      [Robust Face Alignment, Gender Prediction, Fac...   \n",
       "55      [Robust Face Alignment, Gender Prediction, Fac...   \n",
       "...                                                   ...   \n",
       "213387  [Robust Face Alignment, Gender Prediction, Fac...   \n",
       "213391  [Robust Face Alignment, Gender Prediction, Fac...   \n",
       "214080  [Robust Face Alignment, Gender Prediction, Fac...   \n",
       "214271  [Robust Face Alignment, Gender Prediction, Fac...   \n",
       "215740  [Robust Face Alignment, Gender Prediction, Fac...   \n",
       "\n",
       "                                           all_categories  \n",
       "47      [Methodology, Natural Language Processing, Com...  \n",
       "49      [Methodology, Natural Language Processing, Com...  \n",
       "51      [Methodology, Natural Language Processing, Com...  \n",
       "53      [Methodology, Natural Language Processing, Com...  \n",
       "55      [Methodology, Natural Language Processing, Com...  \n",
       "...                                                   ...  \n",
       "213387  [Methodology, Natural Language Processing, Com...  \n",
       "213391  [Methodology, Natural Language Processing, Com...  \n",
       "214080                                  [Computer Vision]  \n",
       "214271                     [Methodology, Computer Vision]  \n",
       "215740                                  [Computer Vision]  \n",
       "\n",
       "[2380 rows x 18 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linked_Titles=pd.read_csv('/home/bkoch/Projects/DataProject/analyses/04-PWC/PWC_2021_06_16/PWC_Linkedto_MAG.PWC_Title.txt',sep='\\t')\n",
    "pwc_papers[pwc_papers.task=='Face Recognition'].title.isin(linked_Titles.PWC_Title).sum()\n",
    "datasets_pwc[datasets_pwc.dataset_tasks.apply(lambda x: \"Face Recognition\" in x)]\n",
    "dataset_citing_papers_pwc[dataset_citing_papers_pwc.task.apply(lambda x: \"Face Recognition\" in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5d214674-c38f-4cf9-b072-1426e7dd22df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>name</th>\n",
       "      <th>full_name</th>\n",
       "      <th>homepage</th>\n",
       "      <th>description</th>\n",
       "      <th>introduced_date</th>\n",
       "      <th>warning</th>\n",
       "      <th>modalities</th>\n",
       "      <th>languages</th>\n",
       "      <th>variants</th>\n",
       "      <th>...</th>\n",
       "      <th>data_loaders</th>\n",
       "      <th>title</th>\n",
       "      <th>paper_url</th>\n",
       "      <th>Texts</th>\n",
       "      <th>Images</th>\n",
       "      <th>dataset_tasks</th>\n",
       "      <th>dataset_tasks_parents</th>\n",
       "      <th>dataset_tasks_categories</th>\n",
       "      <th>dataset_tasks_children</th>\n",
       "      <th>dataset_tasks_siblings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://paperswithcode.com/dataset/lfw</td>\n",
       "      <td>LFW</td>\n",
       "      <td>Labeled Faces in the Wild</td>\n",
       "      <td>http://vis-www.cs.umass.edu/lfw/</td>\n",
       "      <td>The **LFW** dataset contains 13,233 images of ...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[LFW, Labeled Faces in the Wild, LFW (Online O...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'url': 'https://www.tensorflow.org/datasets/...</td>\n",
       "      <td>Labeled faces in the wild: A database for stud...</td>\n",
       "      <td>http://vis-www.cs.umass.edu/lfw/lfw.pdf</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[3D FACE MODELING, Face Verification, Face Rec...</td>\n",
       "      <td>[3D, Facial Recognition and Modelling, 3D, Fac...</td>\n",
       "      <td>[Computer Vision, Computer Vision, Computer Vi...</td>\n",
       "      <td>[Facial Recognition and Modelling, Disguised F...</td>\n",
       "      <td>[Video Reconstruction, 3D Shape Generation, 3D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>https://paperswithcode.com/dataset/adience</td>\n",
       "      <td>Adience</td>\n",
       "      <td></td>\n",
       "      <td>https://talhassner.github.io/home/projects/Adi...</td>\n",
       "      <td>The **Adience** dataset, published in 2014, co...</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Adience, Adience Age, Adience Gender, Adience...</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Age and Gender Estimation of Unfiltered Faces</td>\n",
       "      <td>https://doi.org/10.1109/TIFS.2014.2359646</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[Face Recognition, Age And Gender Classificati...</td>\n",
       "      <td>[Facial Recognition and Modelling, Facial Reco...</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Facial Inpainting, Action Unit Detection, Fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>https://paperswithcode.com/dataset/multi-pie</td>\n",
       "      <td>Multi-PIE</td>\n",
       "      <td></td>\n",
       "      <td>http://www.cs.cmu.edu/afs/cs/project/PIE/Multi...</td>\n",
       "      <td>The **Multi-PIE** (Multi Pose, Illumination, E...</td>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Multi-PIE]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Multi-PIE</td>\n",
       "      <td>https://doi.org/10.1109/AFGR.2008.4813399</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[Single-Image Portrait Relighting, Face Recogn...</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Computer Code, Computer Vision]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Facial Inpainting, Action Unit Detection, Fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>https://paperswithcode.com/dataset/vgg-face-1</td>\n",
       "      <td>VGG Face</td>\n",
       "      <td></td>\n",
       "      <td>https://www.robots.ox.ac.uk/~vgg/data/vgg_face/</td>\n",
       "      <td>The **VGG Face** dataset is face identity reco...</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[VGG Face]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Deep Face Recognition</td>\n",
       "      <td>https://doi.org/10.5244/C.29.41</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[Domain Adaptation, Face Verification, Face Re...</td>\n",
       "      <td>[Facial Recognition and Modelling, 3D, Facial ...</td>\n",
       "      <td>[Computer Vision, Methodology, Computer Vision...</td>\n",
       "      <td>[Unsupervised Domain Adaptation, Domain Genera...</td>\n",
       "      <td>[Facial Inpainting, Video Reconstruction, Acti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>https://paperswithcode.com/dataset/casia-webface</td>\n",
       "      <td>CASIA-WebFace</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>The **CASIA-WebFace** dataset is used for face...</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[WebFace, WebFace - 8x upscaling, CASIA-WebFace]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Learning Face Representation from Scratch</td>\n",
       "      <td>https://paperswithcode.com/paper/learning-face...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[Image Super-Resolution, Face Verification, Fa...</td>\n",
       "      <td>[Super-Resolution, Facial Recognition and Mode...</td>\n",
       "      <td>[Audio, Computer Vision, Computer Vision, Comp...</td>\n",
       "      <td>[Multi-Frame Super-Resolution, Audio Super-Res...</td>\n",
       "      <td>[Depth Map Super-Resolution, Image Super-Resol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>https://paperswithcode.com/dataset/ms-celeb-1m</td>\n",
       "      <td>MS-Celeb-1M</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>The **MS-Celeb-1M** dataset is a large-scale f...</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[MS-Celeb-1M]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>MS-Celeb-1M: A Dataset and Benchmark for Large...</td>\n",
       "      <td>https://paperswithcode.com/paper/ms-celeb-1m-a...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[Face Verification, Face Recognition, Face Ide...</td>\n",
       "      <td>[Facial Recognition and Modelling, 3D, Facial ...</td>\n",
       "      <td>[Computer Vision, Computer Vision]</td>\n",
       "      <td>[Disguised Face Verification, Age-Invariant Fa...</td>\n",
       "      <td>[Facial Inpainting, Video Reconstruction, Acti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>https://paperswithcode.com/dataset/extended-ya...</td>\n",
       "      <td>Extended Yale B</td>\n",
       "      <td></td>\n",
       "      <td>http://vision.ucsd.edu/~leekc/ExtYaleDatabase/...</td>\n",
       "      <td>The **Extended Yale B** database contains 2414...</td>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Extended Yale-B, Extended Yale B]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>From Few to Many: Illumination Cone Models for...</td>\n",
       "      <td>https://doi.org/10.1109/34.927464</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[Image Classification, Image Clustering, Face ...</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Computer Vision, Methodology, Computer Vision...</td>\n",
       "      <td>[Few-Shot Image Classification, Fine-Grained I...</td>\n",
       "      <td>[Facial Inpainting, Action Unit Detection, Fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>https://paperswithcode.com/dataset/color-feret</td>\n",
       "      <td>Color FERET</td>\n",
       "      <td>Color FERET</td>\n",
       "      <td>https://catalog.data.gov/dataset/color-feret-d...</td>\n",
       "      <td>The color FERET database is a dataset for face...</td>\n",
       "      <td>1997-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Color FERET (Online Open Set), Color FERET]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>The FERET Evaluation Methodology for Face-Reco...</td>\n",
       "      <td>https://doi.org/10.1109/CVPR.1997.609311</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[Face Recognition]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Facial Inpainting, Action Unit Detection, Fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>https://paperswithcode.com/dataset/replay-mobi...</td>\n",
       "      <td>Replay-Mobile</td>\n",
       "      <td>Replay-Mobile</td>\n",
       "      <td>https://www.idiap.ch/dataset/replay-mobile</td>\n",
       "      <td>The **Replay-Mobile** Database for face spoofi...</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images, Videos]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Replay Mobile, Replay-Mobile]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>The Replay-Mobile Face Presentation-Attack Dat...</td>\n",
       "      <td>https://doi.org/10.1109/BIOSIG.2016.7736936</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[Face Recognition, Face Anti-Spoofing, Face Pr...</td>\n",
       "      <td>[Facial Recognition and Modelling, Facial Reco...</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Facial Inpainting, Action Unit Detection, Fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>https://paperswithcode.com/dataset/casia-fasd</td>\n",
       "      <td>CASIA-FASD</td>\n",
       "      <td>CASIA-FASD</td>\n",
       "      <td>https://pypi.org/project/bob.db.casia-fasd/</td>\n",
       "      <td>**CASIA-FASD** is a small face anti-spoofing d...</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[CASIA-FASD]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>A face antispoofing database with diverse attacks</td>\n",
       "      <td>https://doi.org/10.1109/ICB.2012.6199754</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[Anomaly Detection, Face Recognition, Face Ant...</td>\n",
       "      <td>[Facial Recognition and Modelling, Facial Reco...</td>\n",
       "      <td>[Miscellaneous, Computer Vision, Speech, Metho...</td>\n",
       "      <td>[Unsupervised Anomaly Detection, Anomaly Detec...</td>\n",
       "      <td>[Facial Inpainting, Action Unit Detection, Fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>https://paperswithcode.com/dataset/partial-reid</td>\n",
       "      <td>Partial-REID</td>\n",
       "      <td>Partial-REID</td>\n",
       "      <td>https://github.com/JDAI-CV/Partial-Person-ReID</td>\n",
       "      <td>Partial REID is a specially designed partial p...</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Partial-REID]</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'url': 'https://github.com/JDAI-CV/Partial-P...</td>\n",
       "      <td>Partial Person Re-Identification</td>\n",
       "      <td>https://paperswithcode.com/paper/partial-perso...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[Person Re-Identification, Face Recognition, D...</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Computer Vision, Computer Vision, Methodology]</td>\n",
       "      <td>[Unsupervised Person Re-Identification, Video-...</td>\n",
       "      <td>[Facial Inpainting, Action Unit Detection, Fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>https://paperswithcode.com/dataset/iqiyi-vid</td>\n",
       "      <td>iQIYI-VID</td>\n",
       "      <td>iQIYI-VID</td>\n",
       "      <td>http://challenge.ai.iqiyi.com/detail?raceId=5a...</td>\n",
       "      <td>iQIYI-VID dataset, which comprises video clips...</td>\n",
       "      <td>2018-11-19</td>\n",
       "      <td>None</td>\n",
       "      <td>[Videos]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[iQIYI-VID]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>iQIYI-VID: A Large Dataset for Multi-modal Per...</td>\n",
       "      <td>https://paperswithcode.com/paper/iqiyi-vid-a-l...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[Person Re-Identification, Face Recognition, P...</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Computer Vision, Computer Vision, Computer Vi...</td>\n",
       "      <td>[Unsupervised Person Re-Identification, Video-...</td>\n",
       "      <td>[Facial Inpainting, Action Unit Detection, Fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>https://paperswithcode.com/dataset/kanface</td>\n",
       "      <td>KANFace</td>\n",
       "      <td>KANFace Dataset</td>\n",
       "      <td>https://sites.google.com/view/kanface-dataset</td>\n",
       "      <td>KANFace consists of 40K still images and 44K s...</td>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[KANFace]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Investigating Bias in Deep Face Analysis: The ...</td>\n",
       "      <td>https://paperswithcode.com/paper/investigating...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[Face Recognition, Age Estimation, Fairness]</td>\n",
       "      <td>[Facial Recognition and Modelling, Facial Reco...</td>\n",
       "      <td>[Computer Vision, Computer Vision, Miscellaneous]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Facial Inpainting, Action Unit Detection, Fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>https://paperswithcode.com/dataset/casia-surf</td>\n",
       "      <td>CASIA-SURF</td>\n",
       "      <td></td>\n",
       "      <td>https://sites.google.com/qq.com/face-anti-spoo...</td>\n",
       "      <td>Dataset for face anti-spoofing in terms of bot...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[CASIA-SURF]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>CASIA-SURF: A Large-scale Multi-modal Benchmar...</td>\n",
       "      <td>https://paperswithcode.com/paper/casia-surf-a-...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[Face Recognition, Face Anti-Spoofing, Face Pr...</td>\n",
       "      <td>[Facial Recognition and Modelling, Facial Reco...</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Facial Inpainting, Action Unit Detection, Fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>https://paperswithcode.com/dataset/celeba-spoof</td>\n",
       "      <td>CelebA-Spoof</td>\n",
       "      <td></td>\n",
       "      <td>https://github.com/Davidzhangyuanhan/CelebA-Spoof</td>\n",
       "      <td>CelebA-Spoof is a large-scale face anti-spoofi...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[CelebA-Spoof]</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'url': 'https://github.com/Davidzhangyuanhan...</td>\n",
       "      <td>CelebA-Spoof: Large-Scale Face Anti-Spoofing D...</td>\n",
       "      <td>https://paperswithcode.com/paper/celeba-spoof-...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[Face Recognition, Face Anti-Spoofing]</td>\n",
       "      <td>[Facial Recognition and Modelling, Facial Reco...</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Facial Inpainting, Action Unit Detection, Fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>https://paperswithcode.com/dataset/curated-afd</td>\n",
       "      <td>Curated AFD</td>\n",
       "      <td>None</td>\n",
       "      <td>https://github.com/vitoralbiero/afd_dataset_cl...</td>\n",
       "      <td>The **Curated AFD** dataset is a curated versi...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Curated AFD]</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'url': 'https://github.com/vitoralbiero/afd_...</td>\n",
       "      <td>A Method for Curation of Web-Scraped Face Imag...</td>\n",
       "      <td>https://paperswithcode.com/paper/a-method-for-...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[Face Recognition]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Facial Inpainting, Action Unit Detection, Fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714</th>\n",
       "      <td>https://paperswithcode.com/dataset/dfw</td>\n",
       "      <td>DFW</td>\n",
       "      <td>Disguised Faces in the Wild</td>\n",
       "      <td>http://iab-rubric.org/resources/dfw.html</td>\n",
       "      <td>Contains over 11000 images of 1000 identities ...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Disguised Faces in the Wild, Disguised Faces ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Recognizing Disguised Faces in the Wild</td>\n",
       "      <td>https://paperswithcode.com/paper/recognizing-d...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[Face Recognition, Heterogeneous Face Recognit...</td>\n",
       "      <td>[Facial Recognition and Modelling, Facial Reco...</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Facial Inpainting, Action Unit Detection, Fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>https://paperswithcode.com/dataset/diveface</td>\n",
       "      <td>DiveFace</td>\n",
       "      <td></td>\n",
       "      <td>https://github.com/BiDAlab/DiveFace</td>\n",
       "      <td>A new face annotation dataset with balanced di...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[DiveFace]</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'url': 'https://github.com/BiDAlab/DiveFace'...</td>\n",
       "      <td>SensitiveNets: Learning Agnostic Representatio...</td>\n",
       "      <td>https://paperswithcode.com/paper/sensitivenets...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[Face Recognition, Fairness]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Computer Vision, Computer Vision, Miscellaneous]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Facial Inpainting, Action Unit Detection, Fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1813</th>\n",
       "      <td>https://paperswithcode.com/dataset/fairface</td>\n",
       "      <td>FairFace</td>\n",
       "      <td></td>\n",
       "      <td>https://github.com/joojs/fairface</td>\n",
       "      <td>**FairFace** is a face image dataset which is ...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[FairFace]</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'url': 'https://huggingface.co/datasets/nate...</td>\n",
       "      <td>FairFace: Face Attribute Dataset for Balanced ...</td>\n",
       "      <td>https://paperswithcode.com/paper/fairface-face...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[Face Recognition, Facial Attribute Classifica...</td>\n",
       "      <td>[Facial Recognition and Modelling, Facial Reco...</td>\n",
       "      <td>[Computer Vision, Reasoning, Computer Vision, ...</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Facial Inpainting, Action Unit Detection, Fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1957</th>\n",
       "      <td>https://paperswithcode.com/dataset/icartoonface</td>\n",
       "      <td>iCartoonFace</td>\n",
       "      <td>None</td>\n",
       "      <td>https://github.com/luxiangju-PersonAI/iCartoon...</td>\n",
       "      <td>The **iCartoonFace** dataset is a large-scale ...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[iCartoonFace]</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'url': 'https://github.com/luxiangju-PersonA...</td>\n",
       "      <td>Cartoon Face Recognition: A Benchmark Dataset</td>\n",
       "      <td>https://paperswithcode.com/paper/icartoonface-...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[Image Classification, Face Recognition, Perso...</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Computer Vision, Methodology, Computer Vision...</td>\n",
       "      <td>[Few-Shot Image Classification, Fine-Grained I...</td>\n",
       "      <td>[Facial Inpainting, Action Unit Detection, Fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>https://paperswithcode.com/dataset/imdb-face</td>\n",
       "      <td>IMDb-Face</td>\n",
       "      <td></td>\n",
       "      <td>https://github.com/fwang91/IMDb-Face</td>\n",
       "      <td>IMDb-Face is  large-scale noise-controlled dat...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[IMDb-Face]</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'url': 'https://github.com/fwang91/IMDb-Face...</td>\n",
       "      <td>The Devil of Face Recognition is in the Noise</td>\n",
       "      <td>https://paperswithcode.com/paper/the-devil-of-...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[Face Recognition, Curriculum Learning]</td>\n",
       "      <td>[Facial Recognition and Modelling, General Rei...</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Facial Inpainting, Action Unit Detection, Fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>https://paperswithcode.com/dataset/lslf</td>\n",
       "      <td>LSLF</td>\n",
       "      <td>Large-scale Labeled Face</td>\n",
       "      <td>http://discovery.cs.wayne.edu/lab_website/lsdl/</td>\n",
       "      <td>Consists of a large number of unconstrained mu...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[LSLF]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Large-scale Datasets: Faces with Partial Occlu...</td>\n",
       "      <td>https://paperswithcode.com/paper/large-scale-d...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[Face Recognition, Face Detection]</td>\n",
       "      <td>[Facial Recognition and Modelling, Facial Reco...</td>\n",
       "      <td>[Computer Vision, Computer Vision]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Facial Inpainting, Action Unit Detection, Fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>https://paperswithcode.com/dataset/mebal</td>\n",
       "      <td>mEBAL</td>\n",
       "      <td></td>\n",
       "      <td>https://github.com/BiDAlab/mEBAL</td>\n",
       "      <td>A multimodal database for eye blink detection ...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[mEBAL]</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'url': 'https://github.com/BiDAlab/mEBAL', '...</td>\n",
       "      <td>mEBAL: A Multimodal Database for Eye Blink Det...</td>\n",
       "      <td>https://paperswithcode.com/paper/mebal-a-multi...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[Face Recognition, EEG, Face Anti-Spoofing]</td>\n",
       "      <td>[Facial Recognition and Modelling, Facial Reco...</td>\n",
       "      <td>[Computer Vision, Time Series, Methodology]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Facial Inpainting, Action Unit Detection, Fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>https://paperswithcode.com/dataset/meglass</td>\n",
       "      <td>MeGlass</td>\n",
       "      <td>None</td>\n",
       "      <td>https://github.com/cleardusk/MeGlass</td>\n",
       "      <td>**MeGlass** is an eyeglass dataset originally ...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[MeGlass]</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'url': 'https://github.com/cleardusk/MeGlass...</td>\n",
       "      <td>Face Synthesis for Eyeglass-Robust Face Recogn...</td>\n",
       "      <td>https://paperswithcode.com/paper/face-synthesi...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[Face Recognition, Robust Face Recognition, Fa...</td>\n",
       "      <td>[Facial Recognition and Modelling, Facial Reco...</td>\n",
       "      <td>[Computer Vision, Computer Vision]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Facial Inpainting, Action Unit Detection, Fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2414</th>\n",
       "      <td>https://paperswithcode.com/dataset/qmul-survface</td>\n",
       "      <td>QMUL-SurvFace</td>\n",
       "      <td></td>\n",
       "      <td>https://qmul-survface.github.io/</td>\n",
       "      <td>**QMUL-SurvFace** is a surveillance face recog...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[QMUL-SurvFace]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Surveillance Face Recognition Challenge</td>\n",
       "      <td>https://paperswithcode.com/paper/surveillance-...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[Super-Resolution, Face Recognition, Deblurring]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Graphs, Computer Vision, Computer Vision, Com...</td>\n",
       "      <td>[Image Super-Resolution, Video Super-Resolutio...</td>\n",
       "      <td>[Facial Inpainting, Action Unit Detection, Fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2457</th>\n",
       "      <td>https://paperswithcode.com/dataset/rfw</td>\n",
       "      <td>RFW</td>\n",
       "      <td>Racial Faces in-the-Wild</td>\n",
       "      <td>http://whdeng.cn/RFW/testing.html</td>\n",
       "      <td>To validate the racial bias of four commercial...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[RFW]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Racial Faces in-the-Wild: Reducing Racial Bias...</td>\n",
       "      <td>https://paperswithcode.com/paper/racial-faces-...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[Face Verification, Face Recognition, Fairness]</td>\n",
       "      <td>[Facial Recognition and Modelling, 3D, Facial ...</td>\n",
       "      <td>[Computer Vision, Computer Vision, Computer Vi...</td>\n",
       "      <td>[Disguised Face Verification, Age-Invariant Fa...</td>\n",
       "      <td>[Facial Inpainting, Video Reconstruction, Acti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2467</th>\n",
       "      <td>https://paperswithcode.com/dataset/rmfd</td>\n",
       "      <td>RMFD</td>\n",
       "      <td>Real-World Masked Face Dataset</td>\n",
       "      <td>https://github.com/X-zhangyang/Real-World-Mask...</td>\n",
       "      <td>**Real-World Masked Face Dataset** (**RMFD**) ...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[RMFD]</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'url': 'https://github.com/X-zhangyang/Real-...</td>\n",
       "      <td>Masked Face Recognition Dataset and Application</td>\n",
       "      <td>https://paperswithcode.com/paper/masked-face-r...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[Face Recognition, Face Detection]</td>\n",
       "      <td>[Facial Recognition and Modelling, Facial Reco...</td>\n",
       "      <td>[Computer Vision, Computer Vision]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Facial Inpainting, Action Unit Detection, Fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>https://paperswithcode.com/dataset/swax</td>\n",
       "      <td>SWAX</td>\n",
       "      <td>Sense Wax Attack dataset</td>\n",
       "      <td>http://smartsenselab.dcc.ufmg.br/en/dataset/sw...</td>\n",
       "      <td>Comprised of real human and wax figure images ...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[SWAX]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>The SWAX Benchmark: Attacking Biometric System...</td>\n",
       "      <td>https://paperswithcode.com/paper/the-swax-benc...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[Face Recognition, Face Anti-Spoofing, Face Pr...</td>\n",
       "      <td>[Facial Recognition and Modelling, Facial Reco...</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Facial Inpainting, Action Unit Detection, Fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>https://paperswithcode.com/dataset/umdfaces</td>\n",
       "      <td>UMDFaces</td>\n",
       "      <td></td>\n",
       "      <td>https://www.umdfaces.io/</td>\n",
       "      <td>UMDFaces is a face dataset divided into two pa...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[UMDFaces]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>UMDFaces: An Annotated Face Dataset for Traini...</td>\n",
       "      <td>https://paperswithcode.com/paper/umdfaces-an-a...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[Face Verification, Face Recognition, Face Det...</td>\n",
       "      <td>[Facial Recognition and Modelling, 3D, Facial ...</td>\n",
       "      <td>[Computer Vision, Computer Vision, Computer Vi...</td>\n",
       "      <td>[Disguised Face Verification, Age-Invariant Fa...</td>\n",
       "      <td>[Facial Inpainting, Video Reconstruction, Acti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2786</th>\n",
       "      <td>https://paperswithcode.com/dataset/webcaricatu...</td>\n",
       "      <td>WebCaricature Dataset</td>\n",
       "      <td></td>\n",
       "      <td>http://cs.nju.edu.cn/rl/WebCaricature.htm</td>\n",
       "      <td>Aims to facilitate research in caricature reco...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[WebCaricature Dataset]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>WebCaricature: a benchmark for caricature reco...</td>\n",
       "      <td>https://paperswithcode.com/paper/webcaricature...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[Face Recognition, Style Transfer, Caricature]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Computer Vision, Computer Vision, Computer Vi...</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Facial Inpainting, Action Unit Detection, Fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3015</th>\n",
       "      <td>https://paperswithcode.com/dataset/wildestfaces</td>\n",
       "      <td>WildestFaces</td>\n",
       "      <td></td>\n",
       "      <td>https://ycbilge.github.io/wildestFaces</td>\n",
       "      <td>WildestFaces is tailored to study cross-domain...</td>\n",
       "      <td>2020-09-16</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[WildestFaces]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Red Carpet to Fight Club: Partially-supervised...</td>\n",
       "      <td>https://paperswithcode.com/paper/red-carpet-to...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[Face Recognition]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Facial Inpainting, Action Unit Detection, Fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3016</th>\n",
       "      <td>https://paperswithcode.com/dataset/fad</td>\n",
       "      <td>FAD</td>\n",
       "      <td>Face Attributes Dataset</td>\n",
       "      <td>https://arxiv.org/pdf/1605.09062.pdf</td>\n",
       "      <td>FAD is a dataset that have roughly 200,000 att...</td>\n",
       "      <td>2016-05-29</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[FAD]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Predicting Personal Traits from Facial Images ...</td>\n",
       "      <td>https://paperswithcode.com/paper/predicting-pe...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[Face Recognition, Face Detection, Physical At...</td>\n",
       "      <td>[Facial Recognition and Modelling, Facial Reco...</td>\n",
       "      <td>[Computer Vision, Computer Vision, Computer Vi...</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Facial Inpainting, Action Unit Detection, Fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>https://paperswithcode.com/dataset/casia-face-...</td>\n",
       "      <td>CASIA-Face-Africa</td>\n",
       "      <td></td>\n",
       "      <td>http://www.cripacsir.cn/dataset/casia-face-afr...</td>\n",
       "      <td>**CASIA-Face-Africa** is a face image database...</td>\n",
       "      <td>2021-05-08</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[CASIA-Face-Africa]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>CASIA-Face-Africa: A Large-scale African Face ...</td>\n",
       "      <td>https://paperswithcode.com/paper/casia-face-af...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[Face Recognition, Facial Landmark Detection, ...</td>\n",
       "      <td>[Facial Recognition and Modelling, Facial Reco...</td>\n",
       "      <td>[Computer Vision, Computer Vision, Computer Vi...</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Facial Inpainting, Action Unit Detection, Fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4231</th>\n",
       "      <td>https://paperswithcode.com/dataset/imfw</td>\n",
       "      <td>IMFW</td>\n",
       "      <td>Indian Masked Faces In The Wild</td>\n",
       "      <td>http://www.iab-rubric.org/resources/imfw.html</td>\n",
       "      <td>Indian Masked faces in the wild Database is co...</td>\n",
       "      <td>2021-06-17</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[IMFW]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Indian Masked Faces in the Wild Dataset</td>\n",
       "      <td>https://paperswithcode.com/paper/indian-masked...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[Face Recognition]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Facial Inpainting, Action Unit Detection, Fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4285</th>\n",
       "      <td>https://paperswithcode.com/dataset/extended-yo...</td>\n",
       "      <td>Extended YouTube Faces (E-YTF)</td>\n",
       "      <td></td>\n",
       "      <td>https://www.micc.unifi.it/resources/datasets/e...</td>\n",
       "      <td>The proposed Extended-YouTube Faces (E-YTF) is...</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images, Videos]</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[Extended YouTube Faces (E-YTF)]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Additional Baseline Metrics for the paper \"Ext...</td>\n",
       "      <td>https://paperswithcode.com/paper/additional-ba...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[Face Verification, Face Recognition]</td>\n",
       "      <td>[Facial Recognition and Modelling, 3D, Facial ...</td>\n",
       "      <td>[Computer Vision, Computer Vision]</td>\n",
       "      <td>[Disguised Face Verification, Age-Invariant Fa...</td>\n",
       "      <td>[Facial Inpainting, Video Reconstruction, Acti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4298</th>\n",
       "      <td>https://paperswithcode.com/dataset/tinyface</td>\n",
       "      <td>TinyFace</td>\n",
       "      <td></td>\n",
       "      <td>https://qmul-tinyface.github.io/</td>\n",
       "      <td>**TinyFace** is a large scale face recognition...</td>\n",
       "      <td>2018-11-21</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[TinyFace]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Low-Resolution Face Recognition</td>\n",
       "      <td>https://paperswithcode.com/paper/low-resolutio...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[Face Recognition]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Facial Inpainting, Action Unit Detection, Fac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    url  \\\n",
       "8                https://paperswithcode.com/dataset/lfw   \n",
       "468          https://paperswithcode.com/dataset/adience   \n",
       "601        https://paperswithcode.com/dataset/multi-pie   \n",
       "788       https://paperswithcode.com/dataset/vgg-face-1   \n",
       "790    https://paperswithcode.com/dataset/casia-webface   \n",
       "792      https://paperswithcode.com/dataset/ms-celeb-1m   \n",
       "815   https://paperswithcode.com/dataset/extended-ya...   \n",
       "955      https://paperswithcode.com/dataset/color-feret   \n",
       "968   https://paperswithcode.com/dataset/replay-mobi...   \n",
       "975       https://paperswithcode.com/dataset/casia-fasd   \n",
       "995     https://paperswithcode.com/dataset/partial-reid   \n",
       "1235       https://paperswithcode.com/dataset/iqiyi-vid   \n",
       "1237         https://paperswithcode.com/dataset/kanface   \n",
       "1537      https://paperswithcode.com/dataset/casia-surf   \n",
       "1550    https://paperswithcode.com/dataset/celeba-spoof   \n",
       "1672     https://paperswithcode.com/dataset/curated-afd   \n",
       "1714             https://paperswithcode.com/dataset/dfw   \n",
       "1725        https://paperswithcode.com/dataset/diveface   \n",
       "1813        https://paperswithcode.com/dataset/fairface   \n",
       "1957    https://paperswithcode.com/dataset/icartoonface   \n",
       "1977       https://paperswithcode.com/dataset/imdb-face   \n",
       "2095            https://paperswithcode.com/dataset/lslf   \n",
       "2124           https://paperswithcode.com/dataset/mebal   \n",
       "2139         https://paperswithcode.com/dataset/meglass   \n",
       "2414   https://paperswithcode.com/dataset/qmul-survface   \n",
       "2457             https://paperswithcode.com/dataset/rfw   \n",
       "2467            https://paperswithcode.com/dataset/rmfd   \n",
       "2622            https://paperswithcode.com/dataset/swax   \n",
       "2732        https://paperswithcode.com/dataset/umdfaces   \n",
       "2786  https://paperswithcode.com/dataset/webcaricatu...   \n",
       "3015    https://paperswithcode.com/dataset/wildestfaces   \n",
       "3016             https://paperswithcode.com/dataset/fad   \n",
       "3999  https://paperswithcode.com/dataset/casia-face-...   \n",
       "4231            https://paperswithcode.com/dataset/imfw   \n",
       "4285  https://paperswithcode.com/dataset/extended-yo...   \n",
       "4298        https://paperswithcode.com/dataset/tinyface   \n",
       "\n",
       "                                name                        full_name  \\\n",
       "8                                LFW        Labeled Faces in the Wild   \n",
       "468                          Adience                                    \n",
       "601                        Multi-PIE                                    \n",
       "788                         VGG Face                                    \n",
       "790                    CASIA-WebFace                                    \n",
       "792                      MS-Celeb-1M                                    \n",
       "815                  Extended Yale B                                    \n",
       "955                      Color FERET                      Color FERET   \n",
       "968                    Replay-Mobile                    Replay-Mobile   \n",
       "975                       CASIA-FASD                       CASIA-FASD   \n",
       "995                     Partial-REID                     Partial-REID   \n",
       "1235                       iQIYI-VID                        iQIYI-VID   \n",
       "1237                         KANFace                  KANFace Dataset   \n",
       "1537                      CASIA-SURF                                    \n",
       "1550                    CelebA-Spoof                                    \n",
       "1672                     Curated AFD                             None   \n",
       "1714                             DFW      Disguised Faces in the Wild   \n",
       "1725                        DiveFace                                    \n",
       "1813                        FairFace                                    \n",
       "1957                    iCartoonFace                             None   \n",
       "1977                       IMDb-Face                                    \n",
       "2095                            LSLF         Large-scale Labeled Face   \n",
       "2124                           mEBAL                                    \n",
       "2139                         MeGlass                             None   \n",
       "2414                   QMUL-SurvFace                                    \n",
       "2457                             RFW         Racial Faces in-the-Wild   \n",
       "2467                            RMFD   Real-World Masked Face Dataset   \n",
       "2622                            SWAX         Sense Wax Attack dataset   \n",
       "2732                        UMDFaces                                    \n",
       "2786           WebCaricature Dataset                                    \n",
       "3015                    WildestFaces                                    \n",
       "3016                             FAD          Face Attributes Dataset   \n",
       "3999               CASIA-Face-Africa                                    \n",
       "4231                            IMFW  Indian Masked Faces In The Wild   \n",
       "4285  Extended YouTube Faces (E-YTF)                                    \n",
       "4298                        TinyFace                                    \n",
       "\n",
       "                                               homepage  \\\n",
       "8                      http://vis-www.cs.umass.edu/lfw/   \n",
       "468   https://talhassner.github.io/home/projects/Adi...   \n",
       "601   http://www.cs.cmu.edu/afs/cs/project/PIE/Multi...   \n",
       "788     https://www.robots.ox.ac.uk/~vgg/data/vgg_face/   \n",
       "790                                                       \n",
       "792                                                None   \n",
       "815   http://vision.ucsd.edu/~leekc/ExtYaleDatabase/...   \n",
       "955   https://catalog.data.gov/dataset/color-feret-d...   \n",
       "968          https://www.idiap.ch/dataset/replay-mobile   \n",
       "975         https://pypi.org/project/bob.db.casia-fasd/   \n",
       "995      https://github.com/JDAI-CV/Partial-Person-ReID   \n",
       "1235  http://challenge.ai.iqiyi.com/detail?raceId=5a...   \n",
       "1237      https://sites.google.com/view/kanface-dataset   \n",
       "1537  https://sites.google.com/qq.com/face-anti-spoo...   \n",
       "1550  https://github.com/Davidzhangyuanhan/CelebA-Spoof   \n",
       "1672  https://github.com/vitoralbiero/afd_dataset_cl...   \n",
       "1714           http://iab-rubric.org/resources/dfw.html   \n",
       "1725                https://github.com/BiDAlab/DiveFace   \n",
       "1813                  https://github.com/joojs/fairface   \n",
       "1957  https://github.com/luxiangju-PersonAI/iCartoon...   \n",
       "1977               https://github.com/fwang91/IMDb-Face   \n",
       "2095    http://discovery.cs.wayne.edu/lab_website/lsdl/   \n",
       "2124                   https://github.com/BiDAlab/mEBAL   \n",
       "2139               https://github.com/cleardusk/MeGlass   \n",
       "2414                   https://qmul-survface.github.io/   \n",
       "2457                  http://whdeng.cn/RFW/testing.html   \n",
       "2467  https://github.com/X-zhangyang/Real-World-Mask...   \n",
       "2622  http://smartsenselab.dcc.ufmg.br/en/dataset/sw...   \n",
       "2732                           https://www.umdfaces.io/   \n",
       "2786          http://cs.nju.edu.cn/rl/WebCaricature.htm   \n",
       "3015             https://ycbilge.github.io/wildestFaces   \n",
       "3016               https://arxiv.org/pdf/1605.09062.pdf   \n",
       "3999  http://www.cripacsir.cn/dataset/casia-face-afr...   \n",
       "4231      http://www.iab-rubric.org/resources/imfw.html   \n",
       "4285  https://www.micc.unifi.it/resources/datasets/e...   \n",
       "4298                   https://qmul-tinyface.github.io/   \n",
       "\n",
       "                                            description introduced_date  \\\n",
       "8     The **LFW** dataset contains 13,233 images of ...             NaT   \n",
       "468   The **Adience** dataset, published in 2014, co...      2014-01-01   \n",
       "601   The **Multi-PIE** (Multi Pose, Illumination, E...      2008-01-01   \n",
       "788   The **VGG Face** dataset is face identity reco...      2015-01-01   \n",
       "790   The **CASIA-WebFace** dataset is used for face...      2014-01-01   \n",
       "792   The **MS-Celeb-1M** dataset is a large-scale f...      2016-01-01   \n",
       "815   The **Extended Yale B** database contains 2414...      2001-01-01   \n",
       "955   The color FERET database is a dataset for face...      1997-01-01   \n",
       "968   The **Replay-Mobile** Database for face spoofi...      2016-01-01   \n",
       "975   **CASIA-FASD** is a small face anti-spoofing d...      2012-01-01   \n",
       "995   Partial REID is a specially designed partial p...      2015-01-01   \n",
       "1235  iQIYI-VID dataset, which comprises video clips...      2018-11-19   \n",
       "1237  KANFace consists of 40K still images and 44K s...      2020-05-15   \n",
       "1537  Dataset for face anti-spoofing in terms of bot...             NaT   \n",
       "1550  CelebA-Spoof is a large-scale face anti-spoofi...             NaT   \n",
       "1672  The **Curated AFD** dataset is a curated versi...             NaT   \n",
       "1714  Contains over 11000 images of 1000 identities ...             NaT   \n",
       "1725  A new face annotation dataset with balanced di...             NaT   \n",
       "1813  **FairFace** is a face image dataset which is ...             NaT   \n",
       "1957  The **iCartoonFace** dataset is a large-scale ...             NaT   \n",
       "1977  IMDb-Face is  large-scale noise-controlled dat...             NaT   \n",
       "2095  Consists of a large number of unconstrained mu...             NaT   \n",
       "2124  A multimodal database for eye blink detection ...             NaT   \n",
       "2139  **MeGlass** is an eyeglass dataset originally ...             NaT   \n",
       "2414  **QMUL-SurvFace** is a surveillance face recog...             NaT   \n",
       "2457  To validate the racial bias of four commercial...             NaT   \n",
       "2467  **Real-World Masked Face Dataset** (**RMFD**) ...             NaT   \n",
       "2622  Comprised of real human and wax figure images ...             NaT   \n",
       "2732  UMDFaces is a face dataset divided into two pa...             NaT   \n",
       "2786  Aims to facilitate research in caricature reco...             NaT   \n",
       "3015  WildestFaces is tailored to study cross-domain...      2020-09-16   \n",
       "3016  FAD is a dataset that have roughly 200,000 att...      2016-05-29   \n",
       "3999  **CASIA-Face-Africa** is a face image database...      2021-05-08   \n",
       "4231  Indian Masked faces in the wild Database is co...      2021-06-17   \n",
       "4285  The proposed Extended-YouTube Faces (E-YTF) is...      2018-01-01   \n",
       "4298  **TinyFace** is a large scale face recognition...      2018-11-21   \n",
       "\n",
       "     warning        modalities  languages  \\\n",
       "8       None          [Images]         []   \n",
       "468     None          [Images]         []   \n",
       "601     None          [Images]         []   \n",
       "788     None          [Images]         []   \n",
       "790     None          [Images]         []   \n",
       "792     None          [Images]         []   \n",
       "815     None          [Images]         []   \n",
       "955     None          [Images]         []   \n",
       "968     None  [Images, Videos]         []   \n",
       "975     None          [Images]         []   \n",
       "995     None          [Images]         []   \n",
       "1235    None          [Videos]         []   \n",
       "1237    None          [Images]         []   \n",
       "1537    None                []         []   \n",
       "1550    None          [Images]         []   \n",
       "1672    None          [Images]         []   \n",
       "1714    None          [Images]         []   \n",
       "1725    None                []         []   \n",
       "1813    None          [Images]         []   \n",
       "1957    None          [Images]         []   \n",
       "1977    None          [Images]         []   \n",
       "2095    None          [Images]         []   \n",
       "2124    None                []         []   \n",
       "2139    None          [Images]         []   \n",
       "2414    None                []         []   \n",
       "2457    None                []         []   \n",
       "2467    None          [Images]         []   \n",
       "2622    None          [Images]         []   \n",
       "2732    None          [Images]         []   \n",
       "2786    None                []         []   \n",
       "3015    None          [Images]         []   \n",
       "3016    None          [Images]         []   \n",
       "3999    None          [Images]         []   \n",
       "4231    None          [Images]         []   \n",
       "4285    None  [Images, Videos]  [English]   \n",
       "4298    None          [Images]         []   \n",
       "\n",
       "                                               variants  ...  \\\n",
       "8     [LFW, Labeled Faces in the Wild, LFW (Online O...  ...   \n",
       "468   [Adience, Adience Age, Adience Gender, Adience...  ...   \n",
       "601                                         [Multi-PIE]  ...   \n",
       "788                                          [VGG Face]  ...   \n",
       "790    [WebFace, WebFace - 8x upscaling, CASIA-WebFace]  ...   \n",
       "792                                       [MS-Celeb-1M]  ...   \n",
       "815                  [Extended Yale-B, Extended Yale B]  ...   \n",
       "955        [Color FERET (Online Open Set), Color FERET]  ...   \n",
       "968                      [Replay Mobile, Replay-Mobile]  ...   \n",
       "975                                        [CASIA-FASD]  ...   \n",
       "995                                      [Partial-REID]  ...   \n",
       "1235                                        [iQIYI-VID]  ...   \n",
       "1237                                          [KANFace]  ...   \n",
       "1537                                       [CASIA-SURF]  ...   \n",
       "1550                                     [CelebA-Spoof]  ...   \n",
       "1672                                      [Curated AFD]  ...   \n",
       "1714  [Disguised Faces in the Wild, Disguised Faces ...  ...   \n",
       "1725                                         [DiveFace]  ...   \n",
       "1813                                         [FairFace]  ...   \n",
       "1957                                     [iCartoonFace]  ...   \n",
       "1977                                        [IMDb-Face]  ...   \n",
       "2095                                             [LSLF]  ...   \n",
       "2124                                            [mEBAL]  ...   \n",
       "2139                                          [MeGlass]  ...   \n",
       "2414                                    [QMUL-SurvFace]  ...   \n",
       "2457                                              [RFW]  ...   \n",
       "2467                                             [RMFD]  ...   \n",
       "2622                                             [SWAX]  ...   \n",
       "2732                                         [UMDFaces]  ...   \n",
       "2786                            [WebCaricature Dataset]  ...   \n",
       "3015                                     [WildestFaces]  ...   \n",
       "3016                                              [FAD]  ...   \n",
       "3999                                [CASIA-Face-Africa]  ...   \n",
       "4231                                             [IMFW]  ...   \n",
       "4285                   [Extended YouTube Faces (E-YTF)]  ...   \n",
       "4298                                         [TinyFace]  ...   \n",
       "\n",
       "                                           data_loaders  \\\n",
       "8     [{'url': 'https://www.tensorflow.org/datasets/...   \n",
       "468                                                  []   \n",
       "601                                                  []   \n",
       "788                                                  []   \n",
       "790                                                  []   \n",
       "792                                                  []   \n",
       "815                                                  []   \n",
       "955                                                  []   \n",
       "968                                                  []   \n",
       "975                                                  []   \n",
       "995   [{'url': 'https://github.com/JDAI-CV/Partial-P...   \n",
       "1235                                                 []   \n",
       "1237                                                 []   \n",
       "1537                                                 []   \n",
       "1550  [{'url': 'https://github.com/Davidzhangyuanhan...   \n",
       "1672  [{'url': 'https://github.com/vitoralbiero/afd_...   \n",
       "1714                                                 []   \n",
       "1725  [{'url': 'https://github.com/BiDAlab/DiveFace'...   \n",
       "1813  [{'url': 'https://huggingface.co/datasets/nate...   \n",
       "1957  [{'url': 'https://github.com/luxiangju-PersonA...   \n",
       "1977  [{'url': 'https://github.com/fwang91/IMDb-Face...   \n",
       "2095                                                 []   \n",
       "2124  [{'url': 'https://github.com/BiDAlab/mEBAL', '...   \n",
       "2139  [{'url': 'https://github.com/cleardusk/MeGlass...   \n",
       "2414                                                 []   \n",
       "2457                                                 []   \n",
       "2467  [{'url': 'https://github.com/X-zhangyang/Real-...   \n",
       "2622                                                 []   \n",
       "2732                                                 []   \n",
       "2786                                                 []   \n",
       "3015                                                 []   \n",
       "3016                                                 []   \n",
       "3999                                                 []   \n",
       "4231                                                 []   \n",
       "4285                                                 []   \n",
       "4298                                                 []   \n",
       "\n",
       "                                                  title  \\\n",
       "8     Labeled faces in the wild: A database for stud...   \n",
       "468       Age and Gender Estimation of Unfiltered Faces   \n",
       "601                                           Multi-PIE   \n",
       "788                               Deep Face Recognition   \n",
       "790           Learning Face Representation from Scratch   \n",
       "792   MS-Celeb-1M: A Dataset and Benchmark for Large...   \n",
       "815   From Few to Many: Illumination Cone Models for...   \n",
       "955   The FERET Evaluation Methodology for Face-Reco...   \n",
       "968   The Replay-Mobile Face Presentation-Attack Dat...   \n",
       "975   A face antispoofing database with diverse attacks   \n",
       "995                    Partial Person Re-Identification   \n",
       "1235  iQIYI-VID: A Large Dataset for Multi-modal Per...   \n",
       "1237  Investigating Bias in Deep Face Analysis: The ...   \n",
       "1537  CASIA-SURF: A Large-scale Multi-modal Benchmar...   \n",
       "1550  CelebA-Spoof: Large-Scale Face Anti-Spoofing D...   \n",
       "1672  A Method for Curation of Web-Scraped Face Imag...   \n",
       "1714            Recognizing Disguised Faces in the Wild   \n",
       "1725  SensitiveNets: Learning Agnostic Representatio...   \n",
       "1813  FairFace: Face Attribute Dataset for Balanced ...   \n",
       "1957      Cartoon Face Recognition: A Benchmark Dataset   \n",
       "1977      The Devil of Face Recognition is in the Noise   \n",
       "2095  Large-scale Datasets: Faces with Partial Occlu...   \n",
       "2124  mEBAL: A Multimodal Database for Eye Blink Det...   \n",
       "2139  Face Synthesis for Eyeglass-Robust Face Recogn...   \n",
       "2414            Surveillance Face Recognition Challenge   \n",
       "2457  Racial Faces in-the-Wild: Reducing Racial Bias...   \n",
       "2467    Masked Face Recognition Dataset and Application   \n",
       "2622  The SWAX Benchmark: Attacking Biometric System...   \n",
       "2732  UMDFaces: An Annotated Face Dataset for Traini...   \n",
       "2786  WebCaricature: a benchmark for caricature reco...   \n",
       "3015  Red Carpet to Fight Club: Partially-supervised...   \n",
       "3016  Predicting Personal Traits from Facial Images ...   \n",
       "3999  CASIA-Face-Africa: A Large-scale African Face ...   \n",
       "4231            Indian Masked Faces in the Wild Dataset   \n",
       "4285  Additional Baseline Metrics for the paper \"Ext...   \n",
       "4298                    Low-Resolution Face Recognition   \n",
       "\n",
       "                                              paper_url  Texts  Images  \\\n",
       "8               http://vis-www.cs.umass.edu/lfw/lfw.pdf  False    True   \n",
       "468           https://doi.org/10.1109/TIFS.2014.2359646  False    True   \n",
       "601           https://doi.org/10.1109/AFGR.2008.4813399  False    True   \n",
       "788                     https://doi.org/10.5244/C.29.41  False    True   \n",
       "790   https://paperswithcode.com/paper/learning-face...  False    True   \n",
       "792   https://paperswithcode.com/paper/ms-celeb-1m-a...  False    True   \n",
       "815                   https://doi.org/10.1109/34.927464  False    True   \n",
       "955            https://doi.org/10.1109/CVPR.1997.609311  False    True   \n",
       "968         https://doi.org/10.1109/BIOSIG.2016.7736936  False    True   \n",
       "975            https://doi.org/10.1109/ICB.2012.6199754  False    True   \n",
       "995   https://paperswithcode.com/paper/partial-perso...  False    True   \n",
       "1235  https://paperswithcode.com/paper/iqiyi-vid-a-l...  False   False   \n",
       "1237  https://paperswithcode.com/paper/investigating...  False    True   \n",
       "1537  https://paperswithcode.com/paper/casia-surf-a-...  False   False   \n",
       "1550  https://paperswithcode.com/paper/celeba-spoof-...  False    True   \n",
       "1672  https://paperswithcode.com/paper/a-method-for-...  False    True   \n",
       "1714  https://paperswithcode.com/paper/recognizing-d...  False    True   \n",
       "1725  https://paperswithcode.com/paper/sensitivenets...  False   False   \n",
       "1813  https://paperswithcode.com/paper/fairface-face...  False    True   \n",
       "1957  https://paperswithcode.com/paper/icartoonface-...  False    True   \n",
       "1977  https://paperswithcode.com/paper/the-devil-of-...  False    True   \n",
       "2095  https://paperswithcode.com/paper/large-scale-d...  False    True   \n",
       "2124  https://paperswithcode.com/paper/mebal-a-multi...  False   False   \n",
       "2139  https://paperswithcode.com/paper/face-synthesi...  False    True   \n",
       "2414  https://paperswithcode.com/paper/surveillance-...  False   False   \n",
       "2457  https://paperswithcode.com/paper/racial-faces-...  False   False   \n",
       "2467  https://paperswithcode.com/paper/masked-face-r...  False    True   \n",
       "2622  https://paperswithcode.com/paper/the-swax-benc...  False    True   \n",
       "2732  https://paperswithcode.com/paper/umdfaces-an-a...  False    True   \n",
       "2786  https://paperswithcode.com/paper/webcaricature...  False   False   \n",
       "3015  https://paperswithcode.com/paper/red-carpet-to...  False    True   \n",
       "3016  https://paperswithcode.com/paper/predicting-pe...  False    True   \n",
       "3999  https://paperswithcode.com/paper/casia-face-af...  False    True   \n",
       "4231  https://paperswithcode.com/paper/indian-masked...  False    True   \n",
       "4285  https://paperswithcode.com/paper/additional-ba...  False    True   \n",
       "4298  https://paperswithcode.com/paper/low-resolutio...  False    True   \n",
       "\n",
       "                                          dataset_tasks  \\\n",
       "8     [3D FACE MODELING, Face Verification, Face Rec...   \n",
       "468   [Face Recognition, Age And Gender Classificati...   \n",
       "601   [Single-Image Portrait Relighting, Face Recogn...   \n",
       "788   [Domain Adaptation, Face Verification, Face Re...   \n",
       "790   [Image Super-Resolution, Face Verification, Fa...   \n",
       "792   [Face Verification, Face Recognition, Face Ide...   \n",
       "815   [Image Classification, Image Clustering, Face ...   \n",
       "955                                  [Face Recognition]   \n",
       "968   [Face Recognition, Face Anti-Spoofing, Face Pr...   \n",
       "975   [Anomaly Detection, Face Recognition, Face Ant...   \n",
       "995   [Person Re-Identification, Face Recognition, D...   \n",
       "1235  [Person Re-Identification, Face Recognition, P...   \n",
       "1237       [Face Recognition, Age Estimation, Fairness]   \n",
       "1537  [Face Recognition, Face Anti-Spoofing, Face Pr...   \n",
       "1550             [Face Recognition, Face Anti-Spoofing]   \n",
       "1672                                 [Face Recognition]   \n",
       "1714  [Face Recognition, Heterogeneous Face Recognit...   \n",
       "1725                       [Face Recognition, Fairness]   \n",
       "1813  [Face Recognition, Facial Attribute Classifica...   \n",
       "1957  [Image Classification, Face Recognition, Perso...   \n",
       "1977            [Face Recognition, Curriculum Learning]   \n",
       "2095                 [Face Recognition, Face Detection]   \n",
       "2124        [Face Recognition, EEG, Face Anti-Spoofing]   \n",
       "2139  [Face Recognition, Robust Face Recognition, Fa...   \n",
       "2414   [Super-Resolution, Face Recognition, Deblurring]   \n",
       "2457    [Face Verification, Face Recognition, Fairness]   \n",
       "2467                 [Face Recognition, Face Detection]   \n",
       "2622  [Face Recognition, Face Anti-Spoofing, Face Pr...   \n",
       "2732  [Face Verification, Face Recognition, Face Det...   \n",
       "2786     [Face Recognition, Style Transfer, Caricature]   \n",
       "3015                                 [Face Recognition]   \n",
       "3016  [Face Recognition, Face Detection, Physical At...   \n",
       "3999  [Face Recognition, Facial Landmark Detection, ...   \n",
       "4231                                 [Face Recognition]   \n",
       "4285              [Face Verification, Face Recognition]   \n",
       "4298                                 [Face Recognition]   \n",
       "\n",
       "                                  dataset_tasks_parents  \\\n",
       "8     [3D, Facial Recognition and Modelling, 3D, Fac...   \n",
       "468   [Facial Recognition and Modelling, Facial Reco...   \n",
       "601                  [Facial Recognition and Modelling]   \n",
       "788   [Facial Recognition and Modelling, 3D, Facial ...   \n",
       "790   [Super-Resolution, Facial Recognition and Mode...   \n",
       "792   [Facial Recognition and Modelling, 3D, Facial ...   \n",
       "815                  [Facial Recognition and Modelling]   \n",
       "955                  [Facial Recognition and Modelling]   \n",
       "968   [Facial Recognition and Modelling, Facial Reco...   \n",
       "975   [Facial Recognition and Modelling, Facial Reco...   \n",
       "995                  [Facial Recognition and Modelling]   \n",
       "1235                 [Facial Recognition and Modelling]   \n",
       "1237  [Facial Recognition and Modelling, Facial Reco...   \n",
       "1537  [Facial Recognition and Modelling, Facial Reco...   \n",
       "1550  [Facial Recognition and Modelling, Facial Reco...   \n",
       "1672                 [Facial Recognition and Modelling]   \n",
       "1714  [Facial Recognition and Modelling, Facial Reco...   \n",
       "1725                 [Facial Recognition and Modelling]   \n",
       "1813  [Facial Recognition and Modelling, Facial Reco...   \n",
       "1957                 [Facial Recognition and Modelling]   \n",
       "1977  [Facial Recognition and Modelling, General Rei...   \n",
       "2095  [Facial Recognition and Modelling, Facial Reco...   \n",
       "2124  [Facial Recognition and Modelling, Facial Reco...   \n",
       "2139  [Facial Recognition and Modelling, Facial Reco...   \n",
       "2414                 [Facial Recognition and Modelling]   \n",
       "2457  [Facial Recognition and Modelling, 3D, Facial ...   \n",
       "2467  [Facial Recognition and Modelling, Facial Reco...   \n",
       "2622  [Facial Recognition and Modelling, Facial Reco...   \n",
       "2732  [Facial Recognition and Modelling, 3D, Facial ...   \n",
       "2786                 [Facial Recognition and Modelling]   \n",
       "3015                 [Facial Recognition and Modelling]   \n",
       "3016  [Facial Recognition and Modelling, Facial Reco...   \n",
       "3999  [Facial Recognition and Modelling, Facial Reco...   \n",
       "4231                 [Facial Recognition and Modelling]   \n",
       "4285  [Facial Recognition and Modelling, 3D, Facial ...   \n",
       "4298                 [Facial Recognition and Modelling]   \n",
       "\n",
       "                               dataset_tasks_categories  \\\n",
       "8     [Computer Vision, Computer Vision, Computer Vi...   \n",
       "468                                   [Computer Vision]   \n",
       "601                    [Computer Code, Computer Vision]   \n",
       "788   [Computer Vision, Methodology, Computer Vision...   \n",
       "790   [Audio, Computer Vision, Computer Vision, Comp...   \n",
       "792                  [Computer Vision, Computer Vision]   \n",
       "815   [Computer Vision, Methodology, Computer Vision...   \n",
       "955                                   [Computer Vision]   \n",
       "968                                   [Computer Vision]   \n",
       "975   [Miscellaneous, Computer Vision, Speech, Metho...   \n",
       "995     [Computer Vision, Computer Vision, Methodology]   \n",
       "1235  [Computer Vision, Computer Vision, Computer Vi...   \n",
       "1237  [Computer Vision, Computer Vision, Miscellaneous]   \n",
       "1537                                  [Computer Vision]   \n",
       "1550                                  [Computer Vision]   \n",
       "1672                                  [Computer Vision]   \n",
       "1714                                  [Computer Vision]   \n",
       "1725  [Computer Vision, Computer Vision, Miscellaneous]   \n",
       "1813  [Computer Vision, Reasoning, Computer Vision, ...   \n",
       "1957  [Computer Vision, Methodology, Computer Vision...   \n",
       "1977                                  [Computer Vision]   \n",
       "2095                 [Computer Vision, Computer Vision]   \n",
       "2124        [Computer Vision, Time Series, Methodology]   \n",
       "2139                 [Computer Vision, Computer Vision]   \n",
       "2414  [Graphs, Computer Vision, Computer Vision, Com...   \n",
       "2457  [Computer Vision, Computer Vision, Computer Vi...   \n",
       "2467                 [Computer Vision, Computer Vision]   \n",
       "2622                                  [Computer Vision]   \n",
       "2732  [Computer Vision, Computer Vision, Computer Vi...   \n",
       "2786  [Computer Vision, Computer Vision, Computer Vi...   \n",
       "3015                                  [Computer Vision]   \n",
       "3016  [Computer Vision, Computer Vision, Computer Vi...   \n",
       "3999  [Computer Vision, Computer Vision, Computer Vi...   \n",
       "4231                                  [Computer Vision]   \n",
       "4285                 [Computer Vision, Computer Vision]   \n",
       "4298                                  [Computer Vision]   \n",
       "\n",
       "                                 dataset_tasks_children  \\\n",
       "8     [Facial Recognition and Modelling, Disguised F...   \n",
       "468   [Age-Invariant Face Recognition, Face Quality ...   \n",
       "601   [Age-Invariant Face Recognition, Face Quality ...   \n",
       "788   [Unsupervised Domain Adaptation, Domain Genera...   \n",
       "790   [Multi-Frame Super-Resolution, Audio Super-Res...   \n",
       "792   [Disguised Face Verification, Age-Invariant Fa...   \n",
       "815   [Few-Shot Image Classification, Fine-Grained I...   \n",
       "955   [Age-Invariant Face Recognition, Face Quality ...   \n",
       "968   [Age-Invariant Face Recognition, Face Quality ...   \n",
       "975   [Unsupervised Anomaly Detection, Anomaly Detec...   \n",
       "995   [Unsupervised Person Re-Identification, Video-...   \n",
       "1235  [Unsupervised Person Re-Identification, Video-...   \n",
       "1237  [Age-Invariant Face Recognition, Face Quality ...   \n",
       "1537  [Age-Invariant Face Recognition, Face Quality ...   \n",
       "1550  [Age-Invariant Face Recognition, Face Quality ...   \n",
       "1672  [Age-Invariant Face Recognition, Face Quality ...   \n",
       "1714  [Age-Invariant Face Recognition, Face Quality ...   \n",
       "1725  [Age-Invariant Face Recognition, Face Quality ...   \n",
       "1813  [Age-Invariant Face Recognition, Face Quality ...   \n",
       "1957  [Few-Shot Image Classification, Fine-Grained I...   \n",
       "1977  [Age-Invariant Face Recognition, Face Quality ...   \n",
       "2095  [Age-Invariant Face Recognition, Face Quality ...   \n",
       "2124  [Age-Invariant Face Recognition, Face Quality ...   \n",
       "2139  [Age-Invariant Face Recognition, Face Quality ...   \n",
       "2414  [Image Super-Resolution, Video Super-Resolutio...   \n",
       "2457  [Disguised Face Verification, Age-Invariant Fa...   \n",
       "2467  [Age-Invariant Face Recognition, Face Quality ...   \n",
       "2622  [Age-Invariant Face Recognition, Face Quality ...   \n",
       "2732  [Disguised Face Verification, Age-Invariant Fa...   \n",
       "2786  [Age-Invariant Face Recognition, Face Quality ...   \n",
       "3015  [Age-Invariant Face Recognition, Face Quality ...   \n",
       "3016  [Age-Invariant Face Recognition, Face Quality ...   \n",
       "3999  [Age-Invariant Face Recognition, Face Quality ...   \n",
       "4231  [Age-Invariant Face Recognition, Face Quality ...   \n",
       "4285  [Disguised Face Verification, Age-Invariant Fa...   \n",
       "4298  [Age-Invariant Face Recognition, Face Quality ...   \n",
       "\n",
       "                                 dataset_tasks_siblings  \n",
       "8     [Video Reconstruction, 3D Shape Generation, 3D...  \n",
       "468   [Facial Inpainting, Action Unit Detection, Fac...  \n",
       "601   [Facial Inpainting, Action Unit Detection, Fac...  \n",
       "788   [Facial Inpainting, Video Reconstruction, Acti...  \n",
       "790   [Depth Map Super-Resolution, Image Super-Resol...  \n",
       "792   [Facial Inpainting, Video Reconstruction, Acti...  \n",
       "815   [Facial Inpainting, Action Unit Detection, Fac...  \n",
       "955   [Facial Inpainting, Action Unit Detection, Fac...  \n",
       "968   [Facial Inpainting, Action Unit Detection, Fac...  \n",
       "975   [Facial Inpainting, Action Unit Detection, Fac...  \n",
       "995   [Facial Inpainting, Action Unit Detection, Fac...  \n",
       "1235  [Facial Inpainting, Action Unit Detection, Fac...  \n",
       "1237  [Facial Inpainting, Action Unit Detection, Fac...  \n",
       "1537  [Facial Inpainting, Action Unit Detection, Fac...  \n",
       "1550  [Facial Inpainting, Action Unit Detection, Fac...  \n",
       "1672  [Facial Inpainting, Action Unit Detection, Fac...  \n",
       "1714  [Facial Inpainting, Action Unit Detection, Fac...  \n",
       "1725  [Facial Inpainting, Action Unit Detection, Fac...  \n",
       "1813  [Facial Inpainting, Action Unit Detection, Fac...  \n",
       "1957  [Facial Inpainting, Action Unit Detection, Fac...  \n",
       "1977  [Facial Inpainting, Action Unit Detection, Fac...  \n",
       "2095  [Facial Inpainting, Action Unit Detection, Fac...  \n",
       "2124  [Facial Inpainting, Action Unit Detection, Fac...  \n",
       "2139  [Facial Inpainting, Action Unit Detection, Fac...  \n",
       "2414  [Facial Inpainting, Action Unit Detection, Fac...  \n",
       "2457  [Facial Inpainting, Video Reconstruction, Acti...  \n",
       "2467  [Facial Inpainting, Action Unit Detection, Fac...  \n",
       "2622  [Facial Inpainting, Action Unit Detection, Fac...  \n",
       "2732  [Facial Inpainting, Video Reconstruction, Acti...  \n",
       "2786  [Facial Inpainting, Action Unit Detection, Fac...  \n",
       "3015  [Facial Inpainting, Action Unit Detection, Fac...  \n",
       "3016  [Facial Inpainting, Action Unit Detection, Fac...  \n",
       "3999  [Facial Inpainting, Action Unit Detection, Fac...  \n",
       "4231  [Facial Inpainting, Action Unit Detection, Fac...  \n",
       "4285  [Facial Inpainting, Video Reconstruction, Acti...  \n",
       "4298  [Facial Inpainting, Action Unit Detection, Fac...  \n",
       "\n",
       "[36 rows x 21 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[datasets.dataset_tasks.apply(lambda x: \"Face Recognition\" in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "34a6bc94-cdbf-4220-8b81-75d8d66ac263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [Object Recognition, Image Classification, Obj...\n",
       "1            [Object Recognition, Image Classification]\n",
       "2     [Handwriting Recognition, Optical Character Re...\n",
       "3            [Object Recognition, Image Classification]\n",
       "4     [Stereo Matching, Optical Flow Estimation, Vis...\n",
       "5     [Optical Character Recognition, Image Classifi...\n",
       "6     [Face Detection, Facial Attribute Classification]\n",
       "7     [Image Classification, Fine-Grained Image Clas...\n",
       "8                              [Part-Of-Speech Tagging]\n",
       "9            [Object Recognition, Image Classification]\n",
       "10                                 [Speech Recognition]\n",
       "11                                 [Sentiment Analysis]\n",
       "12                                  [Face Verification]\n",
       "13                             [Reinforcement Learning]\n",
       "14                                 [Action Recognition]\n",
       "15                                 [Continuous Control]\n",
       "16                                [Node Classification]\n",
       "17                             [Recommendation Systems]\n",
       "18             [Image Segmentation, Boundary Detection]\n",
       "19                                  [Scene Recognition]\n",
       "20        [Instance Segmentation, Image Classification]\n",
       "21    [Image Recognition, Semi-supervised Image Clas...\n",
       "22                      [Few-Shot Image Classification]\n",
       "23                                  [Domain Adaptation]\n",
       "24                                    [Object Tracking]\n",
       "25                                            [Medical]\n",
       "28    [Scene Understanding, Scene Classification, Ob...\n",
       "29                             [Image Super-Resolution]\n",
       "30                                   [Semantic parsing]\n",
       "31                                 [Object Recognition]\n",
       "33                                   [Face Recognition]\n",
       "34                             [Visual Object Tracking]\n",
       "35    [Optical Character Recognition, Handwriting Re...\n",
       "36                                 [Object Recognition]\n",
       "37                                [Node Classification]\n",
       "38                  [Fine-Grained Image Classification]\n",
       "39    [Emotion Recognition, Multimodal Emotion Recog...\n",
       "40                             [Speaker Identification]\n",
       "41    [Paraphrase Identification, Paraphrase Generat...\n",
       "42             [Object Recognition, Zero-Shot Learning]\n",
       "43      [Action Recognition, Temporal Action Detection]\n",
       "44                             [Image Super-Resolution]\n",
       "46                 [Sentiment Analysis, Opinion Mining]\n",
       "47              [Image Classification, Image Retrieval]\n",
       "48                                [Text Categorization]\n",
       "Name: Proposed Tasks, dtype: object"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_dict=manual_task_labels[['name','Proposed Tasks']]\n",
    "#manual_dict=manual_dict.set_index('name').to_dict()['Proposed Tasks']\n",
    "manual_dict['Proposed Tasks'].apply(lambda x: [j.strip() for j in x.split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "18f6206a-940f-4636-8e55-e3f874614016",
   "metadata": {},
   "outputs": [],
   "source": [
    "res=datasets.loc[datasets['name']==row['name'],'dataset_tasks'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9df68619-7488-403c-8916-7cbc0c415bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    SHIT\n",
       "Name: dataset_tasks, dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.loc[datasets['name']==row['name'],'dataset_tasks']=\"SHIT\"\n",
    "datasets.loc[datasets['name']==row['name'],'dataset_tasks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c121aebb-56d0-406b-aae9-d18a6f43b9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1d7e5a9970>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "dataset_citing_papers_pwc=dataset_citing_papers_pwc[dataset_citing_papers_pwc['all_parents'].apply(lambda x: len(x)<=1)]\n",
    "\n",
    "(dataset_citing_papers_pwc['parents'].apply(lambda x: len(x))).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "afbebcb6-56b7-408a-8f2e-12a956012628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>pwc_dataset_id</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>is_problematic</th>\n",
       "      <th>paper_count</th>\n",
       "      <th>task</th>\n",
       "      <th>categories</th>\n",
       "      <th>parents</th>\n",
       "      <th>children</th>\n",
       "      <th>siblings</th>\n",
       "      <th>pdf_url</th>\n",
       "      <th>paper_url</th>\n",
       "      <th>all_tasks</th>\n",
       "      <th>all_parents</th>\n",
       "      <th>all_children</th>\n",
       "      <th>all_siblings</th>\n",
       "      <th>all_categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2052</th>\n",
       "      <td>MNIST</td>\n",
       "      <td>1</td>\n",
       "      <td>InfoGAN: Interpretable Representation Learning...</td>\n",
       "      <td>2016-06-12</td>\n",
       "      <td>False</td>\n",
       "      <td>4159</td>\n",
       "      <td>Image Generation</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[3D Face Animation]</td>\n",
       "      <td>[Image-to-Image Translation, Image Inpainting,...</td>\n",
       "      <td>[Image Generation, Image Animation, Dialogue G...</td>\n",
       "      <td>http://arxiv.org/pdf/1606.03657v1.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/infogan-inter...</td>\n",
       "      <td>[Image Generation, Representation Learning, Un...</td>\n",
       "      <td>[Image Classification, 3D Face Animation, Unsu...</td>\n",
       "      <td>[Graph Representation Learning, Learning Repre...</td>\n",
       "      <td>[Hyperspectral Image Classification, Artist cl...</td>\n",
       "      <td>[Computer Vision, Methodology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2053</th>\n",
       "      <td>MNIST</td>\n",
       "      <td>1</td>\n",
       "      <td>InfoGAN: Interpretable Representation Learning...</td>\n",
       "      <td>2016-06-12</td>\n",
       "      <td>False</td>\n",
       "      <td>4159</td>\n",
       "      <td>Representation Learning</td>\n",
       "      <td>[Methodology]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Word Embeddings, Graph Embedding, Graph Repre...</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://arxiv.org/pdf/1606.03657v1.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/infogan-inter...</td>\n",
       "      <td>[Image Generation, Representation Learning, Un...</td>\n",
       "      <td>[Image Classification, 3D Face Animation, Unsu...</td>\n",
       "      <td>[Graph Representation Learning, Learning Repre...</td>\n",
       "      <td>[Hyperspectral Image Classification, Artist cl...</td>\n",
       "      <td>[Computer Vision, Methodology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>MNIST</td>\n",
       "      <td>1</td>\n",
       "      <td>InfoGAN: Interpretable Representation Learning...</td>\n",
       "      <td>2016-06-12</td>\n",
       "      <td>False</td>\n",
       "      <td>4159</td>\n",
       "      <td>Unsupervised Image Classification</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Image Classification]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Hyperspectral Image Classification, Artist cl...</td>\n",
       "      <td>http://arxiv.org/pdf/1606.03657v1.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/infogan-inter...</td>\n",
       "      <td>[Image Generation, Representation Learning, Un...</td>\n",
       "      <td>[Image Classification, 3D Face Animation, Unsu...</td>\n",
       "      <td>[Graph Representation Learning, Learning Repre...</td>\n",
       "      <td>[Hyperspectral Image Classification, Artist cl...</td>\n",
       "      <td>[Computer Vision, Methodology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>MNIST</td>\n",
       "      <td>1</td>\n",
       "      <td>InfoGAN: Interpretable Representation Learning...</td>\n",
       "      <td>2016-06-12</td>\n",
       "      <td>False</td>\n",
       "      <td>4159</td>\n",
       "      <td>Unsupervised MNIST</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Unsupervised Representation Learning]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Acoustic Unit Discovery, Unsupervised MNIST]</td>\n",
       "      <td>http://arxiv.org/pdf/1606.03657v1.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/infogan-inter...</td>\n",
       "      <td>[Image Generation, Representation Learning, Un...</td>\n",
       "      <td>[Image Classification, 3D Face Animation, Unsu...</td>\n",
       "      <td>[Graph Representation Learning, Learning Repre...</td>\n",
       "      <td>[Hyperspectral Image Classification, Artist cl...</td>\n",
       "      <td>[Computer Vision, Methodology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>CUB-200-2011</td>\n",
       "      <td>109</td>\n",
       "      <td>InfoGAN: Interpretable Representation Learning...</td>\n",
       "      <td>2016-06-12</td>\n",
       "      <td>False</td>\n",
       "      <td>920</td>\n",
       "      <td>Image Generation</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[3D Face Animation]</td>\n",
       "      <td>[Image-to-Image Translation, Image Inpainting,...</td>\n",
       "      <td>[Image Generation, Image Animation, Dialogue G...</td>\n",
       "      <td>http://arxiv.org/pdf/1606.03657v1.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/infogan-inter...</td>\n",
       "      <td>[Image Generation, Representation Learning, Un...</td>\n",
       "      <td>[Image Classification, 3D Face Animation, Unsu...</td>\n",
       "      <td>[Graph Representation Learning, Learning Repre...</td>\n",
       "      <td>[Hyperspectral Image Classification, Artist cl...</td>\n",
       "      <td>[Computer Vision, Methodology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>CUB-200-2011</td>\n",
       "      <td>109</td>\n",
       "      <td>InfoGAN: Interpretable Representation Learning...</td>\n",
       "      <td>2016-06-12</td>\n",
       "      <td>False</td>\n",
       "      <td>920</td>\n",
       "      <td>Representation Learning</td>\n",
       "      <td>[Methodology]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Word Embeddings, Graph Embedding, Graph Repre...</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://arxiv.org/pdf/1606.03657v1.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/infogan-inter...</td>\n",
       "      <td>[Image Generation, Representation Learning, Un...</td>\n",
       "      <td>[Image Classification, 3D Face Animation, Unsu...</td>\n",
       "      <td>[Graph Representation Learning, Learning Repre...</td>\n",
       "      <td>[Hyperspectral Image Classification, Artist cl...</td>\n",
       "      <td>[Computer Vision, Methodology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>CUB-200-2011</td>\n",
       "      <td>109</td>\n",
       "      <td>InfoGAN: Interpretable Representation Learning...</td>\n",
       "      <td>2016-06-12</td>\n",
       "      <td>False</td>\n",
       "      <td>920</td>\n",
       "      <td>Unsupervised Image Classification</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Image Classification]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Hyperspectral Image Classification, Artist cl...</td>\n",
       "      <td>http://arxiv.org/pdf/1606.03657v1.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/infogan-inter...</td>\n",
       "      <td>[Image Generation, Representation Learning, Un...</td>\n",
       "      <td>[Image Classification, 3D Face Animation, Unsu...</td>\n",
       "      <td>[Graph Representation Learning, Learning Repre...</td>\n",
       "      <td>[Hyperspectral Image Classification, Artist cl...</td>\n",
       "      <td>[Computer Vision, Methodology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>CUB-200-2011</td>\n",
       "      <td>109</td>\n",
       "      <td>InfoGAN: Interpretable Representation Learning...</td>\n",
       "      <td>2016-06-12</td>\n",
       "      <td>False</td>\n",
       "      <td>920</td>\n",
       "      <td>Unsupervised MNIST</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Unsupervised Representation Learning]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Acoustic Unit Discovery, Unsupervised MNIST]</td>\n",
       "      <td>http://arxiv.org/pdf/1606.03657v1.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/infogan-inter...</td>\n",
       "      <td>[Image Generation, Representation Learning, Un...</td>\n",
       "      <td>[Image Classification, 3D Face Animation, Unsu...</td>\n",
       "      <td>[Graph Representation Learning, Learning Repre...</td>\n",
       "      <td>[Hyperspectral Image Classification, Artist cl...</td>\n",
       "      <td>[Computer Vision, Methodology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>Stanford Cars</td>\n",
       "      <td>573</td>\n",
       "      <td>InfoGAN: Interpretable Representation Learning...</td>\n",
       "      <td>2016-06-12</td>\n",
       "      <td>False</td>\n",
       "      <td>198</td>\n",
       "      <td>Image Generation</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[3D Face Animation]</td>\n",
       "      <td>[Image-to-Image Translation, Image Inpainting,...</td>\n",
       "      <td>[Image Generation, Image Animation, Dialogue G...</td>\n",
       "      <td>http://arxiv.org/pdf/1606.03657v1.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/infogan-inter...</td>\n",
       "      <td>[Image Generation, Representation Learning, Un...</td>\n",
       "      <td>[Image Classification, 3D Face Animation, Unsu...</td>\n",
       "      <td>[Graph Representation Learning, Learning Repre...</td>\n",
       "      <td>[Hyperspectral Image Classification, Artist cl...</td>\n",
       "      <td>[Computer Vision, Methodology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>Stanford Cars</td>\n",
       "      <td>573</td>\n",
       "      <td>InfoGAN: Interpretable Representation Learning...</td>\n",
       "      <td>2016-06-12</td>\n",
       "      <td>False</td>\n",
       "      <td>198</td>\n",
       "      <td>Representation Learning</td>\n",
       "      <td>[Methodology]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Word Embeddings, Graph Embedding, Graph Repre...</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://arxiv.org/pdf/1606.03657v1.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/infogan-inter...</td>\n",
       "      <td>[Image Generation, Representation Learning, Un...</td>\n",
       "      <td>[Image Classification, 3D Face Animation, Unsu...</td>\n",
       "      <td>[Graph Representation Learning, Learning Repre...</td>\n",
       "      <td>[Hyperspectral Image Classification, Artist cl...</td>\n",
       "      <td>[Computer Vision, Methodology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2062</th>\n",
       "      <td>Stanford Cars</td>\n",
       "      <td>573</td>\n",
       "      <td>InfoGAN: Interpretable Representation Learning...</td>\n",
       "      <td>2016-06-12</td>\n",
       "      <td>False</td>\n",
       "      <td>198</td>\n",
       "      <td>Unsupervised Image Classification</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Image Classification]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Hyperspectral Image Classification, Artist cl...</td>\n",
       "      <td>http://arxiv.org/pdf/1606.03657v1.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/infogan-inter...</td>\n",
       "      <td>[Image Generation, Representation Learning, Un...</td>\n",
       "      <td>[Image Classification, 3D Face Animation, Unsu...</td>\n",
       "      <td>[Graph Representation Learning, Learning Repre...</td>\n",
       "      <td>[Hyperspectral Image Classification, Artist cl...</td>\n",
       "      <td>[Computer Vision, Methodology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063</th>\n",
       "      <td>Stanford Cars</td>\n",
       "      <td>573</td>\n",
       "      <td>InfoGAN: Interpretable Representation Learning...</td>\n",
       "      <td>2016-06-12</td>\n",
       "      <td>False</td>\n",
       "      <td>198</td>\n",
       "      <td>Unsupervised MNIST</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Unsupervised Representation Learning]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Acoustic Unit Discovery, Unsupervised MNIST]</td>\n",
       "      <td>http://arxiv.org/pdf/1606.03657v1.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/infogan-inter...</td>\n",
       "      <td>[Image Generation, Representation Learning, Un...</td>\n",
       "      <td>[Image Classification, 3D Face Animation, Unsu...</td>\n",
       "      <td>[Graph Representation Learning, Learning Repre...</td>\n",
       "      <td>[Hyperspectral Image Classification, Artist cl...</td>\n",
       "      <td>[Computer Vision, Methodology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2064</th>\n",
       "      <td>Stanford Dogs</td>\n",
       "      <td>577</td>\n",
       "      <td>InfoGAN: Interpretable Representation Learning...</td>\n",
       "      <td>2016-06-12</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>Image Generation</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[3D Face Animation]</td>\n",
       "      <td>[Image-to-Image Translation, Image Inpainting,...</td>\n",
       "      <td>[Image Generation, Image Animation, Dialogue G...</td>\n",
       "      <td>http://arxiv.org/pdf/1606.03657v1.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/infogan-inter...</td>\n",
       "      <td>[Image Generation, Representation Learning, Un...</td>\n",
       "      <td>[Image Classification, 3D Face Animation, Unsu...</td>\n",
       "      <td>[Graph Representation Learning, Learning Repre...</td>\n",
       "      <td>[Hyperspectral Image Classification, Artist cl...</td>\n",
       "      <td>[Computer Vision, Methodology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065</th>\n",
       "      <td>Stanford Dogs</td>\n",
       "      <td>577</td>\n",
       "      <td>InfoGAN: Interpretable Representation Learning...</td>\n",
       "      <td>2016-06-12</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>Representation Learning</td>\n",
       "      <td>[Methodology]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Word Embeddings, Graph Embedding, Graph Repre...</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://arxiv.org/pdf/1606.03657v1.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/infogan-inter...</td>\n",
       "      <td>[Image Generation, Representation Learning, Un...</td>\n",
       "      <td>[Image Classification, 3D Face Animation, Unsu...</td>\n",
       "      <td>[Graph Representation Learning, Learning Repre...</td>\n",
       "      <td>[Hyperspectral Image Classification, Artist cl...</td>\n",
       "      <td>[Computer Vision, Methodology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>Stanford Dogs</td>\n",
       "      <td>577</td>\n",
       "      <td>InfoGAN: Interpretable Representation Learning...</td>\n",
       "      <td>2016-06-12</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>Unsupervised Image Classification</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Image Classification]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Hyperspectral Image Classification, Artist cl...</td>\n",
       "      <td>http://arxiv.org/pdf/1606.03657v1.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/infogan-inter...</td>\n",
       "      <td>[Image Generation, Representation Learning, Un...</td>\n",
       "      <td>[Image Classification, 3D Face Animation, Unsu...</td>\n",
       "      <td>[Graph Representation Learning, Learning Repre...</td>\n",
       "      <td>[Hyperspectral Image Classification, Artist cl...</td>\n",
       "      <td>[Computer Vision, Methodology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>Stanford Dogs</td>\n",
       "      <td>577</td>\n",
       "      <td>InfoGAN: Interpretable Representation Learning...</td>\n",
       "      <td>2016-06-12</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>Unsupervised MNIST</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Unsupervised Representation Learning]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Acoustic Unit Discovery, Unsupervised MNIST]</td>\n",
       "      <td>http://arxiv.org/pdf/1606.03657v1.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/infogan-inter...</td>\n",
       "      <td>[Image Generation, Representation Learning, Un...</td>\n",
       "      <td>[Image Classification, 3D Face Animation, Unsu...</td>\n",
       "      <td>[Graph Representation Learning, Learning Repre...</td>\n",
       "      <td>[Hyperspectral Image Classification, Artist cl...</td>\n",
       "      <td>[Computer Vision, Methodology]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name  pwc_dataset_id  \\\n",
       "2052          MNIST               1   \n",
       "2053          MNIST               1   \n",
       "2054          MNIST               1   \n",
       "2055          MNIST               1   \n",
       "2056   CUB-200-2011             109   \n",
       "2057   CUB-200-2011             109   \n",
       "2058   CUB-200-2011             109   \n",
       "2059   CUB-200-2011             109   \n",
       "2060  Stanford Cars             573   \n",
       "2061  Stanford Cars             573   \n",
       "2062  Stanford Cars             573   \n",
       "2063  Stanford Cars             573   \n",
       "2064  Stanford Dogs             577   \n",
       "2065  Stanford Dogs             577   \n",
       "2066  Stanford Dogs             577   \n",
       "2067  Stanford Dogs             577   \n",
       "\n",
       "                                                  title       date  \\\n",
       "2052  InfoGAN: Interpretable Representation Learning... 2016-06-12   \n",
       "2053  InfoGAN: Interpretable Representation Learning... 2016-06-12   \n",
       "2054  InfoGAN: Interpretable Representation Learning... 2016-06-12   \n",
       "2055  InfoGAN: Interpretable Representation Learning... 2016-06-12   \n",
       "2056  InfoGAN: Interpretable Representation Learning... 2016-06-12   \n",
       "2057  InfoGAN: Interpretable Representation Learning... 2016-06-12   \n",
       "2058  InfoGAN: Interpretable Representation Learning... 2016-06-12   \n",
       "2059  InfoGAN: Interpretable Representation Learning... 2016-06-12   \n",
       "2060  InfoGAN: Interpretable Representation Learning... 2016-06-12   \n",
       "2061  InfoGAN: Interpretable Representation Learning... 2016-06-12   \n",
       "2062  InfoGAN: Interpretable Representation Learning... 2016-06-12   \n",
       "2063  InfoGAN: Interpretable Representation Learning... 2016-06-12   \n",
       "2064  InfoGAN: Interpretable Representation Learning... 2016-06-12   \n",
       "2065  InfoGAN: Interpretable Representation Learning... 2016-06-12   \n",
       "2066  InfoGAN: Interpretable Representation Learning... 2016-06-12   \n",
       "2067  InfoGAN: Interpretable Representation Learning... 2016-06-12   \n",
       "\n",
       "      is_problematic  paper_count                               task  \\\n",
       "2052           False         4159                   Image Generation   \n",
       "2053           False         4159            Representation Learning   \n",
       "2054           False         4159  Unsupervised Image Classification   \n",
       "2055           False         4159                 Unsupervised MNIST   \n",
       "2056           False          920                   Image Generation   \n",
       "2057           False          920            Representation Learning   \n",
       "2058           False          920  Unsupervised Image Classification   \n",
       "2059           False          920                 Unsupervised MNIST   \n",
       "2060           False          198                   Image Generation   \n",
       "2061           False          198            Representation Learning   \n",
       "2062           False          198  Unsupervised Image Classification   \n",
       "2063           False          198                 Unsupervised MNIST   \n",
       "2064           False           19                   Image Generation   \n",
       "2065           False           19            Representation Learning   \n",
       "2066           False           19  Unsupervised Image Classification   \n",
       "2067           False           19                 Unsupervised MNIST   \n",
       "\n",
       "             categories                                 parents  \\\n",
       "2052  [Computer Vision]                     [3D Face Animation]   \n",
       "2053      [Methodology]                                      []   \n",
       "2054                 []                  [Image Classification]   \n",
       "2055                 []  [Unsupervised Representation Learning]   \n",
       "2056  [Computer Vision]                     [3D Face Animation]   \n",
       "2057      [Methodology]                                      []   \n",
       "2058                 []                  [Image Classification]   \n",
       "2059                 []  [Unsupervised Representation Learning]   \n",
       "2060  [Computer Vision]                     [3D Face Animation]   \n",
       "2061      [Methodology]                                      []   \n",
       "2062                 []                  [Image Classification]   \n",
       "2063                 []  [Unsupervised Representation Learning]   \n",
       "2064  [Computer Vision]                     [3D Face Animation]   \n",
       "2065      [Methodology]                                      []   \n",
       "2066                 []                  [Image Classification]   \n",
       "2067                 []  [Unsupervised Representation Learning]   \n",
       "\n",
       "                                               children  \\\n",
       "2052  [Image-to-Image Translation, Image Inpainting,...   \n",
       "2053  [Word Embeddings, Graph Embedding, Graph Repre...   \n",
       "2054                                                 []   \n",
       "2055                                                 []   \n",
       "2056  [Image-to-Image Translation, Image Inpainting,...   \n",
       "2057  [Word Embeddings, Graph Embedding, Graph Repre...   \n",
       "2058                                                 []   \n",
       "2059                                                 []   \n",
       "2060  [Image-to-Image Translation, Image Inpainting,...   \n",
       "2061  [Word Embeddings, Graph Embedding, Graph Repre...   \n",
       "2062                                                 []   \n",
       "2063                                                 []   \n",
       "2064  [Image-to-Image Translation, Image Inpainting,...   \n",
       "2065  [Word Embeddings, Graph Embedding, Graph Repre...   \n",
       "2066                                                 []   \n",
       "2067                                                 []   \n",
       "\n",
       "                                               siblings  \\\n",
       "2052  [Image Generation, Image Animation, Dialogue G...   \n",
       "2053                                                 []   \n",
       "2054  [Hyperspectral Image Classification, Artist cl...   \n",
       "2055      [Acoustic Unit Discovery, Unsupervised MNIST]   \n",
       "2056  [Image Generation, Image Animation, Dialogue G...   \n",
       "2057                                                 []   \n",
       "2058  [Hyperspectral Image Classification, Artist cl...   \n",
       "2059      [Acoustic Unit Discovery, Unsupervised MNIST]   \n",
       "2060  [Image Generation, Image Animation, Dialogue G...   \n",
       "2061                                                 []   \n",
       "2062  [Hyperspectral Image Classification, Artist cl...   \n",
       "2063      [Acoustic Unit Discovery, Unsupervised MNIST]   \n",
       "2064  [Image Generation, Image Animation, Dialogue G...   \n",
       "2065                                                 []   \n",
       "2066  [Hyperspectral Image Classification, Artist cl...   \n",
       "2067      [Acoustic Unit Discovery, Unsupervised MNIST]   \n",
       "\n",
       "                                    pdf_url  \\\n",
       "2052  http://arxiv.org/pdf/1606.03657v1.pdf   \n",
       "2053  http://arxiv.org/pdf/1606.03657v1.pdf   \n",
       "2054  http://arxiv.org/pdf/1606.03657v1.pdf   \n",
       "2055  http://arxiv.org/pdf/1606.03657v1.pdf   \n",
       "2056  http://arxiv.org/pdf/1606.03657v1.pdf   \n",
       "2057  http://arxiv.org/pdf/1606.03657v1.pdf   \n",
       "2058  http://arxiv.org/pdf/1606.03657v1.pdf   \n",
       "2059  http://arxiv.org/pdf/1606.03657v1.pdf   \n",
       "2060  http://arxiv.org/pdf/1606.03657v1.pdf   \n",
       "2061  http://arxiv.org/pdf/1606.03657v1.pdf   \n",
       "2062  http://arxiv.org/pdf/1606.03657v1.pdf   \n",
       "2063  http://arxiv.org/pdf/1606.03657v1.pdf   \n",
       "2064  http://arxiv.org/pdf/1606.03657v1.pdf   \n",
       "2065  http://arxiv.org/pdf/1606.03657v1.pdf   \n",
       "2066  http://arxiv.org/pdf/1606.03657v1.pdf   \n",
       "2067  http://arxiv.org/pdf/1606.03657v1.pdf   \n",
       "\n",
       "                                              paper_url  \\\n",
       "2052  https://paperswithcode.com/paper/infogan-inter...   \n",
       "2053  https://paperswithcode.com/paper/infogan-inter...   \n",
       "2054  https://paperswithcode.com/paper/infogan-inter...   \n",
       "2055  https://paperswithcode.com/paper/infogan-inter...   \n",
       "2056  https://paperswithcode.com/paper/infogan-inter...   \n",
       "2057  https://paperswithcode.com/paper/infogan-inter...   \n",
       "2058  https://paperswithcode.com/paper/infogan-inter...   \n",
       "2059  https://paperswithcode.com/paper/infogan-inter...   \n",
       "2060  https://paperswithcode.com/paper/infogan-inter...   \n",
       "2061  https://paperswithcode.com/paper/infogan-inter...   \n",
       "2062  https://paperswithcode.com/paper/infogan-inter...   \n",
       "2063  https://paperswithcode.com/paper/infogan-inter...   \n",
       "2064  https://paperswithcode.com/paper/infogan-inter...   \n",
       "2065  https://paperswithcode.com/paper/infogan-inter...   \n",
       "2066  https://paperswithcode.com/paper/infogan-inter...   \n",
       "2067  https://paperswithcode.com/paper/infogan-inter...   \n",
       "\n",
       "                                              all_tasks  \\\n",
       "2052  [Image Generation, Representation Learning, Un...   \n",
       "2053  [Image Generation, Representation Learning, Un...   \n",
       "2054  [Image Generation, Representation Learning, Un...   \n",
       "2055  [Image Generation, Representation Learning, Un...   \n",
       "2056  [Image Generation, Representation Learning, Un...   \n",
       "2057  [Image Generation, Representation Learning, Un...   \n",
       "2058  [Image Generation, Representation Learning, Un...   \n",
       "2059  [Image Generation, Representation Learning, Un...   \n",
       "2060  [Image Generation, Representation Learning, Un...   \n",
       "2061  [Image Generation, Representation Learning, Un...   \n",
       "2062  [Image Generation, Representation Learning, Un...   \n",
       "2063  [Image Generation, Representation Learning, Un...   \n",
       "2064  [Image Generation, Representation Learning, Un...   \n",
       "2065  [Image Generation, Representation Learning, Un...   \n",
       "2066  [Image Generation, Representation Learning, Un...   \n",
       "2067  [Image Generation, Representation Learning, Un...   \n",
       "\n",
       "                                            all_parents  \\\n",
       "2052  [Image Classification, 3D Face Animation, Unsu...   \n",
       "2053  [Image Classification, 3D Face Animation, Unsu...   \n",
       "2054  [Image Classification, 3D Face Animation, Unsu...   \n",
       "2055  [Image Classification, 3D Face Animation, Unsu...   \n",
       "2056  [Image Classification, 3D Face Animation, Unsu...   \n",
       "2057  [Image Classification, 3D Face Animation, Unsu...   \n",
       "2058  [Image Classification, 3D Face Animation, Unsu...   \n",
       "2059  [Image Classification, 3D Face Animation, Unsu...   \n",
       "2060  [Image Classification, 3D Face Animation, Unsu...   \n",
       "2061  [Image Classification, 3D Face Animation, Unsu...   \n",
       "2062  [Image Classification, 3D Face Animation, Unsu...   \n",
       "2063  [Image Classification, 3D Face Animation, Unsu...   \n",
       "2064  [Image Classification, 3D Face Animation, Unsu...   \n",
       "2065  [Image Classification, 3D Face Animation, Unsu...   \n",
       "2066  [Image Classification, 3D Face Animation, Unsu...   \n",
       "2067  [Image Classification, 3D Face Animation, Unsu...   \n",
       "\n",
       "                                           all_children  \\\n",
       "2052  [Graph Representation Learning, Learning Repre...   \n",
       "2053  [Graph Representation Learning, Learning Repre...   \n",
       "2054  [Graph Representation Learning, Learning Repre...   \n",
       "2055  [Graph Representation Learning, Learning Repre...   \n",
       "2056  [Graph Representation Learning, Learning Repre...   \n",
       "2057  [Graph Representation Learning, Learning Repre...   \n",
       "2058  [Graph Representation Learning, Learning Repre...   \n",
       "2059  [Graph Representation Learning, Learning Repre...   \n",
       "2060  [Graph Representation Learning, Learning Repre...   \n",
       "2061  [Graph Representation Learning, Learning Repre...   \n",
       "2062  [Graph Representation Learning, Learning Repre...   \n",
       "2063  [Graph Representation Learning, Learning Repre...   \n",
       "2064  [Graph Representation Learning, Learning Repre...   \n",
       "2065  [Graph Representation Learning, Learning Repre...   \n",
       "2066  [Graph Representation Learning, Learning Repre...   \n",
       "2067  [Graph Representation Learning, Learning Repre...   \n",
       "\n",
       "                                           all_siblings  \\\n",
       "2052  [Hyperspectral Image Classification, Artist cl...   \n",
       "2053  [Hyperspectral Image Classification, Artist cl...   \n",
       "2054  [Hyperspectral Image Classification, Artist cl...   \n",
       "2055  [Hyperspectral Image Classification, Artist cl...   \n",
       "2056  [Hyperspectral Image Classification, Artist cl...   \n",
       "2057  [Hyperspectral Image Classification, Artist cl...   \n",
       "2058  [Hyperspectral Image Classification, Artist cl...   \n",
       "2059  [Hyperspectral Image Classification, Artist cl...   \n",
       "2060  [Hyperspectral Image Classification, Artist cl...   \n",
       "2061  [Hyperspectral Image Classification, Artist cl...   \n",
       "2062  [Hyperspectral Image Classification, Artist cl...   \n",
       "2063  [Hyperspectral Image Classification, Artist cl...   \n",
       "2064  [Hyperspectral Image Classification, Artist cl...   \n",
       "2065  [Hyperspectral Image Classification, Artist cl...   \n",
       "2066  [Hyperspectral Image Classification, Artist cl...   \n",
       "2067  [Hyperspectral Image Classification, Artist cl...   \n",
       "\n",
       "                      all_categories  \n",
       "2052  [Computer Vision, Methodology]  \n",
       "2053  [Computer Vision, Methodology]  \n",
       "2054  [Computer Vision, Methodology]  \n",
       "2055  [Computer Vision, Methodology]  \n",
       "2056  [Computer Vision, Methodology]  \n",
       "2057  [Computer Vision, Methodology]  \n",
       "2058  [Computer Vision, Methodology]  \n",
       "2059  [Computer Vision, Methodology]  \n",
       "2060  [Computer Vision, Methodology]  \n",
       "2061  [Computer Vision, Methodology]  \n",
       "2062  [Computer Vision, Methodology]  \n",
       "2063  [Computer Vision, Methodology]  \n",
       "2064  [Computer Vision, Methodology]  \n",
       "2065  [Computer Vision, Methodology]  \n",
       "2066  [Computer Vision, Methodology]  \n",
       "2067  [Computer Vision, Methodology]  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_citing_papers_pwc[dataset_citing_papers_pwc.title=='InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "6f8a195a-cb21-4131-89ce-408cf99590e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               ImageNet\n",
       "1               CIFAR-10\n",
       "2                  MNIST\n",
       "3              CIFAR-100\n",
       "4                  KITTI\n",
       "5                   SVHN\n",
       "6                 CelebA\n",
       "7           CUB-200-2011\n",
       "9          Fashion-MNIST\n",
       "10           LibriSpeech\n",
       "11    IMDb Movie Reviews\n",
       "12                   LFW\n",
       "13            OpenAI Gym\n",
       "14                HMDB51\n",
       "15                MuJoCo\n",
       "16                Pubmed\n",
       "17             MovieLens\n",
       "18                   BSD\n",
       "19                Places\n",
       "20                 NYUv2\n",
       "21                STL-10\n",
       "22              Omniglot\n",
       "23             Office-31\n",
       "24                   OTB\n",
       "25             MIMIC-III\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_datasets=datasets_pwc['name'].unique()\n",
    "missing_citers=dataset_citing_papers[dataset_citing_papers.name.isin(used_datasets)].drop_duplicates('title')\n",
    "manual_names=manual_task_labels[~manual_task_labels.Justification.isnull()].name\n",
    "manual_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "97837863",
   "metadata": {},
   "outputs": [],
   "source": [
    "untasked_datasets=datasets_pwc_total[(datasets_pwc_total.task.isnull()) & (~datasets_pwc_total.title.isnull())].name.drop_duplicates()\n",
    "untasked_citing_papers=dataset_citing_papers_pwc[dataset_citing_papers_pwc.name.isin(untasked_datasets)].drop_duplicates(['name','title'])\n",
    "temp=untasked_citing_papers.groupby('name').size().sort_values(ascending=False).cumsum()/untasked_citing_papers.shape[0]\n",
    "temp.name='percent_missing'\n",
    "untasked_dataset_papers=datasets[datasets.name.isin(untasked_datasets)]\n",
    "untasked_dataset_papers=pd.merge(untasked_dataset_papers,temp,on='name').to_csv(\"untasked_datasets.tsv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "94e7fe42-ed6c-49ca-b028-26b2b046aec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5567496359980587"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp2=untasked_citing_papers.groupby('name').size().sort_values(ascending=False)\n",
    "temp2[temp2.index.isin(manual_names)].sum()/temp2.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "f990978e-da19-46e4-ae5f-b56be9300d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>pwc_dataset_id</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>is_problematic</th>\n",
       "      <th>paper_count</th>\n",
       "      <th>task</th>\n",
       "      <th>categories</th>\n",
       "      <th>parents</th>\n",
       "      <th>children</th>\n",
       "      <th>siblings</th>\n",
       "      <th>pdf_url</th>\n",
       "      <th>paper_url</th>\n",
       "      <th>all_tasks</th>\n",
       "      <th>all_parents</th>\n",
       "      <th>all_children</th>\n",
       "      <th>all_siblings</th>\n",
       "      <th>all_categories</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MNIST</td>\n",
       "      <td>1</td>\n",
       "      <td>Modularity Matters: Learning Invariant Relatio...</td>\n",
       "      <td>2018-06-18</td>\n",
       "      <td>False</td>\n",
       "      <td>4159</td>\n",
       "      <td>Relational Reasoning</td>\n",
       "      <td>[Natural Language Processing]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://arxiv.org/pdf/1806.06765v1.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/modularity-ma...</td>\n",
       "      <td>[Relational Reasoning, Visual Reasoning]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Visual Commonsense Reasoning]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Natural Language Processing, Reasoning, Compu...</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MNIST</td>\n",
       "      <td>1</td>\n",
       "      <td>HitNet: a neural network with capsules embedde...</td>\n",
       "      <td>2018-06-18</td>\n",
       "      <td>False</td>\n",
       "      <td>4159</td>\n",
       "      <td>Data Augmentation</td>\n",
       "      <td>[Computer Vision, Natural Language Processing,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Image Augmentation, Text Augmentation]</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://arxiv.org/pdf/1806.06519v1.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/hitnet-a-neur...</td>\n",
       "      <td>[Data Augmentation]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Image Augmentation, Text Augmentation]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Natural Language Processing, Computer Vision,...</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MNIST</td>\n",
       "      <td>1</td>\n",
       "      <td>Fast Convex Pruning of Deep Neural Networks</td>\n",
       "      <td>2018-06-17</td>\n",
       "      <td>False</td>\n",
       "      <td>4159</td>\n",
       "      <td>Network Pruning</td>\n",
       "      <td>[Methodology]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://arxiv.org/pdf/1806.06457v2.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/fast-convex-p...</td>\n",
       "      <td>[Network Pruning]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Methodology]</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MNIST</td>\n",
       "      <td>1</td>\n",
       "      <td>Learning Factorized Multimodal Representations</td>\n",
       "      <td>2018-06-16</td>\n",
       "      <td>False</td>\n",
       "      <td>4159</td>\n",
       "      <td>Representation Learning</td>\n",
       "      <td>[Methodology]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Word Embeddings, Graph Embedding, Graph Repre...</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://arxiv.org/pdf/1806.06176v3.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/learning-fact...</td>\n",
       "      <td>[Representation Learning]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Learning Representation Of Multi-View Data, G...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Methodology]</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MNIST</td>\n",
       "      <td>1</td>\n",
       "      <td>Uncertainty Estimations by Softplus normalizat...</td>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>False</td>\n",
       "      <td>4159</td>\n",
       "      <td>General Classification</td>\n",
       "      <td>[Natural Language Processing, Methodology]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Constructive Comment Classification]</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://arxiv.org/pdf/1806.05978v6.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/bayesian-conv...</td>\n",
       "      <td>[Bayesian Inference, General Classification, V...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Probabilistic Programming, Constructive Comme...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Natural Language Processing, Methodology]</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216899</th>\n",
       "      <td>Colored MNIST</td>\n",
       "      <td>7627</td>\n",
       "      <td>Invariant Causal Representation Learning</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>51</td>\n",
       "      <td>Representation Learning</td>\n",
       "      <td>[Methodology]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Word Embeddings, Graph Embedding, Graph Repre...</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://openreview.net/pdf?id=K4wkUp5xNK</td>\n",
       "      <td>https://paperswithcode.com/paper/invariant-cau...</td>\n",
       "      <td>[Representation Learning]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Learning Representation Of Multi-View Data, G...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Methodology]</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216900</th>\n",
       "      <td>Colored MNIST</td>\n",
       "      <td>7627</td>\n",
       "      <td>Nonlinear Invariant Risk Minimization: A Causa...</td>\n",
       "      <td>2021-02-24</td>\n",
       "      <td>False</td>\n",
       "      <td>51</td>\n",
       "      <td>Representation Learning</td>\n",
       "      <td>[Methodology]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Word Embeddings, Graph Embedding, Graph Repre...</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://arxiv.org/pdf/2102.12353v2.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/nonlinear-inv...</td>\n",
       "      <td>[Representation Learning]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Learning Representation Of Multi-View Data, G...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Methodology]</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216901</th>\n",
       "      <td>Colored MNIST</td>\n",
       "      <td>7627</td>\n",
       "      <td>Meta-Learned Invariant Risk Minimization</td>\n",
       "      <td>2021-03-24</td>\n",
       "      <td>False</td>\n",
       "      <td>51</td>\n",
       "      <td>Meta-Learning</td>\n",
       "      <td>[Methodology]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Few-Shot Learning, Few-shot Regression]</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://arxiv.org/pdf/2103.12947v1.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/meta-learned-...</td>\n",
       "      <td>[Meta-Learning]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Few-shot Regression, Few-Shot Learning]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Methodology]</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216902</th>\n",
       "      <td>Colored MNIST</td>\n",
       "      <td>7627</td>\n",
       "      <td>Towards Causal Federated Learning For Enhanced...</td>\n",
       "      <td>2021-04-14</td>\n",
       "      <td>False</td>\n",
       "      <td>51</td>\n",
       "      <td>Federated Learning</td>\n",
       "      <td>[Methodology]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Personalized Federated Learning]</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://arxiv.org/pdf/2104.06557v1.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/towards-causa...</td>\n",
       "      <td>[Federated Learning]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Personalized Federated Learning]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Methodology]</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216979</th>\n",
       "      <td>AGENT</td>\n",
       "      <td>7709</td>\n",
       "      <td>Baby Intuitions Benchmark (BIB): Discerning th...</td>\n",
       "      <td>2021-02-23</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>Common Sense Reasoning</td>\n",
       "      <td>[Reasoning]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://arxiv.org/pdf/2102.11938v1.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/baby-intuitio...</td>\n",
       "      <td>[Common Sense Reasoning]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Reasoning]</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28876 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name  pwc_dataset_id  \\\n",
       "0               MNIST               1   \n",
       "4               MNIST               1   \n",
       "7               MNIST               1   \n",
       "8               MNIST               1   \n",
       "11              MNIST               1   \n",
       "...               ...             ...   \n",
       "216899  Colored MNIST            7627   \n",
       "216900  Colored MNIST            7627   \n",
       "216901  Colored MNIST            7627   \n",
       "216902  Colored MNIST            7627   \n",
       "216979          AGENT            7709   \n",
       "\n",
       "                                                    title       date  \\\n",
       "0       Modularity Matters: Learning Invariant Relatio... 2018-06-18   \n",
       "4       HitNet: a neural network with capsules embedde... 2018-06-18   \n",
       "7             Fast Convex Pruning of Deep Neural Networks 2018-06-17   \n",
       "8          Learning Factorized Multimodal Representations 2018-06-16   \n",
       "11      Uncertainty Estimations by Softplus normalizat... 2018-06-15   \n",
       "...                                                   ...        ...   \n",
       "216899           Invariant Causal Representation Learning 2021-01-01   \n",
       "216900  Nonlinear Invariant Risk Minimization: A Causa... 2021-02-24   \n",
       "216901           Meta-Learned Invariant Risk Minimization 2021-03-24   \n",
       "216902  Towards Causal Federated Learning For Enhanced... 2021-04-14   \n",
       "216979  Baby Intuitions Benchmark (BIB): Discerning th... 2021-02-23   \n",
       "\n",
       "        is_problematic  paper_count                     task  \\\n",
       "0                False         4159     Relational Reasoning   \n",
       "4                False         4159        Data Augmentation   \n",
       "7                False         4159          Network Pruning   \n",
       "8                False         4159  Representation Learning   \n",
       "11               False         4159   General Classification   \n",
       "...                ...          ...                      ...   \n",
       "216899           False           51  Representation Learning   \n",
       "216900           False           51  Representation Learning   \n",
       "216901           False           51            Meta-Learning   \n",
       "216902           False           51       Federated Learning   \n",
       "216979           False            2   Common Sense Reasoning   \n",
       "\n",
       "                                               categories parents  \\\n",
       "0                           [Natural Language Processing]      []   \n",
       "4       [Computer Vision, Natural Language Processing,...      []   \n",
       "7                                           [Methodology]      []   \n",
       "8                                           [Methodology]      []   \n",
       "11             [Natural Language Processing, Methodology]      []   \n",
       "...                                                   ...     ...   \n",
       "216899                                      [Methodology]      []   \n",
       "216900                                      [Methodology]      []   \n",
       "216901                                      [Methodology]      []   \n",
       "216902                                      [Methodology]      []   \n",
       "216979                                        [Reasoning]      []   \n",
       "\n",
       "                                                 children siblings  \\\n",
       "0                                                      []       []   \n",
       "4                 [Image Augmentation, Text Augmentation]       []   \n",
       "7                                                      []       []   \n",
       "8       [Word Embeddings, Graph Embedding, Graph Repre...       []   \n",
       "11                  [Constructive Comment Classification]       []   \n",
       "...                                                   ...      ...   \n",
       "216899  [Word Embeddings, Graph Embedding, Graph Repre...       []   \n",
       "216900  [Word Embeddings, Graph Embedding, Graph Repre...       []   \n",
       "216901           [Few-Shot Learning, Few-shot Regression]       []   \n",
       "216902                  [Personalized Federated Learning]       []   \n",
       "216979                                                 []       []   \n",
       "\n",
       "                                         pdf_url  \\\n",
       "0          http://arxiv.org/pdf/1806.06765v1.pdf   \n",
       "4          http://arxiv.org/pdf/1806.06519v1.pdf   \n",
       "7          http://arxiv.org/pdf/1806.06457v2.pdf   \n",
       "8         https://arxiv.org/pdf/1806.06176v3.pdf   \n",
       "11        https://arxiv.org/pdf/1806.05978v6.pdf   \n",
       "...                                          ...   \n",
       "216899  https://openreview.net/pdf?id=K4wkUp5xNK   \n",
       "216900    https://arxiv.org/pdf/2102.12353v2.pdf   \n",
       "216901    https://arxiv.org/pdf/2103.12947v1.pdf   \n",
       "216902    https://arxiv.org/pdf/2104.06557v1.pdf   \n",
       "216979    https://arxiv.org/pdf/2102.11938v1.pdf   \n",
       "\n",
       "                                                paper_url  \\\n",
       "0       https://paperswithcode.com/paper/modularity-ma...   \n",
       "4       https://paperswithcode.com/paper/hitnet-a-neur...   \n",
       "7       https://paperswithcode.com/paper/fast-convex-p...   \n",
       "8       https://paperswithcode.com/paper/learning-fact...   \n",
       "11      https://paperswithcode.com/paper/bayesian-conv...   \n",
       "...                                                   ...   \n",
       "216899  https://paperswithcode.com/paper/invariant-cau...   \n",
       "216900  https://paperswithcode.com/paper/nonlinear-inv...   \n",
       "216901  https://paperswithcode.com/paper/meta-learned-...   \n",
       "216902  https://paperswithcode.com/paper/towards-causa...   \n",
       "216979  https://paperswithcode.com/paper/baby-intuitio...   \n",
       "\n",
       "                                                all_tasks all_parents  \\\n",
       "0                [Relational Reasoning, Visual Reasoning]          []   \n",
       "4                                     [Data Augmentation]          []   \n",
       "7                                       [Network Pruning]          []   \n",
       "8                               [Representation Learning]          []   \n",
       "11      [Bayesian Inference, General Classification, V...          []   \n",
       "...                                                   ...         ...   \n",
       "216899                          [Representation Learning]          []   \n",
       "216900                          [Representation Learning]          []   \n",
       "216901                                    [Meta-Learning]          []   \n",
       "216902                               [Federated Learning]          []   \n",
       "216979                           [Common Sense Reasoning]          []   \n",
       "\n",
       "                                             all_children all_siblings  \\\n",
       "0                          [Visual Commonsense Reasoning]           []   \n",
       "4                 [Image Augmentation, Text Augmentation]           []   \n",
       "7                                                      []           []   \n",
       "8       [Learning Representation Of Multi-View Data, G...           []   \n",
       "11      [Probabilistic Programming, Constructive Comme...           []   \n",
       "...                                                   ...          ...   \n",
       "216899  [Learning Representation Of Multi-View Data, G...           []   \n",
       "216900  [Learning Representation Of Multi-View Data, G...           []   \n",
       "216901           [Few-shot Regression, Few-Shot Learning]           []   \n",
       "216902                  [Personalized Federated Learning]           []   \n",
       "216979                                                 []           []   \n",
       "\n",
       "                                           all_categories  year  \n",
       "0       [Natural Language Processing, Reasoning, Compu...  2018  \n",
       "4       [Natural Language Processing, Computer Vision,...  2018  \n",
       "7                                           [Methodology]  2018  \n",
       "8                                           [Methodology]  2018  \n",
       "11             [Natural Language Processing, Methodology]  2018  \n",
       "...                                                   ...   ...  \n",
       "216899                                      [Methodology]  2021  \n",
       "216900                                      [Methodology]  2021  \n",
       "216901                                      [Methodology]  2021  \n",
       "216902                                      [Methodology]  2021  \n",
       "216979                                        [Reasoning]  2021  \n",
       "\n",
       "[28876 rows x 19 columns]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_citing_papers_pwc[dataset_citing_papers_pwc.name.isin(temp.index)].drop_duplicates('title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "812f6993-3022-4d69-b654-0946cd2f4b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>name</th>\n",
       "      <th>full_name</th>\n",
       "      <th>homepage</th>\n",
       "      <th>description</th>\n",
       "      <th>introduced_date</th>\n",
       "      <th>warning</th>\n",
       "      <th>modalities</th>\n",
       "      <th>languages</th>\n",
       "      <th>variants</th>\n",
       "      <th>num_papers</th>\n",
       "      <th>data_loaders</th>\n",
       "      <th>title</th>\n",
       "      <th>paper_url</th>\n",
       "      <th>Texts</th>\n",
       "      <th>Images</th>\n",
       "      <th>percent_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://paperswithcode.com/dataset/mnist</td>\n",
       "      <td>MNIST</td>\n",
       "      <td></td>\n",
       "      <td>http://yann.lecun.com/exdb/mnist/</td>\n",
       "      <td>The **MNIST** database (**Modified National In...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[75 Superpixel MNIST, MNIST, MNIST-full, MNIST...</td>\n",
       "      <td>4159</td>\n",
       "      <td>[{'url': 'https://pytorch.org/vision/stable/da...</td>\n",
       "      <td>Gradient-based learning applied to document re...</td>\n",
       "      <td>http://arxiv.org/pdf/1102.0183.pdf</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.255564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://paperswithcode.com/dataset/celeba</td>\n",
       "      <td>CelebA</td>\n",
       "      <td>CelebFaces Attributes Dataset</td>\n",
       "      <td>http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html</td>\n",
       "      <td>CelebFaces Attributes dataset contains 202,599...</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[CelebA Aligned, CelebA 64x64, CelebA 256x256,...</td>\n",
       "      <td>1539</td>\n",
       "      <td>[{'url': 'https://pytorch.org/vision/stable/da...</td>\n",
       "      <td>Deep Learning Face Attributes in the Wild</td>\n",
       "      <td>https://paperswithcode.com/paper/deep-learning...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.382329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://paperswithcode.com/dataset/imagenet</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td></td>\n",
       "      <td>http://image-net.org/challenges/LSVRC/</td>\n",
       "      <td>The **ImageNet** dataset contains 14,197,122 a...</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[ILSVRC 2015, ILSVRC 2016, ImageNet, ImageNet ...</td>\n",
       "      <td>6081</td>\n",
       "      <td>[{'url': 'https://pytorch.org/vision/stable/da...</td>\n",
       "      <td>ImageNet: A large-scale hierarchical image dat...</td>\n",
       "      <td>https://doi.org/10.1109/CVPR.2009.5206848</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.107213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://paperswithcode.com/dataset/penn-treebank</td>\n",
       "      <td>Penn Treebank</td>\n",
       "      <td></td>\n",
       "      <td>https://catalog.ldc.upenn.edu/docs/LDC95T7/cl9...</td>\n",
       "      <td>The English **Penn Treebank** (**PTB**) corpus...</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>[Texts]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PTB dataset, ECG lead II, PTB, Penn Treebank ...</td>\n",
       "      <td>1056</td>\n",
       "      <td>[{'url': 'https://pytorch.org/text/stable/data...</td>\n",
       "      <td>Building a Large Annotated Corpus of English: ...</td>\n",
       "      <td>http://dl.acm.org/citation.cfm?id=972470.972475</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.418960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://paperswithcode.com/dataset/lfw</td>\n",
       "      <td>LFW</td>\n",
       "      <td>Labeled Faces in the Wild</td>\n",
       "      <td>http://vis-www.cs.umass.edu/lfw/</td>\n",
       "      <td>The **LFW** dataset contains 13,233 images of ...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[LFW, Labeled Faces in the Wild, LFW (Online O...</td>\n",
       "      <td>576</td>\n",
       "      <td>[{'url': 'https://www.tensorflow.org/datasets/...</td>\n",
       "      <td>Labeled faces in the wild: A database for stud...</td>\n",
       "      <td>http://vis-www.cs.umass.edu/lfw/lfw.pdf</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.472139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>https://paperswithcode.com/dataset/bdd-x</td>\n",
       "      <td>BDD-X</td>\n",
       "      <td>Berkeley Deep Drive-X (eXplanation)</td>\n",
       "      <td>https://github.com/JinkyuKimUCB/BDD-X-dataset</td>\n",
       "      <td>**Berkeley Deep Drive-X (eXplanation)** is a d...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[BDD-X]</td>\n",
       "      <td>8</td>\n",
       "      <td>[]</td>\n",
       "      <td>Textual Explanations for Self-Driving Vehicles</td>\n",
       "      <td>https://paperswithcode.com/paper/textual-expla...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.988491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>https://paperswithcode.com/dataset/data-collec...</td>\n",
       "      <td>Data Collected with Package Delivery Quadcopte...</td>\n",
       "      <td></td>\n",
       "      <td>https://doi.org/10.1184/R1/12683453.v1</td>\n",
       "      <td>This experiment was performed in order to empi...</td>\n",
       "      <td>2020-07-27</td>\n",
       "      <td>None</td>\n",
       "      <td>[Tabular, Time series]</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[Data Collected with Package Delivery Quadcopt...</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>In-flight positional and energy use data set o...</td>\n",
       "      <td>https://paperswithcode.com/paper/in-flight-pos...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.998660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>https://paperswithcode.com/dataset/pde-dataset</td>\n",
       "      <td>PDE dataset</td>\n",
       "      <td>Parametric Partial Differential Equation dataset</td>\n",
       "      <td>https://github.com/zongyi-li/graph-pde</td>\n",
       "      <td>Contains data of parametric PDEs\\n\\n- Burgers'...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>[Physics]</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[PDE dataset]</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>Multipole Graph Neural Operator for Parametric...</td>\n",
       "      <td>https://paperswithcode.com/paper/multipole-gra...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.998613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>https://paperswithcode.com/dataset/colored-mnist</td>\n",
       "      <td>Colored MNIST</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Click to add a brief description of the datase...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Colored MNIST]</td>\n",
       "      <td>51</td>\n",
       "      <td>[]</td>\n",
       "      <td>Invariant Risk Minimization</td>\n",
       "      <td>https://paperswithcode.com/paper/invariant-ris...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.931152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>https://paperswithcode.com/dataset/agent</td>\n",
       "      <td>AGENT</td>\n",
       "      <td></td>\n",
       "      <td>https://www.tshu.io/AGENT/</td>\n",
       "      <td>Inspired by cognitive development studies on i...</td>\n",
       "      <td>2021-02-24</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AGENT]</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>AGENT: A Benchmark for Core Psychological Reas...</td>\n",
       "      <td>https://paperswithcode.com/paper/agent-a-bench...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.997458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url  \\\n",
       "0             https://paperswithcode.com/dataset/mnist   \n",
       "1            https://paperswithcode.com/dataset/celeba   \n",
       "2          https://paperswithcode.com/dataset/imagenet   \n",
       "3     https://paperswithcode.com/dataset/penn-treebank   \n",
       "4               https://paperswithcode.com/dataset/lfw   \n",
       "..                                                 ...   \n",
       "635           https://paperswithcode.com/dataset/bdd-x   \n",
       "636  https://paperswithcode.com/dataset/data-collec...   \n",
       "637     https://paperswithcode.com/dataset/pde-dataset   \n",
       "638   https://paperswithcode.com/dataset/colored-mnist   \n",
       "639           https://paperswithcode.com/dataset/agent   \n",
       "\n",
       "                                                  name  \\\n",
       "0                                                MNIST   \n",
       "1                                               CelebA   \n",
       "2                                             ImageNet   \n",
       "3                                        Penn Treebank   \n",
       "4                                                  LFW   \n",
       "..                                                 ...   \n",
       "635                                              BDD-X   \n",
       "636  Data Collected with Package Delivery Quadcopte...   \n",
       "637                                        PDE dataset   \n",
       "638                                      Colored MNIST   \n",
       "639                                              AGENT   \n",
       "\n",
       "                                            full_name  \\\n",
       "0                                                       \n",
       "1                       CelebFaces Attributes Dataset   \n",
       "2                                                       \n",
       "3                                                       \n",
       "4                           Labeled Faces in the Wild   \n",
       "..                                                ...   \n",
       "635               Berkeley Deep Drive-X (eXplanation)   \n",
       "636                                                     \n",
       "637  Parametric Partial Differential Equation dataset   \n",
       "638                                                     \n",
       "639                                                     \n",
       "\n",
       "                                              homepage  \\\n",
       "0                    http://yann.lecun.com/exdb/mnist/   \n",
       "1     http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html   \n",
       "2               http://image-net.org/challenges/LSVRC/   \n",
       "3    https://catalog.ldc.upenn.edu/docs/LDC95T7/cl9...   \n",
       "4                     http://vis-www.cs.umass.edu/lfw/   \n",
       "..                                                 ...   \n",
       "635      https://github.com/JinkyuKimUCB/BDD-X-dataset   \n",
       "636             https://doi.org/10.1184/R1/12683453.v1   \n",
       "637             https://github.com/zongyi-li/graph-pde   \n",
       "638                                                      \n",
       "639                         https://www.tshu.io/AGENT/   \n",
       "\n",
       "                                           description introduced_date  \\\n",
       "0    The **MNIST** database (**Modified National In...             NaT   \n",
       "1    CelebFaces Attributes dataset contains 202,599...      2015-01-01   \n",
       "2    The **ImageNet** dataset contains 14,197,122 a...      2009-01-01   \n",
       "3    The English **Penn Treebank** (**PTB**) corpus...      1993-01-01   \n",
       "4    The **LFW** dataset contains 13,233 images of ...             NaT   \n",
       "..                                                 ...             ...   \n",
       "635  **Berkeley Deep Drive-X (eXplanation)** is a d...             NaT   \n",
       "636  This experiment was performed in order to empi...      2020-07-27   \n",
       "637  Contains data of parametric PDEs\\n\\n- Burgers'...             NaT   \n",
       "638  Click to add a brief description of the datase...             NaT   \n",
       "639  Inspired by cognitive development studies on i...      2021-02-24   \n",
       "\n",
       "    warning              modalities  languages  \\\n",
       "0      None                [Images]         []   \n",
       "1      None                [Images]         []   \n",
       "2      None                [Images]  [English]   \n",
       "3      None                 [Texts]         []   \n",
       "4      None                [Images]         []   \n",
       "..      ...                     ...        ...   \n",
       "635    None                      []  [English]   \n",
       "636    None  [Tabular, Time series]  [English]   \n",
       "637    None               [Physics]  [English]   \n",
       "638    None                      []         []   \n",
       "639    None                      []         []   \n",
       "\n",
       "                                              variants  num_papers  \\\n",
       "0    [75 Superpixel MNIST, MNIST, MNIST-full, MNIST...        4159   \n",
       "1    [CelebA Aligned, CelebA 64x64, CelebA 256x256,...        1539   \n",
       "2    [ILSVRC 2015, ILSVRC 2016, ImageNet, ImageNet ...        6081   \n",
       "3    [PTB dataset, ECG lead II, PTB, Penn Treebank ...        1056   \n",
       "4    [LFW, Labeled Faces in the Wild, LFW (Online O...         576   \n",
       "..                                                 ...         ...   \n",
       "635                                            [BDD-X]           8   \n",
       "636  [Data Collected with Package Delivery Quadcopt...           2   \n",
       "637                                      [PDE dataset]           2   \n",
       "638                                    [Colored MNIST]          51   \n",
       "639                                            [AGENT]           2   \n",
       "\n",
       "                                          data_loaders  \\\n",
       "0    [{'url': 'https://pytorch.org/vision/stable/da...   \n",
       "1    [{'url': 'https://pytorch.org/vision/stable/da...   \n",
       "2    [{'url': 'https://pytorch.org/vision/stable/da...   \n",
       "3    [{'url': 'https://pytorch.org/text/stable/data...   \n",
       "4    [{'url': 'https://www.tensorflow.org/datasets/...   \n",
       "..                                                 ...   \n",
       "635                                                 []   \n",
       "636                                                 []   \n",
       "637                                                 []   \n",
       "638                                                 []   \n",
       "639                                                 []   \n",
       "\n",
       "                                                 title  \\\n",
       "0    Gradient-based learning applied to document re...   \n",
       "1            Deep Learning Face Attributes in the Wild   \n",
       "2    ImageNet: A large-scale hierarchical image dat...   \n",
       "3    Building a Large Annotated Corpus of English: ...   \n",
       "4    Labeled faces in the wild: A database for stud...   \n",
       "..                                                 ...   \n",
       "635     Textual Explanations for Self-Driving Vehicles   \n",
       "636  In-flight positional and energy use data set o...   \n",
       "637  Multipole Graph Neural Operator for Parametric...   \n",
       "638                        Invariant Risk Minimization   \n",
       "639  AGENT: A Benchmark for Core Psychological Reas...   \n",
       "\n",
       "                                             paper_url  Texts  Images  \\\n",
       "0                   http://arxiv.org/pdf/1102.0183.pdf  False    True   \n",
       "1    https://paperswithcode.com/paper/deep-learning...  False    True   \n",
       "2            https://doi.org/10.1109/CVPR.2009.5206848  False    True   \n",
       "3      http://dl.acm.org/citation.cfm?id=972470.972475   True   False   \n",
       "4              http://vis-www.cs.umass.edu/lfw/lfw.pdf  False    True   \n",
       "..                                                 ...    ...     ...   \n",
       "635  https://paperswithcode.com/paper/textual-expla...  False   False   \n",
       "636  https://paperswithcode.com/paper/in-flight-pos...  False   False   \n",
       "637  https://paperswithcode.com/paper/multipole-gra...  False   False   \n",
       "638  https://paperswithcode.com/paper/invariant-ris...  False   False   \n",
       "639  https://paperswithcode.com/paper/agent-a-bench...  False   False   \n",
       "\n",
       "     percent_missing  \n",
       "0           0.255564  \n",
       "1           0.382329  \n",
       "2           0.107213  \n",
       "3           0.418960  \n",
       "4           0.472139  \n",
       "..               ...  \n",
       "635         0.988491  \n",
       "636         0.998660  \n",
       "637         0.998613  \n",
       "638         0.931152  \n",
       "639         0.997458  \n",
       "\n",
       "[640 rows x 17 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "untasked_datasets=datasets_pwc_total[(datasets_pwc_total.task.isnull()) & (~datasets_pwc_total.title.isnull())].name.drop_duplicates()\n",
    "untasked_citing_papers=dataset_citing_papers_pwc[dataset_citing_papers_pwc.name.isin(untasked_datasets)].drop_duplicates(['name','title'])\n",
    "temp=untasked_citing_papers.groupby('name').size().sort_values(ascending=False).cumsum()/untasked_citing_papers.shape[0]\n",
    "temp.name='percent_missing'\n",
    "untasked_dataset_papers=datasets[datasets.name.isin(untasked_datasets)]\n",
    "pd.merge(untasked_dataset_papers,temp,on='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "386461e8-ce90-4eb1-91d4-870d8b2bc2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>name</th>\n",
       "      <th>full_name</th>\n",
       "      <th>homepage</th>\n",
       "      <th>description</th>\n",
       "      <th>introduced_date</th>\n",
       "      <th>warning</th>\n",
       "      <th>modalities</th>\n",
       "      <th>languages</th>\n",
       "      <th>variants</th>\n",
       "      <th>...</th>\n",
       "      <th>data_loaders</th>\n",
       "      <th>title</th>\n",
       "      <th>paper_url</th>\n",
       "      <th>Texts</th>\n",
       "      <th>Images</th>\n",
       "      <th>dataset_tasks</th>\n",
       "      <th>dataset_tasks_parents</th>\n",
       "      <th>dataset_tasks_categories</th>\n",
       "      <th>dataset_tasks_children</th>\n",
       "      <th>dataset_tasks_siblings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://paperswithcode.com/dataset/mnist</td>\n",
       "      <td>MNIST</td>\n",
       "      <td></td>\n",
       "      <td>http://yann.lecun.com/exdb/mnist/</td>\n",
       "      <td>The **MNIST** database (**Modified National In...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[75 Superpixel MNIST, MNIST, MNIST-full, MNIST...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'url': 'https://pytorch.org/vision/stable/da...</td>\n",
       "      <td>Gradient-based learning applied to document re...</td>\n",
       "      <td>http://arxiv.org/pdf/1102.0183.pdf</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[Image Classification, Image Generation, Speec...</td>\n",
       "      <td>[3D Face Animation, Image Classification, Auto...</td>\n",
       "      <td>[Computer Vision, Methodology, Computer Vision...</td>\n",
       "      <td>[Few-Shot Image Classification, Fine-Grained I...</td>\n",
       "      <td>[Dialogue Generation, Image Animation, Image G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://paperswithcode.com/dataset/celeba</td>\n",
       "      <td>CelebA</td>\n",
       "      <td>CelebFaces Attributes Dataset</td>\n",
       "      <td>http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html</td>\n",
       "      <td>CelebFaces Attributes dataset contains 202,599...</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[CelebA Aligned, CelebA 64x64, CelebA 256x256,...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'url': 'https://pytorch.org/vision/stable/da...</td>\n",
       "      <td>Deep Learning Face Attributes in the Wild</td>\n",
       "      <td>https://paperswithcode.com/paper/deep-learning...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[Image Classification, Image Generation, Face ...</td>\n",
       "      <td>[3D Face Animation, Facial Recognition and Mod...</td>\n",
       "      <td>[Computer Vision, Methodology, Computer Vision...</td>\n",
       "      <td>[Few-Shot Image Classification, Fine-Grained I...</td>\n",
       "      <td>[Dialogue Generation, Image Animation, Image G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://paperswithcode.com/dataset/jft-300m</td>\n",
       "      <td>JFT-300M</td>\n",
       "      <td>JFT-300M</td>\n",
       "      <td></td>\n",
       "      <td>**JFT-300M** is an internal Google dataset use...</td>\n",
       "      <td>2017-07-10</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[JFT-300M]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Revisiting Unreasonable Effectiveness of Data ...</td>\n",
       "      <td>https://paperswithcode.com/paper/revisiting-un...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[Image Classification]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Computer Vision, Methodology]</td>\n",
       "      <td>[Few-Shot Image Classification, Fine-Grained I...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://paperswithcode.com/dataset/glue</td>\n",
       "      <td>GLUE</td>\n",
       "      <td>General Language Understanding Evaluation benc...</td>\n",
       "      <td>https://gluebenchmark.com/</td>\n",
       "      <td>General Language Understanding Evaluation (**G...</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>[Texts]</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[GLUE, RTE, WNLI, QNLI, MultiNLI, Quora Questi...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'url': 'https://huggingface.co/datasets/glue...</td>\n",
       "      <td>GLUE: A Multi-Task Benchmark and Analysis Plat...</td>\n",
       "      <td>https://paperswithcode.com/paper/glue-a-multi-...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[Question Answering, Sentiment Analysis, Natur...</td>\n",
       "      <td>[Semantic Textual Similarity, Text Generation]</td>\n",
       "      <td>[Natural Language Processing, Natural Language...</td>\n",
       "      <td>[Open-Domain Question Answering, Answer Select...</td>\n",
       "      <td>[Paraphrase Identification, Cross-Lingual Sema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://paperswithcode.com/dataset/multinli</td>\n",
       "      <td>MultiNLI</td>\n",
       "      <td>Multi-Genre Natural Language Inference</td>\n",
       "      <td>https://cims.nyu.edu/~sbowman/multinli/</td>\n",
       "      <td>The **Multi-Genre Natural Language Inference**...</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>[Texts]</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[MultiNLI, MultiNLI Dev]</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'url': 'https://huggingface.co/datasets/mult...</td>\n",
       "      <td>A Broad-Coverage Challenge Corpus for Sentence...</td>\n",
       "      <td>https://paperswithcode.com/paper/a-broad-cover...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[Natural Language Inference]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Natural Language Processing]</td>\n",
       "      <td>[Cross-Lingual Natural Language Inference]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4379</th>\n",
       "      <td>https://paperswithcode.com/dataset/openea-benc...</td>\n",
       "      <td>OpenEA Benchmark</td>\n",
       "      <td></td>\n",
       "      <td>https://github.com/nju-websoft/OpenEA#dataset-...</td>\n",
       "      <td>1.0 Version of OpenEA benchmark datasets. Plea...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>[Graphs]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[OpenEA Benchmark]</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'url': 'https://github.com/nju-websoft/OpenE...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4380</th>\n",
       "      <td>https://paperswithcode.com/dataset/fewclue</td>\n",
       "      <td>FewCLUE</td>\n",
       "      <td></td>\n",
       "      <td>https://github.com/CLUEbenchmark/FewCLUE</td>\n",
       "      <td>Chinese Few-shot Learning Evaluation Benchmark...</td>\n",
       "      <td>2021-07-15</td>\n",
       "      <td>None</td>\n",
       "      <td>[Texts]</td>\n",
       "      <td>[Chinese]</td>\n",
       "      <td>[FewCLUE]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>FewCLUE: A Chinese Few-shot Learning Evaluatio...</td>\n",
       "      <td>https://paperswithcode.com/paper/fewclue-a-chi...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>https://paperswithcode.com/dataset/zs-f-vqa</td>\n",
       "      <td>ZS-F-VQA</td>\n",
       "      <td></td>\n",
       "      <td>https://github.com/China-UK-ZSL/ZS-F-VQA</td>\n",
       "      <td>The ZS-F-VQA dataset  is a new split of the F-...</td>\n",
       "      <td>2021-07-12</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images, Texts, Graphs]</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[ZS-F-VQA]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Zero-shot Visual Question Answering using Know...</td>\n",
       "      <td>https://paperswithcode.com/paper/zero-shot-vis...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[Visual Question Answering, Factual Visual Que...</td>\n",
       "      <td>[Visual Question Answering]</td>\n",
       "      <td>[Computer Vision, Natural Language Processing]</td>\n",
       "      <td>[Machine Reading Comprehension, Embodied Quest...</td>\n",
       "      <td>[Embodied Question Answering, Factual Visual Q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4382</th>\n",
       "      <td>https://paperswithcode.com/dataset/imc-phototo...</td>\n",
       "      <td>IMC PhotoTourism</td>\n",
       "      <td>Image Matching Challenge Phototourism</td>\n",
       "      <td>https://www.cs.ubc.ca/research/image-matching-...</td>\n",
       "      <td>Dataset provided by the Image Matching Worksho...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[IMC PhotoTourism]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[Stereo Matching, Structure from Motion, Local...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Computer Vision, Computer Vision, Computer Vi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4383</th>\n",
       "      <td>https://paperswithcode.com/dataset/https-githu...</td>\n",
       "      <td>https://github.com/jcorrean/psychologyofcorrup...</td>\n",
       "      <td></td>\n",
       "      <td>https://github.com/jcorrean/psychologyofcorrup...</td>\n",
       "      <td>Click to add a brief description of the datase...</td>\n",
       "      <td>2021-07-16</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[https://github.com/jcorrean/psychologyofcorru...</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4383 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    url  \\\n",
       "0              https://paperswithcode.com/dataset/mnist   \n",
       "1             https://paperswithcode.com/dataset/celeba   \n",
       "2           https://paperswithcode.com/dataset/jft-300m   \n",
       "3               https://paperswithcode.com/dataset/glue   \n",
       "4           https://paperswithcode.com/dataset/multinli   \n",
       "...                                                 ...   \n",
       "4379  https://paperswithcode.com/dataset/openea-benc...   \n",
       "4380         https://paperswithcode.com/dataset/fewclue   \n",
       "4381        https://paperswithcode.com/dataset/zs-f-vqa   \n",
       "4382  https://paperswithcode.com/dataset/imc-phototo...   \n",
       "4383  https://paperswithcode.com/dataset/https-githu...   \n",
       "\n",
       "                                                   name  \\\n",
       "0                                                 MNIST   \n",
       "1                                                CelebA   \n",
       "2                                              JFT-300M   \n",
       "3                                                  GLUE   \n",
       "4                                              MultiNLI   \n",
       "...                                                 ...   \n",
       "4379                                   OpenEA Benchmark   \n",
       "4380                                            FewCLUE   \n",
       "4381                                           ZS-F-VQA   \n",
       "4382                                   IMC PhotoTourism   \n",
       "4383  https://github.com/jcorrean/psychologyofcorrup...   \n",
       "\n",
       "                                              full_name  \\\n",
       "0                                                         \n",
       "1                         CelebFaces Attributes Dataset   \n",
       "2                                              JFT-300M   \n",
       "3     General Language Understanding Evaluation benc...   \n",
       "4                Multi-Genre Natural Language Inference   \n",
       "...                                                 ...   \n",
       "4379                                                      \n",
       "4380                                                      \n",
       "4381                                                      \n",
       "4382              Image Matching Challenge Phototourism   \n",
       "4383                                                      \n",
       "\n",
       "                                               homepage  \\\n",
       "0                     http://yann.lecun.com/exdb/mnist/   \n",
       "1      http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html   \n",
       "2                                                         \n",
       "3                            https://gluebenchmark.com/   \n",
       "4               https://cims.nyu.edu/~sbowman/multinli/   \n",
       "...                                                 ...   \n",
       "4379  https://github.com/nju-websoft/OpenEA#dataset-...   \n",
       "4380           https://github.com/CLUEbenchmark/FewCLUE   \n",
       "4381           https://github.com/China-UK-ZSL/ZS-F-VQA   \n",
       "4382  https://www.cs.ubc.ca/research/image-matching-...   \n",
       "4383  https://github.com/jcorrean/psychologyofcorrup...   \n",
       "\n",
       "                                            description introduced_date  \\\n",
       "0     The **MNIST** database (**Modified National In...             NaT   \n",
       "1     CelebFaces Attributes dataset contains 202,599...      2015-01-01   \n",
       "2     **JFT-300M** is an internal Google dataset use...      2017-07-10   \n",
       "3     General Language Understanding Evaluation (**G...      2019-01-01   \n",
       "4     The **Multi-Genre Natural Language Inference**...      2018-01-01   \n",
       "...                                                 ...             ...   \n",
       "4379  1.0 Version of OpenEA benchmark datasets. Plea...             NaT   \n",
       "4380  Chinese Few-shot Learning Evaluation Benchmark...      2021-07-15   \n",
       "4381  The ZS-F-VQA dataset  is a new split of the F-...      2021-07-12   \n",
       "4382  Dataset provided by the Image Matching Worksho...             NaT   \n",
       "4383  Click to add a brief description of the datase...      2021-07-16   \n",
       "\n",
       "     warning               modalities  languages  \\\n",
       "0       None                 [Images]         []   \n",
       "1       None                 [Images]         []   \n",
       "2       None                 [Images]         []   \n",
       "3       None                  [Texts]  [English]   \n",
       "4       None                  [Texts]  [English]   \n",
       "...      ...                      ...        ...   \n",
       "4379    None                 [Graphs]         []   \n",
       "4380    None                  [Texts]  [Chinese]   \n",
       "4381    None  [Images, Texts, Graphs]  [English]   \n",
       "4382    None                 [Images]         []   \n",
       "4383    None                       []  [English]   \n",
       "\n",
       "                                               variants  ...  \\\n",
       "0     [75 Superpixel MNIST, MNIST, MNIST-full, MNIST...  ...   \n",
       "1     [CelebA Aligned, CelebA 64x64, CelebA 256x256,...  ...   \n",
       "2                                            [JFT-300M]  ...   \n",
       "3     [GLUE, RTE, WNLI, QNLI, MultiNLI, Quora Questi...  ...   \n",
       "4                              [MultiNLI, MultiNLI Dev]  ...   \n",
       "...                                                 ...  ...   \n",
       "4379                                 [OpenEA Benchmark]  ...   \n",
       "4380                                          [FewCLUE]  ...   \n",
       "4381                                         [ZS-F-VQA]  ...   \n",
       "4382                                 [IMC PhotoTourism]  ...   \n",
       "4383  [https://github.com/jcorrean/psychologyofcorru...  ...   \n",
       "\n",
       "                                           data_loaders  \\\n",
       "0     [{'url': 'https://pytorch.org/vision/stable/da...   \n",
       "1     [{'url': 'https://pytorch.org/vision/stable/da...   \n",
       "2                                                    []   \n",
       "3     [{'url': 'https://huggingface.co/datasets/glue...   \n",
       "4     [{'url': 'https://huggingface.co/datasets/mult...   \n",
       "...                                                 ...   \n",
       "4379  [{'url': 'https://github.com/nju-websoft/OpenE...   \n",
       "4380                                                 []   \n",
       "4381                                                 []   \n",
       "4382                                                 []   \n",
       "4383                                                 []   \n",
       "\n",
       "                                                  title  \\\n",
       "0     Gradient-based learning applied to document re...   \n",
       "1             Deep Learning Face Attributes in the Wild   \n",
       "2     Revisiting Unreasonable Effectiveness of Data ...   \n",
       "3     GLUE: A Multi-Task Benchmark and Analysis Plat...   \n",
       "4     A Broad-Coverage Challenge Corpus for Sentence...   \n",
       "...                                                 ...   \n",
       "4379                                               None   \n",
       "4380  FewCLUE: A Chinese Few-shot Learning Evaluatio...   \n",
       "4381  Zero-shot Visual Question Answering using Know...   \n",
       "4382                                               None   \n",
       "4383                                               None   \n",
       "\n",
       "                                              paper_url  Texts  Images  \\\n",
       "0                    http://arxiv.org/pdf/1102.0183.pdf  False    True   \n",
       "1     https://paperswithcode.com/paper/deep-learning...  False    True   \n",
       "2     https://paperswithcode.com/paper/revisiting-un...  False    True   \n",
       "3     https://paperswithcode.com/paper/glue-a-multi-...   True   False   \n",
       "4     https://paperswithcode.com/paper/a-broad-cover...   True   False   \n",
       "...                                                 ...    ...     ...   \n",
       "4379                                               None  False   False   \n",
       "4380  https://paperswithcode.com/paper/fewclue-a-chi...   True   False   \n",
       "4381  https://paperswithcode.com/paper/zero-shot-vis...   True    True   \n",
       "4382                                               None  False    True   \n",
       "4383                                               None  False   False   \n",
       "\n",
       "                                          dataset_tasks  \\\n",
       "0     [Image Classification, Image Generation, Speec...   \n",
       "1     [Image Classification, Image Generation, Face ...   \n",
       "2                                [Image Classification]   \n",
       "3     [Question Answering, Sentiment Analysis, Natur...   \n",
       "4                          [Natural Language Inference]   \n",
       "...                                                 ...   \n",
       "4379                                                 []   \n",
       "4380                                                 []   \n",
       "4381  [Visual Question Answering, Factual Visual Que...   \n",
       "4382  [Stereo Matching, Structure from Motion, Local...   \n",
       "4383                                                 []   \n",
       "\n",
       "                                  dataset_tasks_parents  \\\n",
       "0     [3D Face Animation, Image Classification, Auto...   \n",
       "1     [3D Face Animation, Facial Recognition and Mod...   \n",
       "2                                                    []   \n",
       "3        [Semantic Textual Similarity, Text Generation]   \n",
       "4                                                    []   \n",
       "...                                                 ...   \n",
       "4379                                                 []   \n",
       "4380                                                 []   \n",
       "4381                        [Visual Question Answering]   \n",
       "4382                                                 []   \n",
       "4383                                                 []   \n",
       "\n",
       "                               dataset_tasks_categories  \\\n",
       "0     [Computer Vision, Methodology, Computer Vision...   \n",
       "1     [Computer Vision, Methodology, Computer Vision...   \n",
       "2                        [Computer Vision, Methodology]   \n",
       "3     [Natural Language Processing, Natural Language...   \n",
       "4                         [Natural Language Processing]   \n",
       "...                                                 ...   \n",
       "4379                                                 []   \n",
       "4380                                                 []   \n",
       "4381     [Computer Vision, Natural Language Processing]   \n",
       "4382  [Computer Vision, Computer Vision, Computer Vi...   \n",
       "4383                                                 []   \n",
       "\n",
       "                                 dataset_tasks_children  \\\n",
       "0     [Few-Shot Image Classification, Fine-Grained I...   \n",
       "1     [Few-Shot Image Classification, Fine-Grained I...   \n",
       "2     [Few-Shot Image Classification, Fine-Grained I...   \n",
       "3     [Open-Domain Question Answering, Answer Select...   \n",
       "4            [Cross-Lingual Natural Language Inference]   \n",
       "...                                                 ...   \n",
       "4379                                                 []   \n",
       "4380                                                 []   \n",
       "4381  [Machine Reading Comprehension, Embodied Quest...   \n",
       "4382                                                 []   \n",
       "4383                                                 []   \n",
       "\n",
       "                                 dataset_tasks_siblings  \n",
       "0     [Dialogue Generation, Image Animation, Image G...  \n",
       "1     [Dialogue Generation, Image Animation, Image G...  \n",
       "2                                                    []  \n",
       "3     [Paraphrase Identification, Cross-Lingual Sema...  \n",
       "4                                                    []  \n",
       "...                                                 ...  \n",
       "4379                                                 []  \n",
       "4380                                                 []  \n",
       "4381  [Embodied Question Answering, Factual Visual Q...  \n",
       "4382                                                 []  \n",
       "4383                                                 []  \n",
       "\n",
       "[4383 rows x 21 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "b203d3a0-f0dc-4e51-8885-e5b00e2af6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=untasked_citing_papers.groupby('name').size().sort_values(ascending=False).cumsum()/untasked_citing_papers.shape[0]\n",
    "temp.name='percent_missing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "16dc7cb6-85cd-4f5f-8026-58eca864e6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Classification                                 9162\n",
       "Semantic Segmentation                                  6974\n",
       "Image Classification                                   6933\n",
       "Question Answering                                     6032\n",
       "Object Detection                                       5701\n",
       "                                                       ... \n",
       "Polyphone disambiguation                                  1\n",
       "Reverse Style Transfer                                    1\n",
       "ROI-based image generation                                1\n",
       "Multilingual Machine Comprehension in English Hindi       1\n",
       "Detecting Shadows                                         1\n",
       "Name: task, Length: 1653, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_citing_papers_pwc['task'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "446fcec7-e05a-4501-9804-b5ec16388de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>name</th>\n",
       "      <th>full_name</th>\n",
       "      <th>homepage</th>\n",
       "      <th>description</th>\n",
       "      <th>introduced_date</th>\n",
       "      <th>warning</th>\n",
       "      <th>modalities</th>\n",
       "      <th>languages</th>\n",
       "      <th>variants</th>\n",
       "      <th>num_papers</th>\n",
       "      <th>data_loaders</th>\n",
       "      <th>title</th>\n",
       "      <th>paper_url</th>\n",
       "      <th>Texts</th>\n",
       "      <th>Images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://paperswithcode.com/dataset/mnist</td>\n",
       "      <td>MNIST</td>\n",
       "      <td></td>\n",
       "      <td>http://yann.lecun.com/exdb/mnist/</td>\n",
       "      <td>The **MNIST** database (**Modified National In...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[75 Superpixel MNIST, MNIST, MNIST-full, MNIST...</td>\n",
       "      <td>4159</td>\n",
       "      <td>[{'url': 'https://pytorch.org/vision/stable/da...</td>\n",
       "      <td>Gradient-based learning applied to document re...</td>\n",
       "      <td>http://arxiv.org/pdf/1102.0183.pdf</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://paperswithcode.com/dataset/celeba</td>\n",
       "      <td>CelebA</td>\n",
       "      <td>CelebFaces Attributes Dataset</td>\n",
       "      <td>http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html</td>\n",
       "      <td>CelebFaces Attributes dataset contains 202,599...</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[CelebA Aligned, CelebA 64x64, CelebA 256x256,...</td>\n",
       "      <td>1539</td>\n",
       "      <td>[{'url': 'https://pytorch.org/vision/stable/da...</td>\n",
       "      <td>Deep Learning Face Attributes in the Wild</td>\n",
       "      <td>https://paperswithcode.com/paper/deep-learning...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://paperswithcode.com/dataset/imagenet</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td></td>\n",
       "      <td>http://image-net.org/challenges/LSVRC/</td>\n",
       "      <td>The **ImageNet** dataset contains 14,197,122 a...</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[ILSVRC 2015, ILSVRC 2016, ImageNet, ImageNet ...</td>\n",
       "      <td>6081</td>\n",
       "      <td>[{'url': 'https://pytorch.org/vision/stable/da...</td>\n",
       "      <td>ImageNet: A large-scale hierarchical image dat...</td>\n",
       "      <td>https://doi.org/10.1109/CVPR.2009.5206848</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://paperswithcode.com/dataset/penn-treebank</td>\n",
       "      <td>Penn Treebank</td>\n",
       "      <td></td>\n",
       "      <td>https://catalog.ldc.upenn.edu/docs/LDC95T7/cl9...</td>\n",
       "      <td>The English **Penn Treebank** (**PTB**) corpus...</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>[Texts]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PTB dataset, ECG lead II, PTB, Penn Treebank ...</td>\n",
       "      <td>1056</td>\n",
       "      <td>[{'url': 'https://pytorch.org/text/stable/data...</td>\n",
       "      <td>Building a Large Annotated Corpus of English: ...</td>\n",
       "      <td>http://dl.acm.org/citation.cfm?id=972470.972475</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://paperswithcode.com/dataset/lfw</td>\n",
       "      <td>LFW</td>\n",
       "      <td>Labeled Faces in the Wild</td>\n",
       "      <td>http://vis-www.cs.umass.edu/lfw/</td>\n",
       "      <td>The **LFW** dataset contains 13,233 images of ...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[LFW, Labeled Faces in the Wild, LFW (Online O...</td>\n",
       "      <td>576</td>\n",
       "      <td>[{'url': 'https://www.tensorflow.org/datasets/...</td>\n",
       "      <td>Labeled faces in the wild: A database for stud...</td>\n",
       "      <td>http://vis-www.cs.umass.edu/lfw/lfw.pdf</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4347</th>\n",
       "      <td>https://paperswithcode.com/dataset/vindr-ribcxr</td>\n",
       "      <td>VinDr-RibCXR</td>\n",
       "      <td></td>\n",
       "      <td>https://github.com/vinbigdata-medical/MIDL2021...</td>\n",
       "      <td>**VinDr-RibCXR** is a benchmark dataset for au...</td>\n",
       "      <td>2021-07-03</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images, Medical]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[VinDr-RibCXR]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>VinDr-RibCXR: A Benchmark Dataset for Automati...</td>\n",
       "      <td>https://paperswithcode.com/paper/vindr-ribcxr-...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4348</th>\n",
       "      <td>https://paperswithcode.com/dataset/disaster</td>\n",
       "      <td>Disaster</td>\n",
       "      <td></td>\n",
       "      <td>https://niloy193.github.io/Disaster-Dataset/</td>\n",
       "      <td>**Disaster** is a dataset that contains images...</td>\n",
       "      <td>2021-07-02</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Disaster]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>A Novel Disaster Image Dataset and Characteris...</td>\n",
       "      <td>https://paperswithcode.com/paper/a-novel-disas...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4354</th>\n",
       "      <td>https://paperswithcode.com/dataset/mcmd</td>\n",
       "      <td>MCMD</td>\n",
       "      <td>Multi-programming-language Commit Message Dataset</td>\n",
       "      <td>http://doi.org/10.5281/zenodo.5025758</td>\n",
       "      <td>A large-scale dataset in multi-programming lan...</td>\n",
       "      <td>2021-07-12</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[MCMD]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>On the Evaluation of Commit Message Generation...</td>\n",
       "      <td>https://paperswithcode.com/paper/on-the-evalua...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4362</th>\n",
       "      <td>https://paperswithcode.com/dataset/cadsketchnet</td>\n",
       "      <td>CADSketchNet</td>\n",
       "      <td></td>\n",
       "      <td>https://bharadwaj-manda.github.io/CADSketchNet/</td>\n",
       "      <td>CADSketchNet is an annotated collection of ske...</td>\n",
       "      <td>2021-07-13</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[CADSketchNet]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>'CADSketchNet' -- An Annotated Sketch dataset ...</td>\n",
       "      <td>https://paperswithcode.com/paper/cadsketchnet-...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4376</th>\n",
       "      <td>https://paperswithcode.com/dataset/cylinder-in...</td>\n",
       "      <td>Cylinder in Crossflow</td>\n",
       "      <td></td>\n",
       "      <td>https://doi.org/10.7910/DVN/G5MNYF</td>\n",
       "      <td>Click to add a brief description of the datase...</td>\n",
       "      <td>2020-06-11</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Cylinder in Crossflow]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>A Tailored Convolutional Neural Network for No...</td>\n",
       "      <td>https://paperswithcode.com/paper/enabling-nonl...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1180 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    url  \\\n",
       "0              https://paperswithcode.com/dataset/mnist   \n",
       "1             https://paperswithcode.com/dataset/celeba   \n",
       "5           https://paperswithcode.com/dataset/imagenet   \n",
       "6      https://paperswithcode.com/dataset/penn-treebank   \n",
       "8                https://paperswithcode.com/dataset/lfw   \n",
       "...                                                 ...   \n",
       "4347    https://paperswithcode.com/dataset/vindr-ribcxr   \n",
       "4348        https://paperswithcode.com/dataset/disaster   \n",
       "4354            https://paperswithcode.com/dataset/mcmd   \n",
       "4362    https://paperswithcode.com/dataset/cadsketchnet   \n",
       "4376  https://paperswithcode.com/dataset/cylinder-in...   \n",
       "\n",
       "                       name  \\\n",
       "0                     MNIST   \n",
       "1                    CelebA   \n",
       "5                  ImageNet   \n",
       "6             Penn Treebank   \n",
       "8                       LFW   \n",
       "...                     ...   \n",
       "4347           VinDr-RibCXR   \n",
       "4348               Disaster   \n",
       "4354                   MCMD   \n",
       "4362           CADSketchNet   \n",
       "4376  Cylinder in Crossflow   \n",
       "\n",
       "                                              full_name  \\\n",
       "0                                                         \n",
       "1                         CelebFaces Attributes Dataset   \n",
       "5                                                         \n",
       "6                                                         \n",
       "8                             Labeled Faces in the Wild   \n",
       "...                                                 ...   \n",
       "4347                                                      \n",
       "4348                                                      \n",
       "4354  Multi-programming-language Commit Message Dataset   \n",
       "4362                                                      \n",
       "4376                                                      \n",
       "\n",
       "                                               homepage  \\\n",
       "0                     http://yann.lecun.com/exdb/mnist/   \n",
       "1      http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html   \n",
       "5                http://image-net.org/challenges/LSVRC/   \n",
       "6     https://catalog.ldc.upenn.edu/docs/LDC95T7/cl9...   \n",
       "8                      http://vis-www.cs.umass.edu/lfw/   \n",
       "...                                                 ...   \n",
       "4347  https://github.com/vinbigdata-medical/MIDL2021...   \n",
       "4348       https://niloy193.github.io/Disaster-Dataset/   \n",
       "4354              http://doi.org/10.5281/zenodo.5025758   \n",
       "4362    https://bharadwaj-manda.github.io/CADSketchNet/   \n",
       "4376                 https://doi.org/10.7910/DVN/G5MNYF   \n",
       "\n",
       "                                            description introduced_date  \\\n",
       "0     The **MNIST** database (**Modified National In...             NaT   \n",
       "1     CelebFaces Attributes dataset contains 202,599...      2015-01-01   \n",
       "5     The **ImageNet** dataset contains 14,197,122 a...      2009-01-01   \n",
       "6     The English **Penn Treebank** (**PTB**) corpus...      1993-01-01   \n",
       "8     The **LFW** dataset contains 13,233 images of ...             NaT   \n",
       "...                                                 ...             ...   \n",
       "4347  **VinDr-RibCXR** is a benchmark dataset for au...      2021-07-03   \n",
       "4348  **Disaster** is a dataset that contains images...      2021-07-02   \n",
       "4354  A large-scale dataset in multi-programming lan...      2021-07-12   \n",
       "4362  CADSketchNet is an annotated collection of ske...      2021-07-13   \n",
       "4376  Click to add a brief description of the datase...      2020-06-11   \n",
       "\n",
       "     warning         modalities  languages  \\\n",
       "0       None           [Images]         []   \n",
       "1       None           [Images]         []   \n",
       "5       None           [Images]  [English]   \n",
       "6       None            [Texts]         []   \n",
       "8       None           [Images]         []   \n",
       "...      ...                ...        ...   \n",
       "4347    None  [Images, Medical]         []   \n",
       "4348    None           [Images]         []   \n",
       "4354    None                 []         []   \n",
       "4362    None                 []         []   \n",
       "4376    None                 []         []   \n",
       "\n",
       "                                               variants  num_papers  \\\n",
       "0     [75 Superpixel MNIST, MNIST, MNIST-full, MNIST...        4159   \n",
       "1     [CelebA Aligned, CelebA 64x64, CelebA 256x256,...        1539   \n",
       "5     [ILSVRC 2015, ILSVRC 2016, ImageNet, ImageNet ...        6081   \n",
       "6     [PTB dataset, ECG lead II, PTB, Penn Treebank ...        1056   \n",
       "8     [LFW, Labeled Faces in the Wild, LFW (Online O...         576   \n",
       "...                                                 ...         ...   \n",
       "4347                                     [VinDr-RibCXR]           1   \n",
       "4348                                         [Disaster]           1   \n",
       "4354                                             [MCMD]           1   \n",
       "4362                                     [CADSketchNet]           1   \n",
       "4376                            [Cylinder in Crossflow]           1   \n",
       "\n",
       "                                           data_loaders  \\\n",
       "0     [{'url': 'https://pytorch.org/vision/stable/da...   \n",
       "1     [{'url': 'https://pytorch.org/vision/stable/da...   \n",
       "5     [{'url': 'https://pytorch.org/vision/stable/da...   \n",
       "6     [{'url': 'https://pytorch.org/text/stable/data...   \n",
       "8     [{'url': 'https://www.tensorflow.org/datasets/...   \n",
       "...                                                 ...   \n",
       "4347                                                 []   \n",
       "4348                                                 []   \n",
       "4354                                                 []   \n",
       "4362                                                 []   \n",
       "4376                                                 []   \n",
       "\n",
       "                                                  title  \\\n",
       "0     Gradient-based learning applied to document re...   \n",
       "1             Deep Learning Face Attributes in the Wild   \n",
       "5     ImageNet: A large-scale hierarchical image dat...   \n",
       "6     Building a Large Annotated Corpus of English: ...   \n",
       "8     Labeled faces in the wild: A database for stud...   \n",
       "...                                                 ...   \n",
       "4347  VinDr-RibCXR: A Benchmark Dataset for Automati...   \n",
       "4348  A Novel Disaster Image Dataset and Characteris...   \n",
       "4354  On the Evaluation of Commit Message Generation...   \n",
       "4362  'CADSketchNet' -- An Annotated Sketch dataset ...   \n",
       "4376  A Tailored Convolutional Neural Network for No...   \n",
       "\n",
       "                                              paper_url  Texts  Images  \n",
       "0                    http://arxiv.org/pdf/1102.0183.pdf  False    True  \n",
       "1     https://paperswithcode.com/paper/deep-learning...  False    True  \n",
       "5             https://doi.org/10.1109/CVPR.2009.5206848  False    True  \n",
       "6       http://dl.acm.org/citation.cfm?id=972470.972475   True   False  \n",
       "8               http://vis-www.cs.umass.edu/lfw/lfw.pdf  False    True  \n",
       "...                                                 ...    ...     ...  \n",
       "4347  https://paperswithcode.com/paper/vindr-ribcxr-...  False    True  \n",
       "4348  https://paperswithcode.com/paper/a-novel-disas...  False    True  \n",
       "4354  https://paperswithcode.com/paper/on-the-evalua...  False   False  \n",
       "4362  https://paperswithcode.com/paper/cadsketchnet-...  False   False  \n",
       "4376  https://paperswithcode.com/paper/enabling-nonl...  False   False  \n",
       "\n",
       "[1180 rows x 16 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#temp=datasets[~datasets.title.isnull()]\n",
    "#datasets[datasets.name.isin(untasked_datasets) & (~datasets.title.isnull())]\n",
    "untasked_dataset_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16eb5ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>pwc_dataset_id</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>is_problematic</th>\n",
       "      <th>paper_count</th>\n",
       "      <th>task</th>\n",
       "      <th>categories</th>\n",
       "      <th>parents</th>\n",
       "      <th>children</th>\n",
       "      <th>siblings</th>\n",
       "      <th>pdf_url</th>\n",
       "      <th>paper_url</th>\n",
       "      <th>all_tasks</th>\n",
       "      <th>all_parents</th>\n",
       "      <th>all_children</th>\n",
       "      <th>all_siblings</th>\n",
       "      <th>all_categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13020</th>\n",
       "      <td>CelebA</td>\n",
       "      <td>2</td>\n",
       "      <td>Leveraging Mid-Level Deep Representations For ...</td>\n",
       "      <td>2016-02-04</td>\n",
       "      <td>False</td>\n",
       "      <td>1539</td>\n",
       "      <td>Face Recognition</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Robust Face Alignment, Robust Face Recognitio...</td>\n",
       "      <td>http://arxiv.org/pdf/1602.01827v3.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/leveraging-mi...</td>\n",
       "      <td>[Face Recognition, Image Classification]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Learning with noisy labels, Artist classifica...</td>\n",
       "      <td>[Robust Face Alignment, Robust Face Recognitio...</td>\n",
       "      <td>[Computer Vision, Methodology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13021</th>\n",
       "      <td>CelebA</td>\n",
       "      <td>2</td>\n",
       "      <td>Leveraging Mid-Level Deep Representations For ...</td>\n",
       "      <td>2016-02-04</td>\n",
       "      <td>False</td>\n",
       "      <td>1539</td>\n",
       "      <td>Image Classification</td>\n",
       "      <td>[Computer Vision, Methodology]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Few-Shot Image Classification, Fine-Grained I...</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://arxiv.org/pdf/1602.01827v3.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/leveraging-mi...</td>\n",
       "      <td>[Face Recognition, Image Classification]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Learning with noisy labels, Artist classifica...</td>\n",
       "      <td>[Robust Face Alignment, Robust Face Recognitio...</td>\n",
       "      <td>[Computer Vision, Methodology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13024</th>\n",
       "      <td>CelebA</td>\n",
       "      <td>2</td>\n",
       "      <td>Face Attribute Prediction Using Off-the-Shelf ...</td>\n",
       "      <td>2016-02-12</td>\n",
       "      <td>False</td>\n",
       "      <td>1539</td>\n",
       "      <td>Face Recognition</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Robust Face Alignment, Robust Face Recognitio...</td>\n",
       "      <td>http://arxiv.org/pdf/1602.03935v2.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/face-attribut...</td>\n",
       "      <td>[Face Recognition, General Classification]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Constructive Comment Classification, Face Qua...</td>\n",
       "      <td>[Robust Face Alignment, Robust Face Recognitio...</td>\n",
       "      <td>[Computer Vision, Methodology, Natural Languag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13025</th>\n",
       "      <td>CelebA</td>\n",
       "      <td>2</td>\n",
       "      <td>Face Attribute Prediction Using Off-the-Shelf ...</td>\n",
       "      <td>2016-02-12</td>\n",
       "      <td>False</td>\n",
       "      <td>1539</td>\n",
       "      <td>General Classification</td>\n",
       "      <td>[Natural Language Processing, Methodology]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Constructive Comment Classification]</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://arxiv.org/pdf/1602.03935v2.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/face-attribut...</td>\n",
       "      <td>[Face Recognition, General Classification]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Constructive Comment Classification, Face Qua...</td>\n",
       "      <td>[Robust Face Alignment, Robust Face Recognitio...</td>\n",
       "      <td>[Computer Vision, Methodology, Natural Languag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12633</th>\n",
       "      <td>CelebA</td>\n",
       "      <td>2</td>\n",
       "      <td>HyperFace: A Deep Multi-task Learning Framewor...</td>\n",
       "      <td>2016-03-03</td>\n",
       "      <td>False</td>\n",
       "      <td>1539</td>\n",
       "      <td>Multi-Task Learning</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Transfer Learning]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Unsupervised Domain Expansion, Auxiliary Lear...</td>\n",
       "      <td>http://arxiv.org/pdf/1603.01249v3.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/hyperface-a-d...</td>\n",
       "      <td>[Face Detection, Multi-Task Learning, Pose Est...</td>\n",
       "      <td>[2D Human Pose Estimation, Transfer Learning, ...</td>\n",
       "      <td>[6D Pose Estimation using RGBD, 3D Pose Estima...</td>\n",
       "      <td>[Robust Face Alignment, Robust Face Recognitio...</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12632</th>\n",
       "      <td>CelebA</td>\n",
       "      <td>2</td>\n",
       "      <td>HyperFace: A Deep Multi-task Learning Framewor...</td>\n",
       "      <td>2016-03-03</td>\n",
       "      <td>False</td>\n",
       "      <td>1539</td>\n",
       "      <td>Face Detection</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Occluded Face Detection]</td>\n",
       "      <td>[Robust Face Alignment, Robust Face Recognitio...</td>\n",
       "      <td>http://arxiv.org/pdf/1603.01249v3.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/hyperface-a-d...</td>\n",
       "      <td>[Face Detection, Multi-Task Learning, Pose Est...</td>\n",
       "      <td>[2D Human Pose Estimation, Transfer Learning, ...</td>\n",
       "      <td>[6D Pose Estimation using RGBD, 3D Pose Estima...</td>\n",
       "      <td>[Robust Face Alignment, Robust Face Recognitio...</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12634</th>\n",
       "      <td>CelebA</td>\n",
       "      <td>2</td>\n",
       "      <td>HyperFace: A Deep Multi-task Learning Framewor...</td>\n",
       "      <td>2016-03-03</td>\n",
       "      <td>False</td>\n",
       "      <td>1539</td>\n",
       "      <td>Pose Estimation</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[2D Human Pose Estimation]</td>\n",
       "      <td>[3D Human Pose Estimation, Keypoint Detection,...</td>\n",
       "      <td>[Pose Estimation, 3D Face Animation]</td>\n",
       "      <td>http://arxiv.org/pdf/1603.01249v3.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/hyperface-a-d...</td>\n",
       "      <td>[Face Detection, Multi-Task Learning, Pose Est...</td>\n",
       "      <td>[2D Human Pose Estimation, Transfer Learning, ...</td>\n",
       "      <td>[6D Pose Estimation using RGBD, 3D Pose Estima...</td>\n",
       "      <td>[Robust Face Alignment, Robust Face Recognitio...</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13003</th>\n",
       "      <td>CelebA</td>\n",
       "      <td>2</td>\n",
       "      <td>MOON: A Mixed Objective Optimization Network f...</td>\n",
       "      <td>2016-03-22</td>\n",
       "      <td>False</td>\n",
       "      <td>1539</td>\n",
       "      <td>Face Recognition</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Age-Invariant Face Recognition, Face Quality ...</td>\n",
       "      <td>[Robust Face Alignment, Robust Face Recognitio...</td>\n",
       "      <td>http://arxiv.org/pdf/1603.07027v2.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/moon-a-mixed-...</td>\n",
       "      <td>[Face Recognition]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Face Quality Assessement, Age-Invariant Face ...</td>\n",
       "      <td>[Robust Face Alignment, Robust Face Recognitio...</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13033</th>\n",
       "      <td>CelebA</td>\n",
       "      <td>2</td>\n",
       "      <td>Joint Face Detection and Alignment using Multi...</td>\n",
       "      <td>2016-04-11</td>\n",
       "      <td>False</td>\n",
       "      <td>1539</td>\n",
       "      <td>Face Alignment</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Robust Face Alignment, Robust Face Recognitio...</td>\n",
       "      <td>http://arxiv.org/pdf/1604.02878v1.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/joint-face-de...</td>\n",
       "      <td>[Face Alignment, Face Detection]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Occluded Face Detection]</td>\n",
       "      <td>[Robust Face Alignment, Robust Face Recognitio...</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13032</th>\n",
       "      <td>CelebA</td>\n",
       "      <td>2</td>\n",
       "      <td>Joint Face Detection and Alignment using Multi...</td>\n",
       "      <td>2016-04-11</td>\n",
       "      <td>False</td>\n",
       "      <td>1539</td>\n",
       "      <td>Face Detection</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Occluded Face Detection]</td>\n",
       "      <td>[Robust Face Alignment, Robust Face Recognitio...</td>\n",
       "      <td>http://arxiv.org/pdf/1604.02878v1.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/joint-face-de...</td>\n",
       "      <td>[Face Alignment, Face Detection]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Occluded Face Detection]</td>\n",
       "      <td>[Robust Face Alignment, Robust Face Recognitio...</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13018</th>\n",
       "      <td>CelebA</td>\n",
       "      <td>2</td>\n",
       "      <td>Walk and Learn: Facial Attribute Representatio...</td>\n",
       "      <td>2016-04-21</td>\n",
       "      <td>False</td>\n",
       "      <td>1539</td>\n",
       "      <td>Facial Attribute Classification</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Robust Face Alignment, Robust Face Recognitio...</td>\n",
       "      <td>http://arxiv.org/pdf/1604.06433v3.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/walk-and-lear...</td>\n",
       "      <td>[Facial Attribute Classification, Representati...</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Learning Representation Of Multi-View Data, S...</td>\n",
       "      <td>[Robust Face Alignment, Robust Face Recognitio...</td>\n",
       "      <td>[Methodology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13019</th>\n",
       "      <td>CelebA</td>\n",
       "      <td>2</td>\n",
       "      <td>Walk and Learn: Facial Attribute Representatio...</td>\n",
       "      <td>2016-04-21</td>\n",
       "      <td>False</td>\n",
       "      <td>1539</td>\n",
       "      <td>Representation Learning</td>\n",
       "      <td>[Methodology]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Word Embeddings, Graph Embedding, Graph Repre...</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://arxiv.org/pdf/1604.06433v3.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/walk-and-lear...</td>\n",
       "      <td>[Facial Attribute Classification, Representati...</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Learning Representation Of Multi-View Data, S...</td>\n",
       "      <td>[Robust Face Alignment, Robust Face Recognitio...</td>\n",
       "      <td>[Methodology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13031</th>\n",
       "      <td>CelebA</td>\n",
       "      <td>2</td>\n",
       "      <td>Attributes for Improved Attributes: A Multi-Ta...</td>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>False</td>\n",
       "      <td>1539</td>\n",
       "      <td>General Classification</td>\n",
       "      <td>[Natural Language Processing, Methodology]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Constructive Comment Classification]</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://arxiv.org/pdf/1604.07360v1.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/attributes-fo...</td>\n",
       "      <td>[Activity Recognition, Face Verification, Gene...</td>\n",
       "      <td>[3D, Facial Recognition and Modelling]</td>\n",
       "      <td>[Multimodal Activity Recognition, Group Activi...</td>\n",
       "      <td>[Robust Face Alignment, Robust Face Recognitio...</td>\n",
       "      <td>[Computer Vision, Methodology, Natural Languag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13030</th>\n",
       "      <td>CelebA</td>\n",
       "      <td>2</td>\n",
       "      <td>Attributes for Improved Attributes: A Multi-Ta...</td>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>False</td>\n",
       "      <td>1539</td>\n",
       "      <td>Activity Recognition</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Action Recognition, Multimodal Activity Recog...</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://arxiv.org/pdf/1604.07360v1.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/attributes-fo...</td>\n",
       "      <td>[Activity Recognition, Face Verification, Gene...</td>\n",
       "      <td>[3D, Facial Recognition and Modelling]</td>\n",
       "      <td>[Multimodal Activity Recognition, Group Activi...</td>\n",
       "      <td>[Robust Face Alignment, Robust Face Recognitio...</td>\n",
       "      <td>[Computer Vision, Methodology, Natural Languag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13029</th>\n",
       "      <td>CelebA</td>\n",
       "      <td>2</td>\n",
       "      <td>Attributes for Improved Attributes: A Multi-Ta...</td>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>False</td>\n",
       "      <td>1539</td>\n",
       "      <td>Face Verification</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[Facial Recognition and Modelling, 3D]</td>\n",
       "      <td>[Disguised Face Verification]</td>\n",
       "      <td>[Robust Face Alignment, Robust Face Recognitio...</td>\n",
       "      <td>http://arxiv.org/pdf/1604.07360v1.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/attributes-fo...</td>\n",
       "      <td>[Activity Recognition, Face Verification, Gene...</td>\n",
       "      <td>[3D, Facial Recognition and Modelling]</td>\n",
       "      <td>[Multimodal Activity Recognition, Group Activi...</td>\n",
       "      <td>[Robust Face Alignment, Robust Face Recognitio...</td>\n",
       "      <td>[Computer Vision, Methodology, Natural Languag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13011</th>\n",
       "      <td>CelebA</td>\n",
       "      <td>2</td>\n",
       "      <td>Are Facial Attributes Adversarially Robust?</td>\n",
       "      <td>2016-05-18</td>\n",
       "      <td>False</td>\n",
       "      <td>1539</td>\n",
       "      <td>Facial Attribute Classification</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Robust Face Alignment, Robust Face Recognitio...</td>\n",
       "      <td>http://arxiv.org/pdf/1605.05411v3.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/are-facial-at...</td>\n",
       "      <td>[Facial Attribute Classification, General Clas...</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Constructive Comment Classification]</td>\n",
       "      <td>[Robust Face Alignment, Robust Face Recognitio...</td>\n",
       "      <td>[Natural Language Processing, Methodology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13012</th>\n",
       "      <td>CelebA</td>\n",
       "      <td>2</td>\n",
       "      <td>Are Facial Attributes Adversarially Robust?</td>\n",
       "      <td>2016-05-18</td>\n",
       "      <td>False</td>\n",
       "      <td>1539</td>\n",
       "      <td>General Classification</td>\n",
       "      <td>[Natural Language Processing, Methodology]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Constructive Comment Classification]</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://arxiv.org/pdf/1605.05411v3.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/are-facial-at...</td>\n",
       "      <td>[Facial Attribute Classification, General Clas...</td>\n",
       "      <td>[Facial Recognition and Modelling]</td>\n",
       "      <td>[Constructive Comment Classification]</td>\n",
       "      <td>[Robust Face Alignment, Robust Face Recognitio...</td>\n",
       "      <td>[Natural Language Processing, Methodology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12925</th>\n",
       "      <td>CelebA</td>\n",
       "      <td>2</td>\n",
       "      <td>Density estimation using Real NVP</td>\n",
       "      <td>2016-05-27</td>\n",
       "      <td>False</td>\n",
       "      <td>1539</td>\n",
       "      <td>Image Generation</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[3D Face Animation]</td>\n",
       "      <td>[Image-to-Image Translation, Image Inpainting,...</td>\n",
       "      <td>[Dialogue Generation, Image Generation, Image ...</td>\n",
       "      <td>http://arxiv.org/pdf/1605.08803v3.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/density-estim...</td>\n",
       "      <td>[Density Estimation, Image Generation]</td>\n",
       "      <td>[3D Face Animation]</td>\n",
       "      <td>[User Constrained Thumbnail Generation, Layout...</td>\n",
       "      <td>[Dialogue Generation, Image Generation, Image ...</td>\n",
       "      <td>[Computer Vision, Methodology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12926</th>\n",
       "      <td>CelebA</td>\n",
       "      <td>2</td>\n",
       "      <td>Density estimation using Real NVP</td>\n",
       "      <td>2016-05-27</td>\n",
       "      <td>False</td>\n",
       "      <td>1539</td>\n",
       "      <td>Density Estimation</td>\n",
       "      <td>[Methodology]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Arbitrary Conditional Density Estimation]</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://arxiv.org/pdf/1605.08803v3.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/density-estim...</td>\n",
       "      <td>[Density Estimation, Image Generation]</td>\n",
       "      <td>[3D Face Animation]</td>\n",
       "      <td>[User Constrained Thumbnail Generation, Layout...</td>\n",
       "      <td>[Dialogue Generation, Image Generation, Image ...</td>\n",
       "      <td>[Computer Vision, Methodology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13585</th>\n",
       "      <td>CelebA</td>\n",
       "      <td>2</td>\n",
       "      <td>Learning Deep Representation for Imbalanced Cl...</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>False</td>\n",
       "      <td>1539</td>\n",
       "      <td>Representation Learning</td>\n",
       "      <td>[Methodology]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Word Embeddings, Graph Embedding, Graph Repre...</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://openaccess.thecvf.com/content_cvpr_2016...</td>\n",
       "      <td>https://paperswithcode.com/paper/learning-deep...</td>\n",
       "      <td>[General Classification, imbalanced classifica...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Learning Representation Of Multi-View Data, S...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Natural Language Processing, Miscellaneous, M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name  pwc_dataset_id  \\\n",
       "13020  CelebA               2   \n",
       "13021  CelebA               2   \n",
       "13024  CelebA               2   \n",
       "13025  CelebA               2   \n",
       "12633  CelebA               2   \n",
       "12632  CelebA               2   \n",
       "12634  CelebA               2   \n",
       "13003  CelebA               2   \n",
       "13033  CelebA               2   \n",
       "13032  CelebA               2   \n",
       "13018  CelebA               2   \n",
       "13019  CelebA               2   \n",
       "13031  CelebA               2   \n",
       "13030  CelebA               2   \n",
       "13029  CelebA               2   \n",
       "13011  CelebA               2   \n",
       "13012  CelebA               2   \n",
       "12925  CelebA               2   \n",
       "12926  CelebA               2   \n",
       "13585  CelebA               2   \n",
       "\n",
       "                                                   title       date  \\\n",
       "13020  Leveraging Mid-Level Deep Representations For ... 2016-02-04   \n",
       "13021  Leveraging Mid-Level Deep Representations For ... 2016-02-04   \n",
       "13024  Face Attribute Prediction Using Off-the-Shelf ... 2016-02-12   \n",
       "13025  Face Attribute Prediction Using Off-the-Shelf ... 2016-02-12   \n",
       "12633  HyperFace: A Deep Multi-task Learning Framewor... 2016-03-03   \n",
       "12632  HyperFace: A Deep Multi-task Learning Framewor... 2016-03-03   \n",
       "12634  HyperFace: A Deep Multi-task Learning Framewor... 2016-03-03   \n",
       "13003  MOON: A Mixed Objective Optimization Network f... 2016-03-22   \n",
       "13033  Joint Face Detection and Alignment using Multi... 2016-04-11   \n",
       "13032  Joint Face Detection and Alignment using Multi... 2016-04-11   \n",
       "13018  Walk and Learn: Facial Attribute Representatio... 2016-04-21   \n",
       "13019  Walk and Learn: Facial Attribute Representatio... 2016-04-21   \n",
       "13031  Attributes for Improved Attributes: A Multi-Ta... 2016-04-25   \n",
       "13030  Attributes for Improved Attributes: A Multi-Ta... 2016-04-25   \n",
       "13029  Attributes for Improved Attributes: A Multi-Ta... 2016-04-25   \n",
       "13011        Are Facial Attributes Adversarially Robust? 2016-05-18   \n",
       "13012        Are Facial Attributes Adversarially Robust? 2016-05-18   \n",
       "12925                  Density estimation using Real NVP 2016-05-27   \n",
       "12926                  Density estimation using Real NVP 2016-05-27   \n",
       "13585  Learning Deep Representation for Imbalanced Cl... 2016-06-01   \n",
       "\n",
       "       is_problematic  paper_count                             task  \\\n",
       "13020           False         1539                 Face Recognition   \n",
       "13021           False         1539             Image Classification   \n",
       "13024           False         1539                 Face Recognition   \n",
       "13025           False         1539           General Classification   \n",
       "12633           False         1539              Multi-Task Learning   \n",
       "12632           False         1539                   Face Detection   \n",
       "12634           False         1539                  Pose Estimation   \n",
       "13003           False         1539                 Face Recognition   \n",
       "13033           False         1539                   Face Alignment   \n",
       "13032           False         1539                   Face Detection   \n",
       "13018           False         1539  Facial Attribute Classification   \n",
       "13019           False         1539          Representation Learning   \n",
       "13031           False         1539           General Classification   \n",
       "13030           False         1539             Activity Recognition   \n",
       "13029           False         1539                Face Verification   \n",
       "13011           False         1539  Facial Attribute Classification   \n",
       "13012           False         1539           General Classification   \n",
       "12925           False         1539                 Image Generation   \n",
       "12926           False         1539               Density Estimation   \n",
       "13585           False         1539          Representation Learning   \n",
       "\n",
       "                                       categories  \\\n",
       "13020                           [Computer Vision]   \n",
       "13021              [Computer Vision, Methodology]   \n",
       "13024                           [Computer Vision]   \n",
       "13025  [Natural Language Processing, Methodology]   \n",
       "12633                                          []   \n",
       "12632                           [Computer Vision]   \n",
       "12634                           [Computer Vision]   \n",
       "13003                           [Computer Vision]   \n",
       "13033                                          []   \n",
       "13032                           [Computer Vision]   \n",
       "13018                                          []   \n",
       "13019                               [Methodology]   \n",
       "13031  [Natural Language Processing, Methodology]   \n",
       "13030                           [Computer Vision]   \n",
       "13029                           [Computer Vision]   \n",
       "13011                                          []   \n",
       "13012  [Natural Language Processing, Methodology]   \n",
       "12925                           [Computer Vision]   \n",
       "12926                               [Methodology]   \n",
       "13585                               [Methodology]   \n",
       "\n",
       "                                      parents  \\\n",
       "13020      [Facial Recognition and Modelling]   \n",
       "13021                                      []   \n",
       "13024      [Facial Recognition and Modelling]   \n",
       "13025                                      []   \n",
       "12633                     [Transfer Learning]   \n",
       "12632      [Facial Recognition and Modelling]   \n",
       "12634              [2D Human Pose Estimation]   \n",
       "13003      [Facial Recognition and Modelling]   \n",
       "13033      [Facial Recognition and Modelling]   \n",
       "13032      [Facial Recognition and Modelling]   \n",
       "13018      [Facial Recognition and Modelling]   \n",
       "13019                                      []   \n",
       "13031                                      []   \n",
       "13030                                      []   \n",
       "13029  [Facial Recognition and Modelling, 3D]   \n",
       "13011      [Facial Recognition and Modelling]   \n",
       "13012                                      []   \n",
       "12925                     [3D Face Animation]   \n",
       "12926                                      []   \n",
       "13585                                      []   \n",
       "\n",
       "                                                children  \\\n",
       "13020  [Age-Invariant Face Recognition, Face Quality ...   \n",
       "13021  [Few-Shot Image Classification, Fine-Grained I...   \n",
       "13024  [Age-Invariant Face Recognition, Face Quality ...   \n",
       "13025              [Constructive Comment Classification]   \n",
       "12633                                                 []   \n",
       "12632                          [Occluded Face Detection]   \n",
       "12634  [3D Human Pose Estimation, Keypoint Detection,...   \n",
       "13003  [Age-Invariant Face Recognition, Face Quality ...   \n",
       "13033                                                 []   \n",
       "13032                          [Occluded Face Detection]   \n",
       "13018                                                 []   \n",
       "13019  [Word Embeddings, Graph Embedding, Graph Repre...   \n",
       "13031              [Constructive Comment Classification]   \n",
       "13030  [Action Recognition, Multimodal Activity Recog...   \n",
       "13029                      [Disguised Face Verification]   \n",
       "13011                                                 []   \n",
       "13012              [Constructive Comment Classification]   \n",
       "12925  [Image-to-Image Translation, Image Inpainting,...   \n",
       "12926         [Arbitrary Conditional Density Estimation]   \n",
       "13585  [Word Embeddings, Graph Embedding, Graph Repre...   \n",
       "\n",
       "                                                siblings  \\\n",
       "13020  [Robust Face Alignment, Robust Face Recognitio...   \n",
       "13021                                                 []   \n",
       "13024  [Robust Face Alignment, Robust Face Recognitio...   \n",
       "13025                                                 []   \n",
       "12633  [Unsupervised Domain Expansion, Auxiliary Lear...   \n",
       "12632  [Robust Face Alignment, Robust Face Recognitio...   \n",
       "12634               [Pose Estimation, 3D Face Animation]   \n",
       "13003  [Robust Face Alignment, Robust Face Recognitio...   \n",
       "13033  [Robust Face Alignment, Robust Face Recognitio...   \n",
       "13032  [Robust Face Alignment, Robust Face Recognitio...   \n",
       "13018  [Robust Face Alignment, Robust Face Recognitio...   \n",
       "13019                                                 []   \n",
       "13031                                                 []   \n",
       "13030                                                 []   \n",
       "13029  [Robust Face Alignment, Robust Face Recognitio...   \n",
       "13011  [Robust Face Alignment, Robust Face Recognitio...   \n",
       "13012                                                 []   \n",
       "12925  [Dialogue Generation, Image Generation, Image ...   \n",
       "12926                                                 []   \n",
       "13585                                                 []   \n",
       "\n",
       "                                                 pdf_url  \\\n",
       "13020              http://arxiv.org/pdf/1602.01827v3.pdf   \n",
       "13021              http://arxiv.org/pdf/1602.01827v3.pdf   \n",
       "13024              http://arxiv.org/pdf/1602.03935v2.pdf   \n",
       "13025              http://arxiv.org/pdf/1602.03935v2.pdf   \n",
       "12633              http://arxiv.org/pdf/1603.01249v3.pdf   \n",
       "12632              http://arxiv.org/pdf/1603.01249v3.pdf   \n",
       "12634              http://arxiv.org/pdf/1603.01249v3.pdf   \n",
       "13003              http://arxiv.org/pdf/1603.07027v2.pdf   \n",
       "13033              http://arxiv.org/pdf/1604.02878v1.pdf   \n",
       "13032              http://arxiv.org/pdf/1604.02878v1.pdf   \n",
       "13018              http://arxiv.org/pdf/1604.06433v3.pdf   \n",
       "13019              http://arxiv.org/pdf/1604.06433v3.pdf   \n",
       "13031              http://arxiv.org/pdf/1604.07360v1.pdf   \n",
       "13030              http://arxiv.org/pdf/1604.07360v1.pdf   \n",
       "13029              http://arxiv.org/pdf/1604.07360v1.pdf   \n",
       "13011              http://arxiv.org/pdf/1605.05411v3.pdf   \n",
       "13012              http://arxiv.org/pdf/1605.05411v3.pdf   \n",
       "12925              http://arxiv.org/pdf/1605.08803v3.pdf   \n",
       "12926              http://arxiv.org/pdf/1605.08803v3.pdf   \n",
       "13585  http://openaccess.thecvf.com/content_cvpr_2016...   \n",
       "\n",
       "                                               paper_url  \\\n",
       "13020  https://paperswithcode.com/paper/leveraging-mi...   \n",
       "13021  https://paperswithcode.com/paper/leveraging-mi...   \n",
       "13024  https://paperswithcode.com/paper/face-attribut...   \n",
       "13025  https://paperswithcode.com/paper/face-attribut...   \n",
       "12633  https://paperswithcode.com/paper/hyperface-a-d...   \n",
       "12632  https://paperswithcode.com/paper/hyperface-a-d...   \n",
       "12634  https://paperswithcode.com/paper/hyperface-a-d...   \n",
       "13003  https://paperswithcode.com/paper/moon-a-mixed-...   \n",
       "13033  https://paperswithcode.com/paper/joint-face-de...   \n",
       "13032  https://paperswithcode.com/paper/joint-face-de...   \n",
       "13018  https://paperswithcode.com/paper/walk-and-lear...   \n",
       "13019  https://paperswithcode.com/paper/walk-and-lear...   \n",
       "13031  https://paperswithcode.com/paper/attributes-fo...   \n",
       "13030  https://paperswithcode.com/paper/attributes-fo...   \n",
       "13029  https://paperswithcode.com/paper/attributes-fo...   \n",
       "13011  https://paperswithcode.com/paper/are-facial-at...   \n",
       "13012  https://paperswithcode.com/paper/are-facial-at...   \n",
       "12925  https://paperswithcode.com/paper/density-estim...   \n",
       "12926  https://paperswithcode.com/paper/density-estim...   \n",
       "13585  https://paperswithcode.com/paper/learning-deep...   \n",
       "\n",
       "                                               all_tasks  \\\n",
       "13020           [Face Recognition, Image Classification]   \n",
       "13021           [Face Recognition, Image Classification]   \n",
       "13024         [Face Recognition, General Classification]   \n",
       "13025         [Face Recognition, General Classification]   \n",
       "12633  [Face Detection, Multi-Task Learning, Pose Est...   \n",
       "12632  [Face Detection, Multi-Task Learning, Pose Est...   \n",
       "12634  [Face Detection, Multi-Task Learning, Pose Est...   \n",
       "13003                                 [Face Recognition]   \n",
       "13033                   [Face Alignment, Face Detection]   \n",
       "13032                   [Face Alignment, Face Detection]   \n",
       "13018  [Facial Attribute Classification, Representati...   \n",
       "13019  [Facial Attribute Classification, Representati...   \n",
       "13031  [Activity Recognition, Face Verification, Gene...   \n",
       "13030  [Activity Recognition, Face Verification, Gene...   \n",
       "13029  [Activity Recognition, Face Verification, Gene...   \n",
       "13011  [Facial Attribute Classification, General Clas...   \n",
       "13012  [Facial Attribute Classification, General Clas...   \n",
       "12925             [Density Estimation, Image Generation]   \n",
       "12926             [Density Estimation, Image Generation]   \n",
       "13585  [General Classification, imbalanced classifica...   \n",
       "\n",
       "                                             all_parents  \\\n",
       "13020                 [Facial Recognition and Modelling]   \n",
       "13021                 [Facial Recognition and Modelling]   \n",
       "13024                 [Facial Recognition and Modelling]   \n",
       "13025                 [Facial Recognition and Modelling]   \n",
       "12633  [2D Human Pose Estimation, Transfer Learning, ...   \n",
       "12632  [2D Human Pose Estimation, Transfer Learning, ...   \n",
       "12634  [2D Human Pose Estimation, Transfer Learning, ...   \n",
       "13003                 [Facial Recognition and Modelling]   \n",
       "13033                 [Facial Recognition and Modelling]   \n",
       "13032                 [Facial Recognition and Modelling]   \n",
       "13018                 [Facial Recognition and Modelling]   \n",
       "13019                 [Facial Recognition and Modelling]   \n",
       "13031             [3D, Facial Recognition and Modelling]   \n",
       "13030             [3D, Facial Recognition and Modelling]   \n",
       "13029             [3D, Facial Recognition and Modelling]   \n",
       "13011                 [Facial Recognition and Modelling]   \n",
       "13012                 [Facial Recognition and Modelling]   \n",
       "12925                                [3D Face Animation]   \n",
       "12926                                [3D Face Animation]   \n",
       "13585                                                 []   \n",
       "\n",
       "                                            all_children  \\\n",
       "13020  [Learning with noisy labels, Artist classifica...   \n",
       "13021  [Learning with noisy labels, Artist classifica...   \n",
       "13024  [Constructive Comment Classification, Face Qua...   \n",
       "13025  [Constructive Comment Classification, Face Qua...   \n",
       "12633  [6D Pose Estimation using RGBD, 3D Pose Estima...   \n",
       "12632  [6D Pose Estimation using RGBD, 3D Pose Estima...   \n",
       "12634  [6D Pose Estimation using RGBD, 3D Pose Estima...   \n",
       "13003  [Face Quality Assessement, Age-Invariant Face ...   \n",
       "13033                          [Occluded Face Detection]   \n",
       "13032                          [Occluded Face Detection]   \n",
       "13018  [Learning Representation Of Multi-View Data, S...   \n",
       "13019  [Learning Representation Of Multi-View Data, S...   \n",
       "13031  [Multimodal Activity Recognition, Group Activi...   \n",
       "13030  [Multimodal Activity Recognition, Group Activi...   \n",
       "13029  [Multimodal Activity Recognition, Group Activi...   \n",
       "13011              [Constructive Comment Classification]   \n",
       "13012              [Constructive Comment Classification]   \n",
       "12925  [User Constrained Thumbnail Generation, Layout...   \n",
       "12926  [User Constrained Thumbnail Generation, Layout...   \n",
       "13585  [Learning Representation Of Multi-View Data, S...   \n",
       "\n",
       "                                            all_siblings  \\\n",
       "13020  [Robust Face Alignment, Robust Face Recognitio...   \n",
       "13021  [Robust Face Alignment, Robust Face Recognitio...   \n",
       "13024  [Robust Face Alignment, Robust Face Recognitio...   \n",
       "13025  [Robust Face Alignment, Robust Face Recognitio...   \n",
       "12633  [Robust Face Alignment, Robust Face Recognitio...   \n",
       "12632  [Robust Face Alignment, Robust Face Recognitio...   \n",
       "12634  [Robust Face Alignment, Robust Face Recognitio...   \n",
       "13003  [Robust Face Alignment, Robust Face Recognitio...   \n",
       "13033  [Robust Face Alignment, Robust Face Recognitio...   \n",
       "13032  [Robust Face Alignment, Robust Face Recognitio...   \n",
       "13018  [Robust Face Alignment, Robust Face Recognitio...   \n",
       "13019  [Robust Face Alignment, Robust Face Recognitio...   \n",
       "13031  [Robust Face Alignment, Robust Face Recognitio...   \n",
       "13030  [Robust Face Alignment, Robust Face Recognitio...   \n",
       "13029  [Robust Face Alignment, Robust Face Recognitio...   \n",
       "13011  [Robust Face Alignment, Robust Face Recognitio...   \n",
       "13012  [Robust Face Alignment, Robust Face Recognitio...   \n",
       "12925  [Dialogue Generation, Image Generation, Image ...   \n",
       "12926  [Dialogue Generation, Image Generation, Image ...   \n",
       "13585                                                 []   \n",
       "\n",
       "                                          all_categories  \n",
       "13020                     [Computer Vision, Methodology]  \n",
       "13021                     [Computer Vision, Methodology]  \n",
       "13024  [Computer Vision, Methodology, Natural Languag...  \n",
       "13025  [Computer Vision, Methodology, Natural Languag...  \n",
       "12633                                  [Computer Vision]  \n",
       "12632                                  [Computer Vision]  \n",
       "12634                                  [Computer Vision]  \n",
       "13003                                  [Computer Vision]  \n",
       "13033                                  [Computer Vision]  \n",
       "13032                                  [Computer Vision]  \n",
       "13018                                      [Methodology]  \n",
       "13019                                      [Methodology]  \n",
       "13031  [Computer Vision, Methodology, Natural Languag...  \n",
       "13030  [Computer Vision, Methodology, Natural Languag...  \n",
       "13029  [Computer Vision, Methodology, Natural Languag...  \n",
       "13011         [Natural Language Processing, Methodology]  \n",
       "13012         [Natural Language Processing, Methodology]  \n",
       "12925                     [Computer Vision, Methodology]  \n",
       "12926                     [Computer Vision, Methodology]  \n",
       "13585  [Natural Language Processing, Miscellaneous, M...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_citing_papers_pwc[dataset_citing_papers_pwc.name==\"CelebA\"].sort_values('date').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "132c0915-692b-439a-885d-058076d93f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create infomap inputs\n",
    "dataset_citing_papers_origins=pd.merge(datasets_pwc,dataset_citing_papers_pwc,on='name')\n",
    "dataset_citing_papers_origins.columns\n",
    "dataset_citing_papers_origins.rename({'title_x':'origin_title',\n",
    "                                     'all_tasks_x':'origin_tasks',\n",
    "                                     'all_parents_x':'origin_parents',\n",
    "                                     'all_siblings_x':'origin_siblings',\n",
    "                                     'all_siblings_x':'origin_siblings'},axis=1,inplace=True)\n",
    "dataset_citing_papers_origins.columns=[i.replace('_y','') for i in dataset_citing_papers_origins.columns]\n",
    "#dataset_citing_papers_origins=dataset_citing_papers_origins[dataset_citing_papers_origins.date>dataset_citing_papers_origins.introduced_date]\n",
    "dataset_citing_papers_origins=dataset_citing_papers_origins[dataset_citing_papers_origins.title!=dataset_citing_papers_origins.origin_title]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2c6ab62b-ff22-4b03-befc-c1ce1edc624a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Image Recognition', 'Semi-Supervised Image Classification']\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "valid_tasks= set(datasets[datasets.name=='STL-10']['dataset_tasks'].iloc[0]+\\\n",
    "                     datasets[datasets.name=='STL-10']['dataset_tasks_children'].iloc[0]+\\\n",
    "                    datasets[datasets.name=='STL-10']['dataset_tasks_siblings'].iloc[0])\n",
    "print(dataset_citing_papers_origins[dataset_citing_papers_origins.name=='STL-10']['origin_tasks'].iloc[0])\n",
    "print('Semi-Supervised Image Classification' in valid_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19f02df6-00c7-4622-b72d-7dfe3e5b4871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORKING\n"
     ]
    }
   ],
   "source": [
    "# Now create infomap inputs\n",
    "'''\n",
    "origins=datasets_pwc.copy()\n",
    "origins=datasets_pwc[['name','title','introduced_date','Images','Texts','all_tasks','all_parents','all_siblings','all_children']]\n",
    "origins.columns=['name','origin_title','introduced_date','Images','Texts','origin_tasks','origin_parents','origin_siblings','origin_children']\n",
    "dataset_citing_papers_origins=pd.merge(dataset_citing_papers_pwc,origins,on='name')\n",
    "dataset_citing_papers_origins=dataset_citing_papers_origins[dataset_citing_papers_origins.date>dataset_citing_papers_origins.introduced_date]\n",
    "dataset_citing_papers_origins=dataset_citing_papers_origins[dataset_citing_papers_origins.title!=dataset_citing_papers_origins.origin_title]\n",
    "dataset_citing_papers_origins=dataset_citing_papers_origins.drop_duplicates(['name','title'])\n",
    "'''\n",
    "# Now create infomap inputs\n",
    "dataset_citing_papers_origins=pd.merge(datasets_pwc,dataset_citing_papers_pwc,on='name')\n",
    "dataset_citing_papers_origins.columns\n",
    "dataset_citing_papers_origins.rename({'title_x':'origin_title',\n",
    "                                     'all_tasks_x':'origin_tasks',\n",
    "                                     'all_parents_x':'origin_parents',\n",
    "                                     'all_siblings_x':'origin_siblings',\n",
    "                                     'all_children_x':'origin_children'},axis=1,inplace=True)\n",
    "dataset_citing_papers_origins.columns=[i.replace('_y','') for i in dataset_citing_papers_origins.columns]\n",
    "dataset_citing_papers_origins=dataset_citing_papers_origins[dataset_citing_papers_origins.title!=dataset_citing_papers_origins.origin_title]\n",
    "#since it is cyclic, we will skip lowest level tasks and focus on others\n",
    "'''\n",
    "parentless_tasks=task_relations[task_relations['parents'].astype(str)=='[]'].task\n",
    "parentless_tasks=parentless_tasks.to_list()\n",
    "parent_tasks=pd.Series(parent_child_dict).astype(str)\n",
    "parent_tasks=parent_tasks[parent_tasks!='[]'].index.to_list()\n",
    "focal_tasks=set(parentless_tasks+parent_tasks)\n",
    "'''\n",
    "methods_tasks=pd.read_csv(\"MethodTasksfromEmily.txt\",header=None).squeeze().tolist()\n",
    "#focal_tasks=task_hist.index\n",
    "#parent_tasks=[i for i in parent_child_dict.keys() if len(parent_child_dict[i])!=0]\n",
    "#focal_tasks=parent_tasks\n",
    "task_contains_images={}\n",
    "task_contains_texts={}\n",
    "#tasks<-list(parent_child_dict().keys()\n",
    "\n",
    "#external adoptions to siblings and parents\n",
    "sources=[]\n",
    "destinations=[]\n",
    "ds_names=[]\n",
    "paper_titles=[]\n",
    "ds_texts=[]\n",
    "ds_images=[]\n",
    "dest_dates=[]\n",
    "parent_transfer=[]\n",
    "\n",
    "\n",
    "#adoption of homegrown datasets\n",
    "home_tasks=[]\n",
    "home_names=[]\n",
    "home_titles=[]\n",
    "home_dates=[]\n",
    "home_texts=[]\n",
    "home_images=[]\n",
    "home_parent=[]\n",
    "home_introduced=[]\n",
    "\n",
    "introduced_names=[]\n",
    "introduced_dates=[]\n",
    "introduced_tasks=[]\n",
    "introduced_texts=[]\n",
    "introduced_images=[]\n",
    "introduced_parent=[]\n",
    "introduced_title=[]\n",
    "#There are four scenarios\n",
    "#1:Dest is sources's parent: continue\n",
    "#2 Dest is source's child:\n",
    "    #For now we just continue on this\n",
    "    #(Theoretically source can transfer to a child if it is older than child)\n",
    "#3 Dest is source:\n",
    "    #Homegrown for source\n",
    "    #Homegrown for parents\n",
    "#4 Dest is source's sibling: Do sibling transfer\n",
    "\n",
    "#5 Dest is unrelated:\n",
    "    # Do source to dest transfer\n",
    "    # If source has no parents and dest has no parents: continue\n",
    "    # Elif source has parents and dest has no parents: Do parent source to dest transfer\n",
    "    # Elif source has no parents and dest has parents: Do source to parent dest transfer\n",
    "    # Else: Do parent to parent transfer\n",
    "print(\"WORKING\")\n",
    "big_break=False\n",
    "for i,row in dataset_citing_papers_origins.iterrows():\n",
    "    valid_tasks= set(datasets[datasets.name==row['name']]['dataset_tasks'].iloc[0]+\\\n",
    "                     datasets[datasets.name==row['name']]['dataset_tasks_children'].iloc[0]+\\\n",
    "                    datasets[datasets.name==row['name']]['dataset_tasks_siblings'].iloc[0])\n",
    "    for t in row['origin_tasks']:\n",
    "        #print(t)\n",
    "        if t not in valid_tasks: continue\n",
    "        introduced_names.append(row['name'])\n",
    "        introduced_dates.append(row['introduced_date'])\n",
    "        introduced_tasks.append(t)\n",
    "        introduced_images.append(row['Images'])\n",
    "        introduced_texts.append(row['Texts'])\n",
    "        introduced_title.append(row['origin_title'])\n",
    "        introduced_parent.append(False)\n",
    "        if t not in task_contains_images: task_contains_images[t]=0\n",
    "        if t not in task_contains_texts: task_contains_texts[t]=0\n",
    "        task_contains_texts[t]+=row['Images']; task_contains_images[t]+=row['Texts']\n",
    "        #Your parent gets credit for introducing dataset as well!\n",
    "        for d in row['origin_parents']:\n",
    "            if d not in valid_tasks: continue\n",
    "            #if d not in focal_tasks:continue\n",
    "            introduced_names.append(row['name'])\n",
    "            introduced_dates.append(row['introduced_date'])\n",
    "            introduced_tasks.append(d)\n",
    "            introduced_images.append(row['Images'])\n",
    "            introduced_texts.append(row['Texts'])\n",
    "            introduced_parent.append(True)\n",
    "            introduced_title.append(row['origin_title'])\n",
    "\n",
    "            if d not in task_contains_images: task_contains_images[d]=0\n",
    "            if d not in task_contains_texts: task_contains_texts[d]=0\n",
    "            task_contains_texts[d]+=row['Images']; task_contains_images[d]+=row['Texts']\n",
    "            \n",
    "\n",
    "        #who are you passing it to?\n",
    "        for d in row['all_tasks']:\n",
    "            if d not in valid_tasks: continue\n",
    "            #if d not in focal_tasks: continue\n",
    "            #Scenario 1: Dest is sources parent\n",
    "            if d in row['origin_parents']: continue\n",
    "            #Scenario 2: Dest is sources child or another origins child:\n",
    "            if d in row['origin_children']: continue\n",
    "            #Scenario 3: Dest is source. (First confirm its not another origin)\n",
    "            if d in row['origin_tasks'] and t!=d: continue\n",
    "            #you've found yourself. Add to home task\n",
    "            if t==d: \n",
    "                home_tasks.append(t)\n",
    "                home_names.append(row['name'])\n",
    "                home_titles.append(row['title'])\n",
    "                home_dates.append(row['date'])\n",
    "                home_images.append(row['Images'])\n",
    "                home_texts.append(row['Texts'])\n",
    "                home_parent.append(False)\n",
    "                home_introduced.append(row['introduced_date'])\n",
    "                if t not in task_contains_images: task_contains_images[t]=0\n",
    "                if t not in task_contains_texts: task_contains_texts[t]=0\n",
    "                task_contains_texts[t]+=row['Images']; task_contains_images[t]+=row['Texts']\n",
    "                #your parents have also homgrown a task\n",
    "                for parent in row['origin_parents']:\n",
    "                    if parent not in valid_tasks: continue\n",
    "                    home_tasks.append(parent)\n",
    "                    home_names.append(row['name'])\n",
    "                    home_titles.append(row['title'])\n",
    "                    home_dates.append(row['date'])\n",
    "                    home_images.append(row['Images'])\n",
    "                    home_texts.append(row['Texts'])\n",
    "                    home_parent.append(True)\n",
    "                    home_introduced.append(row['introduced_date'])\n",
    "                    if parent not in task_contains_images: task_contains_images[parent]=0\n",
    "                    if parent not in task_contains_texts: task_contains_texts[parent]=0\n",
    "                    task_contains_texts[parent]+=row['Images']; task_contains_images[parent]+=row['Texts']\n",
    "            else:\n",
    "                #A. pass directly to this tasks\n",
    "                if t not in valid_tasks or d not in valid_tasks: continue\n",
    "                sources.append(t)\n",
    "                destinations.append(d)\n",
    "                ds_names.append(row['name'])\n",
    "                paper_titles.append(row['title'])\n",
    "                dest_dates.append(row['date'])\n",
    "                ds_texts.append(row['Texts'])\n",
    "                ds_images.append(row['Images'])\n",
    "                parent_transfer.append(False)\n",
    "                if t not in task_contains_images: task_contains_images[t]=0\n",
    "                if t not in task_contains_texts: task_contains_texts[t]=0\n",
    "                task_contains_texts[t]+=row['Images']; task_contains_images[t]+=row['Texts']\n",
    "                if d not in task_contains_images: task_contains_images[d]=0\n",
    "                if d not in task_contains_texts: task_contains_texts[d]=0\n",
    "                task_contains_texts[d]+=row['Images']; task_contains_images[d]+=row['Texts'] \n",
    "                #B1. Source has no parents but dest does\n",
    "                for pt in row['origin_parents']:\n",
    "                    if t not in valid_tasks or pt not in valid_tasks: continue\n",
    "                    #if pt not in focal_tasks: continue                    \n",
    "                    if t==pt: continue #cant transfer to yourself                        \n",
    "                    for pdest in row['all_parents']:\n",
    "                        if t not in valid_tasks or pdest not in valid_tasks: continue\n",
    "                        #cant transfer to yourself to your own parent or children\n",
    "                        #if pdest not in focal_tasks: continue\n",
    "                        if t==pdest or pdest in row['origin_parents'] or pdest in row['origin_children']: continue\n",
    "                        sources.append(pt)\n",
    "                        destinations.append(pdest)\n",
    "                        ds_names.append(row['name'])\n",
    "                        paper_titles.append(row['title'])\n",
    "                        dest_dates.append(row['date'])\n",
    "                        ds_texts.append(row['Texts'])\n",
    "                        ds_images.append(row['Images'])\n",
    "                        parent_transfer.append(True)\n",
    "                        if pt not in task_contains_images: task_contains_images[pt]=0\n",
    "                        if pt not in task_contains_texts: task_contains_texts[pt]=0\n",
    "                        task_contains_texts[pt]+=row['Images']; task_contains_images[pt]+=row['Texts']\n",
    "                        if pdest not in task_contains_images: task_contains_images[pdest]=0\n",
    "                        if pdest not in task_contains_texts: task_contains_texts[pdest]=0\n",
    "                        task_contains_texts[pdest]+=row['Images']; task_contains_images[pdest]+=row['Texts']\n",
    "\n",
    "source_dest_edgelist=pd.DataFrame({'source_task':sources,'dest_task':destinations,'name':ds_names,'title':paper_titles,'date':dest_dates,'Images':ds_images,'Texts':ds_texts,'Parent_Transfer':parent_transfer}).drop_duplicates()\n",
    "homegrown_edgelist=pd.DataFrame({'task':home_tasks,'name':home_names,'title':home_titles,'date':home_dates,'Images':home_images,'Texts':home_texts,'Parent':home_parent,'introduced_date':home_introduced}).drop_duplicates()\n",
    "birth_edgelist=pd.DataFrame({'task':introduced_tasks,'name':introduced_names,'title':introduced_title,'date':introduced_dates,'Images':introduced_images,'Texts':introduced_texts,'Parent':introduced_parent}).drop_duplicates()\n",
    "task_contains_images=pd.Series(task_contains_images)\n",
    "task_contains_images[task_contains_images>0]=1\n",
    "task_contains_texts=pd.Series(task_contains_texts)\n",
    "task_contains_texts[task_contains_texts>0]=1\n",
    "task_contains_images=task_contains_images.reset_index()\n",
    "task_contains_images.columns=['task','Images']\n",
    "task_contains_texts=task_contains_texts.reset_index()\n",
    "task_contains_texts.columns=['task','Texts']\n",
    "source_dest_edgelist.to_csv('source_dest_edgelist.csv',quoting=1)\n",
    "homegrown_edgelist.to_csv('homegrown_edgelist',quoting=1)\n",
    "birth_edgelist.to_csv('birth_edgelist.csv',quoting=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61f8d5f4-d5ef-44cb-819e-8ede4e6df88d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c2105022dea8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msource_dest_edgelist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'source_dest_edgelist.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mhomegrown_edgelist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'source_dest_edgelist.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbirth_edgelist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'birth_edgelist.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d2fa44f-979b-46ec-9221-b6966e822ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_task</th>\n",
       "      <th>dest_task</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>Images</th>\n",
       "      <th>Texts</th>\n",
       "      <th>Parent_Transfer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Handwriting Recognition</td>\n",
       "      <td>Network Pruning</td>\n",
       "      <td>MNIST</td>\n",
       "      <td>Fast Convex Pruning of Deep Neural Networks</td>\n",
       "      <td>2018-06-17</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Optical Character Recognition</td>\n",
       "      <td>Network Pruning</td>\n",
       "      <td>MNIST</td>\n",
       "      <td>Fast Convex Pruning of Deep Neural Networks</td>\n",
       "      <td>2018-06-17</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image Classification</td>\n",
       "      <td>Network Pruning</td>\n",
       "      <td>MNIST</td>\n",
       "      <td>Fast Convex Pruning of Deep Neural Networks</td>\n",
       "      <td>2018-06-17</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Handwriting Recognition</td>\n",
       "      <td>Domain Adaptation</td>\n",
       "      <td>MNIST</td>\n",
       "      <td>Best sources forward: domain generalization th...</td>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Optical Character Recognition</td>\n",
       "      <td>Domain Adaptation</td>\n",
       "      <td>MNIST</td>\n",
       "      <td>Best sources forward: domain generalization th...</td>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447432</th>\n",
       "      <td>Video Retrieval</td>\n",
       "      <td>Video Understanding</td>\n",
       "      <td>WebVid</td>\n",
       "      <td>CLIP4Clip: An Empirical Study of CLIP for End ...</td>\n",
       "      <td>2021-04-18</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447433</th>\n",
       "      <td>Video-Text Retrieval</td>\n",
       "      <td>Video Understanding</td>\n",
       "      <td>WebVid</td>\n",
       "      <td>CLIP4Clip: An Empirical Study of CLIP for End ...</td>\n",
       "      <td>2021-04-18</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447467</th>\n",
       "      <td>Word Sense Induction</td>\n",
       "      <td>Reading Comprehension</td>\n",
       "      <td>RUSSE</td>\n",
       "      <td>RussianSuperGLUE: A Russian Language Understan...</td>\n",
       "      <td>2020-10-29</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447474</th>\n",
       "      <td>Word Sense Induction</td>\n",
       "      <td>Reading Comprehension</td>\n",
       "      <td>RUSSE</td>\n",
       "      <td>Unreasonable Effectiveness of Rule-Based Heuri...</td>\n",
       "      <td>2021-05-03</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447480</th>\n",
       "      <td>Face Recognition</td>\n",
       "      <td>Face Hallucination</td>\n",
       "      <td>TinyFace</td>\n",
       "      <td>Face Hallucination with Finishing Touches</td>\n",
       "      <td>2020-02-09</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42022 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          source_task              dest_task      name  \\\n",
       "0             Handwriting Recognition        Network Pruning     MNIST   \n",
       "1       Optical Character Recognition        Network Pruning     MNIST   \n",
       "2                Image Classification        Network Pruning     MNIST   \n",
       "3             Handwriting Recognition      Domain Adaptation     MNIST   \n",
       "4       Optical Character Recognition      Domain Adaptation     MNIST   \n",
       "...                               ...                    ...       ...   \n",
       "447432                Video Retrieval    Video Understanding    WebVid   \n",
       "447433           Video-Text Retrieval    Video Understanding    WebVid   \n",
       "447467           Word Sense Induction  Reading Comprehension     RUSSE   \n",
       "447474           Word Sense Induction  Reading Comprehension     RUSSE   \n",
       "447480               Face Recognition     Face Hallucination  TinyFace   \n",
       "\n",
       "                                                    title       date  Images  \\\n",
       "0             Fast Convex Pruning of Deep Neural Networks 2018-06-17    True   \n",
       "1             Fast Convex Pruning of Deep Neural Networks 2018-06-17    True   \n",
       "2             Fast Convex Pruning of Deep Neural Networks 2018-06-17    True   \n",
       "3       Best sources forward: domain generalization th... 2018-06-15    True   \n",
       "4       Best sources forward: domain generalization th... 2018-06-15    True   \n",
       "...                                                   ...        ...     ...   \n",
       "447432  CLIP4Clip: An Empirical Study of CLIP for End ... 2021-04-18   False   \n",
       "447433  CLIP4Clip: An Empirical Study of CLIP for End ... 2021-04-18   False   \n",
       "447467  RussianSuperGLUE: A Russian Language Understan... 2020-10-29   False   \n",
       "447474  Unreasonable Effectiveness of Rule-Based Heuri... 2021-05-03   False   \n",
       "447480          Face Hallucination with Finishing Touches 2020-02-09    True   \n",
       "\n",
       "        Texts  Parent_Transfer  \n",
       "0       False            False  \n",
       "1       False            False  \n",
       "2       False            False  \n",
       "3       False            False  \n",
       "4       False             True  \n",
       "...       ...              ...  \n",
       "447432   True            False  \n",
       "447433   True            False  \n",
       "447467   True            False  \n",
       "447474   True            False  \n",
       "447480  False            False  \n",
       "\n",
       "[42022 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_dest_edgelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "119553c4-40da-4620-929e-58ac41ea24ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-109ee7da6897>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_papers['date']=None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ndest_papers=source_dest_edgelist[['title','dest_task']]\\ndest_papers.columns=['title','task']\\nbirth_papers=birth_edgelist[['title','task']]\\nhomegrown_papers=homegrown_edgelist[['title','task']]\\nfull_dataset=pd.concat([dataset_papers,dest_papers,birth_papers,homegrown_papers]).drop_duplicates()\\ntask_sizes=full_dataset.groupby('task').size()\\n\\nparent_tasks=[i for i in parent_child_dict.keys() if len(parent_child_dict[i])!=0]\\nparent_task_sizes=task_sizes[task_sizes.index.isin(parent_tasks)]\\nparent_task_sizes_median=parent_task_sizes[parent_task_sizes>parent_task_sizes.median()]\\nparent_task_sizes_median.sort_values()\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_dest_edgelist=pd.read_csv('source_dest_edgelist.csv')\n",
    "homegrown_edgelist=pd.read_csv('source_dest_edgelist.csv')\n",
    "birth_edgelist=pd.read_csv('birth_edgelist.csv')\n",
    "dataset_papers=datasets[['name','title']]\n",
    "dataset_papers['date']=None\n",
    "dest_papers=source_dest_edgelist[['name','title','date']]\n",
    "dest_papers.columns=['name','title','date']\n",
    "birth_papers=birth_edgelist[['name','title','date']]\n",
    "homegrown_papers=homegrown_edgelist[['name','title','date']]\n",
    "full_dataset=pd.concat([dataset_papers,dest_papers,birth_papers,homegrown_papers]).drop_duplicates()\n",
    "full_dataset.to_csv('ValidPaperDataset-Titles.txt')\n",
    "'''\n",
    "dest_papers=source_dest_edgelist[['title','dest_task']]\n",
    "dest_papers.columns=['title','task']\n",
    "birth_papers=birth_edgelist[['title','task']]\n",
    "homegrown_papers=homegrown_edgelist[['title','task']]\n",
    "full_dataset=pd.concat([dataset_papers,dest_papers,birth_papers,homegrown_papers]).drop_duplicates()\n",
    "task_sizes=full_dataset.groupby('task').size()\n",
    "\n",
    "parent_tasks=[i for i in parent_child_dict.keys() if len(parent_child_dict[i])!=0]\n",
    "parent_task_sizes=task_sizes[task_sizes.index.isin(parent_tasks)]\n",
    "parent_task_sizes_median=parent_task_sizes[parent_task_sizes>parent_task_sizes.median()]\n",
    "parent_task_sizes_median.sort_values()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17c8d888-b242-4670-991c-f9123c9b47ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'task', 'name', 'title', 'date', 'Images', 'Texts',\n",
       "       'Parent'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84ac8276-1822-49eb-ba77-5c5c56a6926c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datasets_pwc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-471053042086>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mMAGIDs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MAG_Linking_IDs.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#MAGIDs=MAGIDs[['MAGID','PWC_Clean_Title','PWC_Title']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdataset_papers_MAG\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAGIDs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdatasets_pwc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'PWC_Title'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'datasets_pwc' is not defined"
     ]
    }
   ],
   "source": [
    "MAGIDs=pd.read_json('MAG_Linking_IDs.json')\n",
    "#MAGIDs=MAGIDs[['MAGID','PWC_Clean_Title','PWC_Title']]\n",
    "dataset_papers_MAG=pd.merge(MAGIDs,datasets_pwc,left_on='PWC_Title',right_on='title').drop('title',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "737ed5d1-b6c1-4e89-8795-7f7156469e50",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MAGIDs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-677ffca94c25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mMAGIDs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'MAGIDs' is not defined"
     ]
    }
   ],
   "source": [
    "MAGIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "607fd6ce-d221-4d5e-b3fb-0f961a710773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "temp=full_dataset.groupby('name').size().sort_values()\n",
    "dataset_usage_dist=temp[(temp>5)&(temp<500)].plot(kind='hist',bins=500,figsize=[8,4],title='Truncated Distribution of Dataset Usages')\n",
    "fig = dataset_usage_dist.get_figure()\n",
    "fig.savefig('truncated_dist.png')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "c722a301-107e-4f5c-b226-d5fe9757b973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137510,)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "annual_size=pwc_papers.groupby('year').size().reset_index()\n",
    "temp=annual_size.plot(figsize=[8,4],x='year',y=0,title='PWC Corpus papers per year',xlim=[2009,2020],legend=False)\n",
    "fig = temp.get_figure()\n",
    "pwc_papers.title.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f3682d94-cc31-4cc7-8623-f1e9ad214490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "924"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(list(source_dest_edgelist_parents['name'])+list(homegrown_edgelist_parents['name'])+list(birth_edgelist_parents['name'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5189814e-9ff1-4d58-b54f-d2957696c652",
   "metadata": {},
   "outputs": [],
   "source": [
    "Methodologies_to_Drop=[\n",
    "'Word Embeddings',\n",
    "'Anomaly Detection',\n",
    "'Multivariate Time Series Forecasting',\n",
    "'EEG',\n",
    "'Chatbot',\n",
    "'Computed Tomography (CT)',\n",
    "'Electrocardiography (ECG)',\n",
    "'Electrocardiography (ECG)',\n",
    "'Multi-Label Text Classification'    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "57c3389c-e91a-4502-81a2-0c8af615c04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Word Embeddings',\n",
       " 'Anomaly Detection',\n",
       " 'Multivariate Time Series Forecasting',\n",
       " 'EEG',\n",
       " 'Chatbot',\n",
       " 'Computed Tomography (CT)',\n",
       " 'Electrocardiography (ECG)',\n",
       " 'Electrocardiography (ECG)',\n",
       " 'Multi-Label Text Classification']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Methodologies_to_Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc9b6992-dc7e-4b92-88ef-e511661bc493",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: '/mnt/c/Users/berna/Documents/GoogleDataProject/RatioInputs/FullDatasetforR.ParentsOnly.AllYears.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-64c4fd0e5ad9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m#THESE ARE ERRONEOUS NEED TO CHECK EACH ERROR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mfull_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/mnt/c/Users/berna/Documents/GoogleDataProject/RatioInputs/FullDatasetforR.ParentsOnly.AllYears.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquoting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/data/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   3202\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3203\u001b[0m         )\n\u001b[0;32m-> 3204\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/data/lib/python3.8/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             f, handles = get_handle(\n\u001b[0m\u001b[1;32m    185\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/data/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 22] Invalid argument: '/mnt/c/Users/berna/Documents/GoogleDataProject/RatioInputs/FullDatasetforR.ParentsOnly.AllYears.txt'"
     ]
    }
   ],
   "source": [
    "parent_tasks=[i for i in parent_child_dict if len(parent_child_dict[i])!=0]\n",
    "\n",
    "source_dest_edgelist_parents= source_dest_edgelist[(source_dest_edgelist.source_task.isin(parent_tasks)) &\\\n",
    "                                                  (source_dest_edgelist.dest_task.isin(parent_tasks))]\n",
    "homegrown_edgelist_parents= homegrown_edgelist[homegrown_edgelist.task.isin(parent_tasks)]\n",
    "birth_edgelist_parents= birth_edgelist[birth_edgelist.task.isin(parent_tasks)]\n",
    "num_papers_adopting=source_dest_edgelist_parents.groupby(['dest_task']).size()\n",
    "num_papers_adopting.index.names=['task']\n",
    "num_papers_growing=homegrown_edgelist_parents.groupby(['task']).size()\n",
    "num_dataset_births=birth_edgelist_parents.groupby(['task']).size()\n",
    "num_homegrown_datasets=num_dataset_births.shift(1).cumsum()\n",
    "temp=source_dest_edgelist_parents.groupby(['dest_task','name']).size().reset_index().drop(0,axis=1)\n",
    "num_dataset_imports=temp.groupby(['dest_task']).size()\n",
    "#num_converted_growing=homegrown_edgelist_parents[(homegrown_edgelist_parents.introduced_date.dt.year==homegrown_edgelist_parents.date.dt.year)|\\\n",
    "#                                         (homegrown_edgelist_parents.introduced_date.dt.year==homegrown_edgelist_parents.date.dt.year-1)|\\\n",
    "#                                        (homegrown_edgelist_parents.introduced_date.dt.year==homegrown_edgelist_parents.date.dt.year-2)]\n",
    "#num_converted_growing_year=num_converted_growing.groupby(['task',num_converted_growing.date.dt.year]).size()\n",
    "#num_papers_growing_year=homegrown_edgelist_parents.groupby(['task',homegrown_edgelist_parents.date.dt.year]).size()\n",
    "#conversion_pct\n",
    "num_dataset_imports.columns=['imported_datasets']\n",
    "num_dataset_imports.index.names=['task']\n",
    "num_dataset_births.name='num_dataset_births'\n",
    "num_papers_adopting.name='num_papers_adopting'\n",
    "num_dataset_imports.name='num_dataset_imports'\n",
    "num_papers_growing.name='num_papers_growing'\n",
    "num_homegrown_datasets.name='num_dataset_homegrown'\n",
    "#num_converted_growing.name='num_converted_growing'\n",
    "\n",
    "full_data=pd.merge(num_dataset_births.reset_index(),num_papers_adopting.reset_index(),how='outer')\n",
    "full_data=pd.merge(full_data,num_homegrown_datasets.reset_index(),how='outer')\n",
    "full_data=pd.merge(full_data,num_dataset_imports.reset_index(),how='outer')\n",
    "full_data=pd.merge(full_data,num_papers_growing.reset_index(),how='outer')\n",
    "#full_data=pd.merge(full_data,num_converted_growing.reset_index(),how='outer')\n",
    "full_data=full_data.fillna(0)\n",
    "full_data['size']=full_data.num_papers_adopting+full_data.num_papers_growing+full_data.num_dataset_births\n",
    "task_age_df=task_age.reset_index()\n",
    "task_age_df.columns=['task','task_age']\n",
    "full_data=pd.merge(full_data,task_age_df,on='task',how='left')\n",
    "full_data['adoption_ratio']=full_data.num_papers_adopting.divide(full_data.num_papers_growing)\n",
    "full_data['creation_ratio']=full_data.num_dataset_births.divide(full_data.num_dataset_imports)\n",
    "#full_data['conversion_ratio']=full_data.num_dataset_homegrown.divide(full_data.num_papers_growing)\n",
    "full_data['adoption_pct']=full_data.num_papers_adopting.divide(full_data.num_papers_adopting+full_data.num_papers_growing)\n",
    "full_data['creation_pct']=full_data.num_dataset_births.divide(full_data.num_dataset_births+full_data.num_dataset_imports)\n",
    "#full_data['conversion_pct']=full_data.num_converted_growing.divide(full_data.num_papers_growing)\n",
    "#full_data['cvmethods']=full_data.task.isin(methods_tasks).astype(int)\n",
    "#full_data=pd.merge(full_data,task_contains_images,on='task',how='left')\n",
    "#full_data=pd.merge(full_data,task_contains_texts,on='task',how='left')\n",
    "\n",
    "def in_category(x,cat):\n",
    "    if x in task_category_dict and cat in task_category_dict[x]:\n",
    "        return 1\n",
    "    if x in parent_child_dict and any([cat in task_category_dict[p] for p in child_parent_dict[x]]):\n",
    "        return 1\n",
    "    return 0\n",
    "full_data['CV']=full_data['task'].apply(lambda x: in_category(x,'Computer Vision'))\n",
    "full_data['NLP']=full_data['task'].apply(lambda x: in_category(x,'Natural Language Processing'))\n",
    "full_data['Methodology']=full_data['task'].apply(lambda x: in_category(x,'Methodology'))\n",
    "full_data['Methodology']=full_data['Methodology'].apply(lambda x: 0 if x in Methodologies_to_Drop else x)\n",
    "median_parent_task_size=full_data['size'].median()\n",
    "full_data=full_data[full_data['size']>median_parent_task_size]\n",
    "median_parent_tasks=full_data.task\n",
    "median_parent_tasks.to_csv('median_parent_tasks')\n",
    "\n",
    "#THESE ARE ERRONEOUS NEED TO CHECK EACH ERROR\n",
    "full_data.to_csv(\"/mnt/c/Users/berna/Documents/GoogleDataProject/RatioInputs/FullDatasetforR.ParentsOnly.AllYears.txt\",sep='\\t',quoting=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "11fe2077-add4-424e-a418-47e411419321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de8e7e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_papers_adopting=source_dest_edgelist.groupby(['dest_task',source_dest_edgelist.date.dt.year]).size()\n",
    "num_papers_adopting.index.names=['task','date']\n",
    "num_papers_growing=homegrown_edgelist.groupby(['task',homegrown_edgelist.date.dt.year]).size()\n",
    "num_dataset_births=birth_edgelist.groupby(['task', birth_edgelist.date.dt.year]).size()\n",
    "num_homegrown_datasets=num_dataset_births.shift(1).cumsum()\n",
    "temp=source_dest_edgelist.groupby(['dest_task','name',source_dest_edgelist.date.dt.year]).size().reset_index().drop(0,axis=1)\n",
    "num_dataset_imports=temp.groupby(['dest_task',source_dest_edgelist.date.dt.year]).size()\n",
    "num_converted_growing=homegrown_edgelist[(homegrown_edgelist.introduced_date.dt.year==homegrown_edgelist.date.dt.year)|\\\n",
    "                                         (homegrown_edgelist.introduced_date.dt.year==homegrown_edgelist.date.dt.year-1)]\n",
    "num_converted_growing=num_converted_growing.groupby(['task',num_converted_growing.date.dt.year]).size()\n",
    "\n",
    "num_dataset_imports.columns=['imported_datasets']\n",
    "num_dataset_imports.index.names=['task','date']\n",
    "num_dataset_births.name='num_dataset_births'\n",
    "num_papers_adopting.name='num_papers_adopting'\n",
    "num_dataset_imports.name='num_dataset_imports'\n",
    "num_papers_growing.name='num_papers_growing'\n",
    "num_homegrown_datasets.name='num_dataset_homegrown'\n",
    "num_converted_growing.name='num_converted_growing'\n",
    "annual_data=pd.merge(num_dataset_births.reset_index(),num_papers_adopting.reset_index(),how='outer')\n",
    "annual_data=pd.merge(annual_data,num_homegrown_datasets.reset_index(),how='outer')\n",
    "annual_data=pd.merge(annual_data,num_dataset_imports.reset_index(),how='outer')\n",
    "annual_data=pd.merge(annual_data,num_papers_growing.reset_index(),how='outer')\n",
    "annual_data=pd.merge(annual_data,num_converted_growing.reset_index(),how='outer')\n",
    "annual_data=annual_data.fillna(0)\n",
    "annual_data['size']=annual_data.num_papers_adopting+annual_data.num_papers_growing+annual_data.num_dataset_births\n",
    "task_age_df=task_age.reset_index()\n",
    "task_age_df.columns=['task','task_age']\n",
    "annual_data=pd.merge(annual_data,task_age_df,on='task',how='left')\n",
    "annual_data['adoption_ratio']=annual_data.num_papers_adopting.divide(annual_data.num_papers_growing)\n",
    "annual_data['creation_ratio']=annual_data.num_dataset_births.divide(annual_data.num_dataset_imports)\n",
    "#annual_data['conversion_ratio']=annual_data.num_dataset_homegrown.divide(annual_data.num_papers_growing)\n",
    "annual_data['adoption_pct']=annual_data.num_papers_adopting.divide(annual_data.num_papers_adopting+annual_data.num_papers_growing)\n",
    "annual_data['creation_pct']=annual_data.num_dataset_births.divide(annual_data.num_dataset_births+annual_data.num_dataset_imports)\n",
    "annual_data['conversion_pct']=annual_data.num_converted_growing.divide(annual_data.num_papers_growing)\n",
    "annual_data['cvmethods']=annual_data.task.isin(methods_tasks)\n",
    "annual_data=pd.merge(annual_data,task_contains_images,on='task',how='left')\n",
    "annual_data=pd.merge(annual_data,task_contains_texts,on='task',how='left')\n",
    "pwc_papers['year']=pd.to_datetime(pwc_papers['date']).dt.year\n",
    "annual_size=pwc_papers.groupby('year').size().reset_index()\n",
    "annual_data=pd.merge(annual_data,annual_size,left_on='date',right_on='year',how='left')\n",
    "annual_data=annual_data.drop('year',axis=1).rename({0:'pwc_size'},axis=1)\n",
    "annual_data.rename({'date':'year'},axis=1,inplace=True)\n",
    "\n",
    "def in_category(x,cat):\n",
    "    if x in task_category_dict and cat in task_category_dict[x]:\n",
    "        return 1\n",
    "    if x in parent_child_dict and any([cat in task_category_dict[p] for p in child_parent_dict[x]]):\n",
    "        return 1\n",
    "    return 0\n",
    "annual_data['CV']=annual_data['task'].apply(lambda x: in_category(x,'Computer Vision'))\n",
    "annual_data['NLP']=annual_data['task'].apply(lambda x: in_category(x,'Natural Language Processing'))\n",
    "annual_data['Methodology']=annual_data['task'].apply(lambda x: in_category(x,'Methodology'))\n",
    "annual_data['Methodology']=annual_data['Methodology'].apply(lambda x: 0 if x in Methodologies_to_Drop else x)\n",
    "annual_data=annual_data[annual_data.year>=annual_data.task_age]\n",
    "annual_data.to_csv(\"/mnt/c/Users/berna/Documents/GoogleDataProject/RatioInputs/FullDatasetforR.txt\",sep='\\t',quoting=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a455b73-f6b4-4e25-aa2c-69c1b96c17d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANNUAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3da0b6fa-991e-4b8c-bba4-d8bd08e46df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dest_edgelist_parents= source_dest_edgelist[(source_dest_edgelist.source_task.isin(parent_tasks)) &\\\n",
    "                                                  (source_dest_edgelist.dest_task.isin(parent_tasks))]\n",
    "homegrown_edgelist_parents= homegrown_edgelist[homegrown_edgelist.task.isin(parent_tasks)]\n",
    "birth_edgelist_parents= birth_edgelist[birth_edgelist.task.isin(parent_tasks)]\n",
    "#homegrown_edgelist_parents= homegrown_edgelist[(homegrown_edgelist.task.isin(source_dest_edgelist_parents.source_task)) |(homegrown_edgelist.task.isin(source_dest_edgelist_parents.dest_task))]\n",
    "\n",
    "num_papers_adopting=source_dest_edgelist_parents.groupby(['dest_task',source_dest_edgelist_parents.date.dt.year]).size()\n",
    "num_papers_adopting.index.names=['task','date']\n",
    "num_papers_growing=homegrown_edgelist_parents.groupby(['task',homegrown_edgelist_parents.date.dt.year]).size()\n",
    "num_dataset_births=birth_edgelist_parents.groupby(['task', birth_edgelist_parents.date.dt.year]).size()\n",
    "num_homegrown_datasets=num_dataset_births.shift(1).cumsum()\n",
    "temp=source_dest_edgelist_parents.groupby(['dest_task','name',source_dest_edgelist_parents.date.dt.year]).size().reset_index().drop(0,axis=1)\n",
    "num_dataset_imports=temp.groupby(['dest_task',source_dest_edgelist_parents.date.dt.year]).size()\n",
    "num_converted_growing=homegrown_edgelist_parents[(homegrown_edgelist_parents.introduced_date.dt.year==homegrown_edgelist_parents.date.dt.year)|\\\n",
    "                                         (homegrown_edgelist_parents.introduced_date.dt.year==homegrown_edgelist_parents.date.dt.year-1)|\\\n",
    "                                        (homegrown_edgelist_parents.introduced_date.dt.year==homegrown_edgelist_parents.date.dt.year-2)]\n",
    "num_converted_growing=num_converted_growing.groupby(['task',num_converted_growing.date.dt.year]).size()\n",
    "\n",
    "num_dataset_imports.columns=['imported_datasets']\n",
    "num_dataset_imports.index.names=['task','date']\n",
    "num_dataset_births.name='num_dataset_births'\n",
    "num_papers_adopting.name='num_papers_adopting'\n",
    "num_dataset_imports.name='num_dataset_imports'\n",
    "num_papers_growing.name='num_papers_growing'\n",
    "num_homegrown_datasets.name='num_dataset_homegrown'\n",
    "num_converted_growing.name='num_converted_growing'\n",
    "annual_data=pd.merge(num_dataset_births.reset_index(),num_papers_adopting.reset_index(),how='outer')\n",
    "annual_data=pd.merge(annual_data,num_homegrown_datasets.reset_index(),how='outer')\n",
    "annual_data=pd.merge(annual_data,num_dataset_imports.reset_index(),how='outer')\n",
    "annual_data=pd.merge(annual_data,num_papers_growing.reset_index(),how='outer')\n",
    "annual_data=pd.merge(annual_data,num_converted_growing.reset_index(),how='outer')\n",
    "annual_data=annual_data.fillna(0)\n",
    "annual_data['size']=annual_data.num_papers_adopting+annual_data.num_papers_growing+annual_data.num_dataset_births\n",
    "task_age_df=task_age.reset_index()\n",
    "task_age_df.columns=['task','task_age']\n",
    "annual_data=pd.merge(annual_data,task_age_df,on='task',how='left')\n",
    "annual_data['adoption_ratio']=annual_data.num_papers_adopting.divide(annual_data.num_papers_growing)\n",
    "annual_data['creation_ratio']=annual_data.num_dataset_births.divide(annual_data.num_dataset_imports)\n",
    "#annual_data['conversion_ratio']=annual_data.num_dataset_homegrown.divide(annual_data.num_papers_growing)\n",
    "annual_data['adoption_pct']=annual_data.num_papers_adopting.divide(annual_data.num_papers_adopting+annual_data.num_papers_growing)\n",
    "annual_data['creation_pct']=annual_data.num_dataset_births.divide(annual_data.num_dataset_births+annual_data.num_dataset_imports)\n",
    "annual_data['conversion_pct']=annual_data.num_converted_growing.divide(annual_data.num_papers_growing)\n",
    "annual_data['cvmethods']=annual_data.task.isin(methods_tasks)\n",
    "annual_data=pd.merge(annual_data,task_contains_images,on='task',how='left')\n",
    "annual_data=pd.merge(annual_data,task_contains_texts,on='task',how='left')\n",
    "pwc_papers['year']=pd.to_datetime(pwc_papers['date']).dt.year\n",
    "annual_size=pwc_papers.groupby('year').size().reset_index()\n",
    "annual_data=pd.merge(annual_data,annual_size,left_on='date',right_on='year',how='left')\n",
    "annual_data=annual_data.drop('year',axis=1).rename({0:'pwc_size'},axis=1)\n",
    "annual_data.rename({'date':'year'},axis=1,inplace=True)\n",
    "\n",
    "def in_category(x,cat):\n",
    "    if x in task_category_dict and cat in task_category_dict[x]:\n",
    "        return 1\n",
    "    if x in parent_child_dict and any([cat in task_category_dict[p] for p in child_parent_dict[x]]):\n",
    "        return 1\n",
    "    return 0\n",
    "annual_data['CV']=annual_data['task'].apply(lambda x: in_category(x,'Computer Vision'))\n",
    "annual_data['NLP']=annual_data['task'].apply(lambda x: in_category(x,'Natural Language Processing'))\n",
    "annual_data['Methodology']=annual_data['task'].apply(lambda x: in_category(x,'Methodology'))\n",
    "annual_data['Methodology']=annual_data['Methodology'].apply(lambda x: 0 if x in Methodologies_to_Drop else x)\n",
    "#THESE ARE ERRONEOUS NEED TO CHECK EACH ERROR\n",
    "annual_data=annual_data[annual_data.year>=annual_data.task_age]\n",
    "annual_data=annual_data[annual_data.task.isin(median_parent_tasks)]\n",
    "annual_data.to_csv(\"/mnt/c/Users/berna/Documents/GoogleDataProject/RatioInputs/FullDatasetforR.ParentsOnly.txt\",sep='\\t',quoting=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b27baf80-0e7f-4129-93ad-0a96a993f14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 8)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_dest_edgelist_parents[source_dest_edgelist_parents.dest_task=='Facial Landmark Detection'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f219810-697a-4dd5-b6e5-5f269ef1385b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2D Object Detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>3D Face Reconstruction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>3D Human Pose Estimation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>3D Object Detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>3D Reconstruction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>249</td>\n",
       "      <td>Image Compression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>250</td>\n",
       "      <td>Image Inpainting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>260</td>\n",
       "      <td>Small Object Detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>266</td>\n",
       "      <td>Video Generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>268</td>\n",
       "      <td>Visual Place Recognition</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                      task\n",
       "0             1       2D Object Detection\n",
       "1             5    3D Face Reconstruction\n",
       "2             7  3D Human Pose Estimation\n",
       "3             9       3D Object Detection\n",
       "4            10         3D Reconstruction\n",
       "..          ...                       ...\n",
       "128         249         Image Compression\n",
       "129         250          Image Inpainting\n",
       "130         260    Small Object Detection\n",
       "131         266          Video Generation\n",
       "132         268  Visual Place Recognition\n",
       "\n",
       "[133 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_parent_tasks=pd.read_csv('median_parent_tasks')\n",
    "median_parent_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aaf6f09d-c9b1-4269-aee0-5ecf509eebe7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tasks with parent transfers\n",
    "parent_tasks=set(source_dest_edgelist[source_dest_edgelist.Parent_Transfer==True].source_task)\n",
    "parent_tasks=parent_tasks.union(set(source_dest_edgelist[source_dest_edgelist.Parent_Transfer==True].dest_task))\n",
    "parent_tasks=parent_tasks.union(set(homegrown_edgelist[homegrown_edgelist.Parent==True].task))\n",
    "parent_tasks=parent_tasks.union(set(birth_edgelist[birth_edgelist.Parent==True].task))\n",
    "source_dest_edgelist_parents= source_dest_edgelist[(source_dest_edgelist.source_task.isin(parent_tasks)) &\\\n",
    "                                                  (source_dest_edgelist.dest_task.isin(parent_tasks))]\n",
    "homegrown_edgelist_parents= homegrown_edgelist[homegrown_edgelist.task.isin(parent_tasks)]\n",
    "birth_edgelist_parents= birth_edgelist[birth_edgelist.task.isin(parent_tasks)]\n",
    "#homegrown_edgelist_parents= homegrown_edgelist[(homegrown_edgelist.task.isin(source_dest_edgelist_parents.source_task)) |(homegrown_edgelist.task.isin(source_dest_edgelist_parents.dest_task))]\n",
    "\n",
    "num_papers_adopting=source_dest_edgelist_parents.groupby(['dest_task',source_dest_edgelist_parents.date.dt.year]).size()\n",
    "num_papers_adopting.index.names=['task','date']\n",
    "num_papers_growing=homegrown_edgelist_parents.groupby(['task',homegrown_edgelist_parents.date.dt.year]).size()\n",
    "num_dataset_births=birth_edgelist_parents.groupby(['task', birth_edgelist_parents.date.dt.year]).size()\n",
    "num_homegrown_datasets=num_dataset_births.shift(1).cumsum()\n",
    "temp=source_dest_edgelist_parents.groupby(['dest_task','name',source_dest_edgelist_parents.date.dt.year]).size().reset_index().drop(0,axis=1)\n",
    "num_dataset_imports=temp.groupby(['dest_task',source_dest_edgelist_parents.date.dt.year]).size()\n",
    "num_converted_growing=homegrown_edgelist_parents[(homegrown_edgelist_parents.introduced_date.dt.year==homegrown_edgelist_parents.date.dt.year)|\\\n",
    "                                         (homegrown_edgelist_parents.introduced_date.dt.year==homegrown_edgelist_parents.date.dt.year-1)|\\\n",
    "                                        (homegrown_edgelist_parents.introduced_date.dt.year==homegrown_edgelist_parents.date.dt.year-2)]\n",
    "num_converted_growing=num_converted_growing.groupby(['task',num_converted_growing.date.dt.year]).size()\n",
    "\n",
    "num_dataset_imports.columns=['imported_datasets']\n",
    "num_dataset_imports.index.names=['task','date']\n",
    "num_dataset_births.name='num_dataset_births'\n",
    "num_papers_adopting.name='num_papers_adopting'\n",
    "num_dataset_imports.name='num_dataset_imports'\n",
    "num_papers_growing.name='num_papers_growing'\n",
    "num_homegrown_datasets.name='num_dataset_homegrown'\n",
    "num_converted_growing.name='num_converted_growing'\n",
    "annual_data=pd.merge(num_dataset_births.reset_index(),num_papers_adopting.reset_index(),how='outer')\n",
    "annual_data=pd.merge(annual_data,num_homegrown_datasets.reset_index(),how='outer')\n",
    "annual_data=pd.merge(annual_data,num_dataset_imports.reset_index(),how='outer')\n",
    "annual_data=pd.merge(annual_data,num_papers_growing.reset_index(),how='outer')\n",
    "annual_data=pd.merge(annual_data,num_converted_growing.reset_index(),how='outer')\n",
    "annual_data=annual_data.fillna(0)\n",
    "annual_data['size']=annual_data.num_papers_adopting+annual_data.num_papers_growing\n",
    "task_age_df=task_age.reset_index()\n",
    "task_age_df.columns=['task','task_age']\n",
    "annual_data=pd.merge(annual_data,task_age_df,on='task',how='left')\n",
    "annual_data['adoption_ratio']=annual_data.num_papers_adopting.divide(annual_data.num_papers_growing)\n",
    "annual_data['creation_ratio']=annual_data.num_dataset_births.divide(annual_data.num_dataset_imports)\n",
    "#annual_data['conversion_ratio']=annual_data.num_dataset_homegrown.divide(annual_data.num_papers_growing)\n",
    "annual_data['adoption_pct']=annual_data.num_papers_adopting.divide(annual_data.num_papers_adopting+annual_data.num_papers_growing)\n",
    "annual_data['creation_pct']=annual_data.num_dataset_births.divide(annual_data.num_dataset_births+annual_data.num_dataset_imports)\n",
    "annual_data['conversion_pct']=annual_data.num_converted_growing.divide(annual_data.num_papers_growing)\n",
    "annual_data['cvmethods']=annual_data.task.isin(methods_tasks).astype(int)\n",
    "annual_data=pd.merge(annual_data,task_contains_images,on='task',how='left')\n",
    "annual_data=pd.merge(annual_data,task_contains_texts,on='task',how='left')\n",
    "pwc_papers['year']=pd.to_datetime(pwc_papers['date']).dt.year\n",
    "annual_size=pwc_papers.groupby('year').size().reset_index()\n",
    "annual_data=pd.merge(annual_data,annual_size,left_on='date',right_on='year',how='left')\n",
    "annual_data=annual_data.drop('year',axis=1).rename({0:'pwc_size'},axis=1)\n",
    "annual_data.rename({'date':'year'},axis=1,inplace=True)\n",
    "\n",
    "def in_category(x,cat):\n",
    "    if x in task_category_dict and cat in task_category_dict[x]:\n",
    "        return 1\n",
    "    if x in parent_child_dict and any([cat in task_category_dict[p] for p in child_parent_dict[x]]):\n",
    "        return 1\n",
    "    return 0\n",
    "annual_data['CV']=annual_data['task'].apply(lambda x: in_category(x,'Computer Vision'))\n",
    "annual_data['NLP']=annual_data['task'].apply(lambda x: in_category(x,'Natural Language Processing'))\n",
    "annual_data['Methodology']=annual_data['task'].apply(lambda x: in_category(x,'Methodology'))\n",
    "#THESE ARE ERRONEOUS NEED TO CHECK EACH ERROR\n",
    "annual_data=annual_data[annual_data.year>=annual_data.task_age]\n",
    "annual_data.to_csv(\"/mnt/c/Users/berna/Documents/GoogleDataProject/RatioInputs/FullDatasetforR.Parents.Temp.txt\",sep='\\t',quoting=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24d3080c-37a9-491c-9c77-91180aef920c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ebf1a435-307a-43fa-99c4-9822a1ff3f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parent_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7b51e8a8-d91b-48f6-add1-eecc72eff785",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'all_tasks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-85124011e0ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpwc_papers_task\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpwc_papers_task\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'2D Human Pose Estimation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_tasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'2D Human Pose Estimation'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintroduced_date\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/data/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5273\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'all_tasks'"
     ]
    }
   ],
   "source": [
    "pd.to_datetime(pwc_papers_task[pwc_papers_task.task=='2D Human Pose Estimation'].date).dt.year.min()\n",
    "datasets[datasets.all_tasks.apply(lambda x: '2D Human Pose Estimation' in x)].introduced_date.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "ffc64111-8a86-4b3f-95c8-205e6f8f5424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          task  name  \\\n",
      "6939  2D Human Pose Estimation  FLIC   \n",
      "\n",
      "                                                  title       date  Images  \\\n",
      "6939  DeepPose: Human Pose Estimation via Deep Neura... 2013-12-17    True   \n",
      "\n",
      "      Texts  Parent  \n",
      "6939  False    True  \n",
      "Empty DataFrame\n",
      "Columns: [url, name, full_name, homepage, description, introduced_date, warning, modalities, languages, variants, num_papers, data_loaders, title, paper_url, Texts, Images, task, categories, parents, children, siblings, pdf_url, date, all_tasks, all_parents, all_children, all_siblings, all_categories]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 28 columns]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'dt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-300-87a8076d7c0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mhomegrown_edgelist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'task'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhomegrown_edgelist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpapers_from_last_years_ds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/data/lib/python3.8/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, func, dropna, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1570\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1572\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1574\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-300-87a8076d7c0c>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mhomegrown_edgelist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'task'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhomegrown_edgelist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpapers_from_last_years_ds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-300-87a8076d7c0c>\u001b[0m in \u001b[0;36mpapers_from_last_years_ds\u001b[0;34m(df_gb)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtemp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatasets_pwc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdatasets_pwc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_gb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtemp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintroduced_date\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mdf_gb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/data/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5273\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'dt'"
     ]
    }
   ],
   "source": [
    "def papers_from_last_years_ds(df_gb):\n",
    "    print(df_gb)\n",
    "    temp=datasets_pwc[datasets_pwc.name.isin(df_gb.name)]\n",
    "    print(temp)\n",
    "    temp=temp[temp.introduced_date.dt.year==df_gb.dt.year-1].name\n",
    "    return temp.size()\n",
    "    \n",
    "homegrown_edgelist.groupby(['task',homegrown_edgelist.date.dt.year]).filter(lambda x: papers_from_last_years_ds(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "403a8108-9ff7-4e29-a581-f1fe08618980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>name</th>\n",
       "      <th>full_name</th>\n",
       "      <th>homepage</th>\n",
       "      <th>description</th>\n",
       "      <th>introduced_date</th>\n",
       "      <th>warning</th>\n",
       "      <th>modalities</th>\n",
       "      <th>languages</th>\n",
       "      <th>variants</th>\n",
       "      <th>...</th>\n",
       "      <th>parents</th>\n",
       "      <th>children</th>\n",
       "      <th>siblings</th>\n",
       "      <th>pdf_url</th>\n",
       "      <th>date</th>\n",
       "      <th>all_tasks</th>\n",
       "      <th>all_parents</th>\n",
       "      <th>all_children</th>\n",
       "      <th>all_siblings</th>\n",
       "      <th>all_categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>https://paperswithcode.com/dataset/flic</td>\n",
       "      <td>FLIC</td>\n",
       "      <td>Frames Labelled in Cinema</td>\n",
       "      <td>https://bensapp.github.io/flic-dataset.html</td>\n",
       "      <td>The **FLIC** dataset contains 5003 images from...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images, Videos]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[FLIC Elbows, FLIC Wrists, FLIC]</td>\n",
       "      <td>...</td>\n",
       "      <td>[2D Human Pose Estimation]</td>\n",
       "      <td>[3D Human Pose Estimation, Keypoint Detection,...</td>\n",
       "      <td>[Pose Estimation, 3D Face Animation]</td>\n",
       "      <td>http://openaccess.thecvf.com/content_cvpr_2013...</td>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>[Pose Estimation]</td>\n",
       "      <td>[2D Human Pose Estimation]</td>\n",
       "      <td>[Keypoint Detection, 6D Pose Estimation using ...</td>\n",
       "      <td>[Pose Estimation, 3D Face Animation]</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         url  name                  full_name  \\\n",
       "892  https://paperswithcode.com/dataset/flic  FLIC  Frames Labelled in Cinema   \n",
       "\n",
       "                                        homepage  \\\n",
       "892  https://bensapp.github.io/flic-dataset.html   \n",
       "\n",
       "                                           description introduced_date  \\\n",
       "892  The **FLIC** dataset contains 5003 images from...      2013-01-01   \n",
       "\n",
       "    warning        modalities languages                          variants  \\\n",
       "892    None  [Images, Videos]        []  [FLIC Elbows, FLIC Wrists, FLIC]   \n",
       "\n",
       "     ...                     parents  \\\n",
       "892  ...  [2D Human Pose Estimation]   \n",
       "\n",
       "                                              children  \\\n",
       "892  [3D Human Pose Estimation, Keypoint Detection,...   \n",
       "\n",
       "                                 siblings  \\\n",
       "892  [Pose Estimation, 3D Face Animation]   \n",
       "\n",
       "                                               pdf_url        date  \\\n",
       "892  http://openaccess.thecvf.com/content_cvpr_2013...  2013-06-01   \n",
       "\n",
       "             all_tasks                 all_parents  \\\n",
       "892  [Pose Estimation]  [2D Human Pose Estimation]   \n",
       "\n",
       "                                          all_children  \\\n",
       "892  [Keypoint Detection, 6D Pose Estimation using ...   \n",
       "\n",
       "                             all_siblings     all_categories  \n",
       "892  [Pose Estimation, 3D Face Animation]  [Computer Vision]  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_pwc[datasets_pwc.name=='FLIC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "3932559a-5026-4ab6-98ff-d68cb989252b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>Images</th>\n",
       "      <th>Texts</th>\n",
       "      <th>Parent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Visual Question Answering</td>\n",
       "      <td>SHAPES</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Domain Generalization</td>\n",
       "      <td>PACS</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Domain Adaptation</td>\n",
       "      <td>PACS</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>General Classification</td>\n",
       "      <td>Oxford 102 Flower</td>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>Accuracy Metrics</td>\n",
       "      <td>Speech Commands</td>\n",
       "      <td>2018-04-09</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250247</th>\n",
       "      <td>Relation Extraction</td>\n",
       "      <td>WNUT-2020 Task 1</td>\n",
       "      <td>2020-10-27</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250251</th>\n",
       "      <td>Image Reconstruction</td>\n",
       "      <td>UDIS-D</td>\n",
       "      <td>2021-06-24</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250252</th>\n",
       "      <td>Image Stitching</td>\n",
       "      <td>UDIS-D</td>\n",
       "      <td>2021-06-24</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250253</th>\n",
       "      <td>Handwriting Recognition</td>\n",
       "      <td>HKR</td>\n",
       "      <td>2020-07-07</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250254</th>\n",
       "      <td>Optical Character Recognition</td>\n",
       "      <td>HKR</td>\n",
       "      <td>2020-07-07</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2583 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 task               name       date  Images  \\\n",
       "0           Visual Question Answering             SHAPES 2016-01-01    True   \n",
       "49              Domain Generalization               PACS 2017-01-01    True   \n",
       "50                  Domain Adaptation               PACS 2017-01-01    True   \n",
       "317            General Classification  Oxford 102 Flower 2008-12-01    True   \n",
       "612                  Accuracy Metrics    Speech Commands 2018-04-09   False   \n",
       "...                               ...                ...        ...     ...   \n",
       "250247            Relation Extraction   WNUT-2020 Task 1 2020-10-27   False   \n",
       "250251           Image Reconstruction             UDIS-D 2021-06-24    True   \n",
       "250252                Image Stitching             UDIS-D 2021-06-24    True   \n",
       "250253        Handwriting Recognition                HKR 2020-07-07    True   \n",
       "250254  Optical Character Recognition                HKR 2020-07-07    True   \n",
       "\n",
       "        Texts  Parent  \n",
       "0        True   False  \n",
       "49      False   False  \n",
       "50      False    True  \n",
       "317     False   False  \n",
       "612     False   False  \n",
       "...       ...     ...  \n",
       "250247  False   False  \n",
       "250251  False   False  \n",
       "250252  False   False  \n",
       "250253   True   False  \n",
       "250254   True    True  \n",
       "\n",
       "[2583 rows x 6 columns]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birth_edgelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "40b6fabf-f71b-4033-895e-c06c15bb60d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dest_edgelist2=source_dest_edgelist.copy()\n",
    "source_dest_edgelist2['date']=source_dest_edgelist2['date'].apply(lambda x: x if x.year % 2==0 else x-pd.offsets.DateOffset(years=1))\n",
    "homegrown_edgelist2=homegrown_edgelist.copy()\n",
    "homegrown_edgelist2['date']=homegrown_edgelist2['date'].apply(lambda x: x if x.year % 2==0 else x-pd.offsets.DateOffset(years=1))\n",
    "birth_edgelist2=birth_edgelist.copy()\n",
    "birth_edgelist2['date']=birth_edgelist2['date'].apply(lambda x: x if x.year % 2==0 else x-pd.offsets.DateOffset(years=1))\n",
    "pwc_papers2=pwc_papers.copy()\n",
    "pwc_papers2['year']=pd.to_datetime(pwc_papers2['date']).dt.year\n",
    "pwc_papers2['year']=pwc_papers2['year'].apply(lambda x: x if x % 2==0 else x-1)\n",
    "\n",
    "num_papers_adopting=source_dest_edgelist2.groupby(['dest_task',source_dest_edgelist2.date.dt.year]).size()\n",
    "num_papers_adopting.index.names=['task','date']\n",
    "num_papers_growing=homegrown_edgelist2.groupby(['task',homegrown_edgelist2.date.dt.year]).size()\n",
    "num_dataset_births=birth_edgelist2.groupby(['task', birth_edgelist2.date.dt.year]).size()\n",
    "temp=source_dest_edgelist2.groupby(['dest_task','name',source_dest_edgelist2.date.dt.year]).size().reset_index().drop(0,axis=1)\n",
    "num_dataset_imports=temp.groupby(['dest_task',source_dest_edgelist2.date.dt.year]).size()\n",
    "num_dataset_imports.columns=['imported_datasets']\n",
    "num_dataset_imports.index.names=['task','date']\n",
    "num_dataset_births.name='num_dataset_births'\n",
    "num_papers_adopting.name='num_papers_adopting'\n",
    "num_dataset_imports.name='num_dataset_imports'\n",
    "num_papers_growing.name='num_papers_growing'\n",
    "annual_data2=pd.merge(num_dataset_births.reset_index(),num_papers_adopting.reset_index(),how='outer')\n",
    "annual_data2=pd.merge(annual_data2,num_dataset_imports.reset_index(),how='outer')\n",
    "annual_data2=pd.merge(annual_data2,num_papers_growing.reset_index(),how='outer')\n",
    "annual_data2=annual_data2.fillna(0)\n",
    "annual_data2['size']=annual_data2.num_papers_adopting+annual_data2.num_papers_growing\n",
    "task_age_df=task_age.reset_index()\n",
    "task_age_df.columns=['task','task_age']\n",
    "annual_data2=pd.merge(annual_data2,task_age_df,on='task',how='left')\n",
    "annual_data2['adoption_ratio']=annual_data2.num_papers_adopting.divide(annual_data2.num_papers_growing)\n",
    "annual_data2['creation_ratio']=annual_data2.num_dataset_births.divide(annual_data2.num_dataset_imports)\n",
    "annual_data2['conversion_ratio']=annual_data2.num_dataset_births.divide(annual_data2.num_papers_growing)\n",
    "annual_data2['adoption_pct']=annual_data2.num_papers_adopting.divide(annual_data2.num_papers_adopting+annual_data2.num_papers_growing)\n",
    "annual_data2['creation_pct']=annual_data2.num_dataset_births.divide(annual_data2.num_dataset_births+annual_data2.num_dataset_imports)\n",
    "annual_data2['conversion_pct']=annual_data2.num_dataset_births.divide(annual_data2.num_dataset_births+annual_data2.num_papers_growing)\n",
    "annual_data2['cvmethods']=annual_data2.task.isin(methods_tasks)\n",
    "annual_data2=pd.merge(annual_data2,task_contains_images,on='task',how='left')\n",
    "annual_data2=pd.merge(annual_data2,task_contains_texts,on='task',how='left')\n",
    "annual_size2=pwc_papers2.groupby('year').size().reset_index()\n",
    "annual_data2=pd.merge(annual_data2,annual_size2,left_on='date',right_on='year',how='left')\n",
    "annual_data2=annual_data2.drop('year',axis=1).rename({0:'pwc_size'},axis=1)\n",
    "annual_data2.rename({'date':'year'},axis=1,inplace=True)\n",
    "\n",
    "def in_category(x,cat):\n",
    "    if x in task_category_dict and cat in task_category_dict[x]:\n",
    "        return 1\n",
    "    if x in parent_child_dict and any([cat in task_category_dict[p] for p in child_parent_dict[x]]):\n",
    "        return 1\n",
    "    return 0\n",
    "annual_data2['CV']=annual_data2['task'].apply(lambda x: in_category(x,'Computer Vision'))\n",
    "annual_data2['NLP']=annual_data2['task'].apply(lambda x: in_category(x,'Natural Language Processing'))\n",
    "annual_data2['Methodology']=annual_data2['task'].apply(lambda x: in_category(x,'Methodology'))\n",
    "\n",
    "annual_data2.to_csv(\"/mnt/c/Users/berna/Documents/GoogleDataProject/RatioInputs/FullDatasetforR2Years.txt\",sep='\\t',quoting=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "d3372eb3-4060-4e32-944f-cd09cd2e8cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>pwc_dataset_id</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>is_problematic</th>\n",
       "      <th>paper_count</th>\n",
       "      <th>task</th>\n",
       "      <th>categories</th>\n",
       "      <th>parents</th>\n",
       "      <th>children</th>\n",
       "      <th>siblings</th>\n",
       "      <th>pdf_url</th>\n",
       "      <th>paper_url</th>\n",
       "      <th>all_tasks</th>\n",
       "      <th>all_parents</th>\n",
       "      <th>all_children</th>\n",
       "      <th>all_siblings</th>\n",
       "      <th>all_categories</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>MNIST</td>\n",
       "      <td>1</td>\n",
       "      <td>On GANs and GMMs</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>False</td>\n",
       "      <td>4159</td>\n",
       "      <td>Image Generation</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[3D Face Animation]</td>\n",
       "      <td>[Image-to-Image Translation, Image Inpainting,...</td>\n",
       "      <td>[Image Generation]</td>\n",
       "      <td>http://arxiv.org/pdf/1805.12462v2.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/on-gans-and-gmms</td>\n",
       "      <td>[Image Generation]</td>\n",
       "      <td>[3D Face Animation]</td>\n",
       "      <td>[User Constrained Thumbnail Generation, Image ...</td>\n",
       "      <td>[Image Generation, Dialogue Generation, Image ...</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>CelebA</td>\n",
       "      <td>2</td>\n",
       "      <td>On GANs and GMMs</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>False</td>\n",
       "      <td>1539</td>\n",
       "      <td>Image Generation</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[3D Face Animation]</td>\n",
       "      <td>[Image-to-Image Translation, Image Inpainting,...</td>\n",
       "      <td>[Image Generation]</td>\n",
       "      <td>http://arxiv.org/pdf/1805.12462v2.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/on-gans-and-gmms</td>\n",
       "      <td>[Image Generation]</td>\n",
       "      <td>[3D Face Animation]</td>\n",
       "      <td>[User Constrained Thumbnail Generation, Image ...</td>\n",
       "      <td>[Image Generation, Dialogue Generation, Image ...</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>SVHN</td>\n",
       "      <td>424</td>\n",
       "      <td>On GANs and GMMs</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>False</td>\n",
       "      <td>1606</td>\n",
       "      <td>Image Generation</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[3D Face Animation]</td>\n",
       "      <td>[Image-to-Image Translation, Image Inpainting,...</td>\n",
       "      <td>[Image Generation]</td>\n",
       "      <td>http://arxiv.org/pdf/1805.12462v2.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/on-gans-and-gmms</td>\n",
       "      <td>[Image Generation]</td>\n",
       "      <td>[3D Face Animation]</td>\n",
       "      <td>[User Constrained Thumbnail Generation, Image ...</td>\n",
       "      <td>[Image Generation, Dialogue Generation, Image ...</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>CIFAR-10</td>\n",
       "      <td>431</td>\n",
       "      <td>On GANs and GMMs</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>False</td>\n",
       "      <td>6230</td>\n",
       "      <td>Image Generation</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[3D Face Animation]</td>\n",
       "      <td>[Image-to-Image Translation, Image Inpainting,...</td>\n",
       "      <td>[Image Generation]</td>\n",
       "      <td>http://arxiv.org/pdf/1805.12462v2.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/on-gans-and-gmms</td>\n",
       "      <td>[Image Generation]</td>\n",
       "      <td>[3D Face Animation]</td>\n",
       "      <td>[User Constrained Thumbnail Generation, Image ...</td>\n",
       "      <td>[Image Generation, Dialogue Generation, Image ...</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>MNIST</td>\n",
       "      <td>1</td>\n",
       "      <td>DVAE++: Discrete Variational Autoencoders with...</td>\n",
       "      <td>2018-02-14</td>\n",
       "      <td>False</td>\n",
       "      <td>4159</td>\n",
       "      <td>Image Generation</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[3D Face Animation]</td>\n",
       "      <td>[Image-to-Image Translation, Image Inpainting,...</td>\n",
       "      <td>[Image Generation]</td>\n",
       "      <td>http://arxiv.org/pdf/1802.04920v2.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/dvae-discrete...</td>\n",
       "      <td>[Image Generation, Latent Variable Models]</td>\n",
       "      <td>[3D Face Animation]</td>\n",
       "      <td>[User Constrained Thumbnail Generation, Image ...</td>\n",
       "      <td>[Image Generation, Dialogue Generation, Image ...</td>\n",
       "      <td>[Methodology, Computer Vision]</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219087</th>\n",
       "      <td>SketchyCOCO</td>\n",
       "      <td>7264</td>\n",
       "      <td>SketchyCOCO: Image Generation from Freehand Sc...</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>Image Generation</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[3D Face Animation]</td>\n",
       "      <td>[Image-to-Image Translation, Image Inpainting,...</td>\n",
       "      <td>[Image Generation]</td>\n",
       "      <td>https://arxiv.org/pdf/2003.02683v5.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/image-generat...</td>\n",
       "      <td>[Image Generation, Sketch-to-Image Translation]</td>\n",
       "      <td>[3D Face Animation]</td>\n",
       "      <td>[User Constrained Thumbnail Generation, Image ...</td>\n",
       "      <td>[Image Generation, Dialogue Generation, Image ...</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>2020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219088</th>\n",
       "      <td>Scribble</td>\n",
       "      <td>7265</td>\n",
       "      <td>SketchyCOCO: Image Generation from Freehand Sc...</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>Image Generation</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[3D Face Animation]</td>\n",
       "      <td>[Image-to-Image Translation, Image Inpainting,...</td>\n",
       "      <td>[Image Generation]</td>\n",
       "      <td>https://arxiv.org/pdf/2003.02683v5.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/image-generat...</td>\n",
       "      <td>[Image Generation, Sketch-to-Image Translation]</td>\n",
       "      <td>[3D Face Animation]</td>\n",
       "      <td>[User Constrained Thumbnail Generation, Image ...</td>\n",
       "      <td>[Image Generation, Dialogue Generation, Image ...</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>2020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219293</th>\n",
       "      <td>GazeCapture</td>\n",
       "      <td>7440</td>\n",
       "      <td>GazeGAN - Unpaired Adversarial Image Generatio...</td>\n",
       "      <td>2017-11-27</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "      <td>Image Generation</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[3D Face Animation]</td>\n",
       "      <td>[Image-to-Image Translation, Image Inpainting,...</td>\n",
       "      <td>[Image Generation]</td>\n",
       "      <td>http://arxiv.org/pdf/1711.09767v1.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/gazegan-unpai...</td>\n",
       "      <td>[Gaze Estimation, Image Generation, Medical Di...</td>\n",
       "      <td>[3D Face Animation]</td>\n",
       "      <td>[Thoracic Disease Classification, Pose Transfe...</td>\n",
       "      <td>[Image Generation, Dialogue Generation, Image ...</td>\n",
       "      <td>[Medical, Computer Vision]</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219370</th>\n",
       "      <td>RHD</td>\n",
       "      <td>7495</td>\n",
       "      <td>Disentangling Latent Hands for Image Synthesis...</td>\n",
       "      <td>2018-12-03</td>\n",
       "      <td>False</td>\n",
       "      <td>39</td>\n",
       "      <td>Image Generation</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[3D Face Animation]</td>\n",
       "      <td>[Image-to-Image Translation, Image Inpainting,...</td>\n",
       "      <td>[Image Generation]</td>\n",
       "      <td>http://arxiv.org/pdf/1812.01002v2.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/disentangling...</td>\n",
       "      <td>[Image Generation, Pose Estimation]</td>\n",
       "      <td>[3D Face Animation, 2D Human Pose Estimation]</td>\n",
       "      <td>[Pose Transfer, Vehicle Pose Estimation, Keypo...</td>\n",
       "      <td>[Pose Estimation, 3D Face Animation, Dialogue ...</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219855</th>\n",
       "      <td>CLUSTER</td>\n",
       "      <td>7778</td>\n",
       "      <td>Multiresolution Graph Variational Autoencoder</td>\n",
       "      <td>2021-06-02</td>\n",
       "      <td>False</td>\n",
       "      <td>40</td>\n",
       "      <td>Image Generation</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>[3D Face Animation]</td>\n",
       "      <td>[Image-to-Image Translation, Image Inpainting,...</td>\n",
       "      <td>[Image Generation]</td>\n",
       "      <td>https://arxiv.org/pdf/2106.00967v1.pdf</td>\n",
       "      <td>https://paperswithcode.com/paper/multiresoluti...</td>\n",
       "      <td>[Graph Generation, Image Generation, Link Pred...</td>\n",
       "      <td>[3D Face Animation]</td>\n",
       "      <td>[Graph Representation Learning, Calibration fo...</td>\n",
       "      <td>[Image Generation, Dialogue Generation, Image ...</td>\n",
       "      <td>[Knowledge Base, Methodology, Graphs, Computer...</td>\n",
       "      <td>2021.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2137 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               name  pwc_dataset_id  \\\n",
       "176           MNIST               1   \n",
       "177          CelebA               2   \n",
       "178            SVHN             424   \n",
       "179        CIFAR-10             431   \n",
       "212           MNIST               1   \n",
       "...             ...             ...   \n",
       "219087  SketchyCOCO            7264   \n",
       "219088     Scribble            7265   \n",
       "219293  GazeCapture            7440   \n",
       "219370          RHD            7495   \n",
       "219855      CLUSTER            7778   \n",
       "\n",
       "                                                    title       date  \\\n",
       "176                                      On GANs and GMMs 2018-05-31   \n",
       "177                                      On GANs and GMMs 2018-05-31   \n",
       "178                                      On GANs and GMMs 2018-05-31   \n",
       "179                                      On GANs and GMMs 2018-05-31   \n",
       "212     DVAE++: Discrete Variational Autoencoders with... 2018-02-14   \n",
       "...                                                   ...        ...   \n",
       "219087  SketchyCOCO: Image Generation from Freehand Sc... 2020-03-05   \n",
       "219088  SketchyCOCO: Image Generation from Freehand Sc... 2020-03-05   \n",
       "219293  GazeGAN - Unpaired Adversarial Image Generatio... 2017-11-27   \n",
       "219370  Disentangling Latent Hands for Image Synthesis... 2018-12-03   \n",
       "219855      Multiresolution Graph Variational Autoencoder 2021-06-02   \n",
       "\n",
       "        is_problematic  paper_count              task         categories  \\\n",
       "176              False         4159  Image Generation  [Computer Vision]   \n",
       "177              False         1539  Image Generation  [Computer Vision]   \n",
       "178              False         1606  Image Generation  [Computer Vision]   \n",
       "179              False         6230  Image Generation  [Computer Vision]   \n",
       "212              False         4159  Image Generation  [Computer Vision]   \n",
       "...                ...          ...               ...                ...   \n",
       "219087           False            4  Image Generation  [Computer Vision]   \n",
       "219088           False            3  Image Generation  [Computer Vision]   \n",
       "219293           False           25  Image Generation  [Computer Vision]   \n",
       "219370           False           39  Image Generation  [Computer Vision]   \n",
       "219855           False           40  Image Generation  [Computer Vision]   \n",
       "\n",
       "                    parents  \\\n",
       "176     [3D Face Animation]   \n",
       "177     [3D Face Animation]   \n",
       "178     [3D Face Animation]   \n",
       "179     [3D Face Animation]   \n",
       "212     [3D Face Animation]   \n",
       "...                     ...   \n",
       "219087  [3D Face Animation]   \n",
       "219088  [3D Face Animation]   \n",
       "219293  [3D Face Animation]   \n",
       "219370  [3D Face Animation]   \n",
       "219855  [3D Face Animation]   \n",
       "\n",
       "                                                 children            siblings  \\\n",
       "176     [Image-to-Image Translation, Image Inpainting,...  [Image Generation]   \n",
       "177     [Image-to-Image Translation, Image Inpainting,...  [Image Generation]   \n",
       "178     [Image-to-Image Translation, Image Inpainting,...  [Image Generation]   \n",
       "179     [Image-to-Image Translation, Image Inpainting,...  [Image Generation]   \n",
       "212     [Image-to-Image Translation, Image Inpainting,...  [Image Generation]   \n",
       "...                                                   ...                 ...   \n",
       "219087  [Image-to-Image Translation, Image Inpainting,...  [Image Generation]   \n",
       "219088  [Image-to-Image Translation, Image Inpainting,...  [Image Generation]   \n",
       "219293  [Image-to-Image Translation, Image Inpainting,...  [Image Generation]   \n",
       "219370  [Image-to-Image Translation, Image Inpainting,...  [Image Generation]   \n",
       "219855  [Image-to-Image Translation, Image Inpainting,...  [Image Generation]   \n",
       "\n",
       "                                       pdf_url  \\\n",
       "176      http://arxiv.org/pdf/1805.12462v2.pdf   \n",
       "177      http://arxiv.org/pdf/1805.12462v2.pdf   \n",
       "178      http://arxiv.org/pdf/1805.12462v2.pdf   \n",
       "179      http://arxiv.org/pdf/1805.12462v2.pdf   \n",
       "212      http://arxiv.org/pdf/1802.04920v2.pdf   \n",
       "...                                        ...   \n",
       "219087  https://arxiv.org/pdf/2003.02683v5.pdf   \n",
       "219088  https://arxiv.org/pdf/2003.02683v5.pdf   \n",
       "219293   http://arxiv.org/pdf/1711.09767v1.pdf   \n",
       "219370   http://arxiv.org/pdf/1812.01002v2.pdf   \n",
       "219855  https://arxiv.org/pdf/2106.00967v1.pdf   \n",
       "\n",
       "                                                paper_url  \\\n",
       "176     https://paperswithcode.com/paper/on-gans-and-gmms   \n",
       "177     https://paperswithcode.com/paper/on-gans-and-gmms   \n",
       "178     https://paperswithcode.com/paper/on-gans-and-gmms   \n",
       "179     https://paperswithcode.com/paper/on-gans-and-gmms   \n",
       "212     https://paperswithcode.com/paper/dvae-discrete...   \n",
       "...                                                   ...   \n",
       "219087  https://paperswithcode.com/paper/image-generat...   \n",
       "219088  https://paperswithcode.com/paper/image-generat...   \n",
       "219293  https://paperswithcode.com/paper/gazegan-unpai...   \n",
       "219370  https://paperswithcode.com/paper/disentangling...   \n",
       "219855  https://paperswithcode.com/paper/multiresoluti...   \n",
       "\n",
       "                                                all_tasks  \\\n",
       "176                                    [Image Generation]   \n",
       "177                                    [Image Generation]   \n",
       "178                                    [Image Generation]   \n",
       "179                                    [Image Generation]   \n",
       "212            [Image Generation, Latent Variable Models]   \n",
       "...                                                   ...   \n",
       "219087    [Image Generation, Sketch-to-Image Translation]   \n",
       "219088    [Image Generation, Sketch-to-Image Translation]   \n",
       "219293  [Gaze Estimation, Image Generation, Medical Di...   \n",
       "219370                [Image Generation, Pose Estimation]   \n",
       "219855  [Graph Generation, Image Generation, Link Pred...   \n",
       "\n",
       "                                          all_parents  \\\n",
       "176                               [3D Face Animation]   \n",
       "177                               [3D Face Animation]   \n",
       "178                               [3D Face Animation]   \n",
       "179                               [3D Face Animation]   \n",
       "212                               [3D Face Animation]   \n",
       "...                                               ...   \n",
       "219087                            [3D Face Animation]   \n",
       "219088                            [3D Face Animation]   \n",
       "219293                            [3D Face Animation]   \n",
       "219370  [3D Face Animation, 2D Human Pose Estimation]   \n",
       "219855                            [3D Face Animation]   \n",
       "\n",
       "                                             all_children  \\\n",
       "176     [User Constrained Thumbnail Generation, Image ...   \n",
       "177     [User Constrained Thumbnail Generation, Image ...   \n",
       "178     [User Constrained Thumbnail Generation, Image ...   \n",
       "179     [User Constrained Thumbnail Generation, Image ...   \n",
       "212     [User Constrained Thumbnail Generation, Image ...   \n",
       "...                                                   ...   \n",
       "219087  [User Constrained Thumbnail Generation, Image ...   \n",
       "219088  [User Constrained Thumbnail Generation, Image ...   \n",
       "219293  [Thoracic Disease Classification, Pose Transfe...   \n",
       "219370  [Pose Transfer, Vehicle Pose Estimation, Keypo...   \n",
       "219855  [Graph Representation Learning, Calibration fo...   \n",
       "\n",
       "                                             all_siblings  \\\n",
       "176     [Image Generation, Dialogue Generation, Image ...   \n",
       "177     [Image Generation, Dialogue Generation, Image ...   \n",
       "178     [Image Generation, Dialogue Generation, Image ...   \n",
       "179     [Image Generation, Dialogue Generation, Image ...   \n",
       "212     [Image Generation, Dialogue Generation, Image ...   \n",
       "...                                                   ...   \n",
       "219087  [Image Generation, Dialogue Generation, Image ...   \n",
       "219088  [Image Generation, Dialogue Generation, Image ...   \n",
       "219293  [Image Generation, Dialogue Generation, Image ...   \n",
       "219370  [Pose Estimation, 3D Face Animation, Dialogue ...   \n",
       "219855  [Image Generation, Dialogue Generation, Image ...   \n",
       "\n",
       "                                           all_categories    year  \n",
       "176                                     [Computer Vision]  2018.0  \n",
       "177                                     [Computer Vision]  2018.0  \n",
       "178                                     [Computer Vision]  2018.0  \n",
       "179                                     [Computer Vision]  2018.0  \n",
       "212                        [Methodology, Computer Vision]  2018.0  \n",
       "...                                                   ...     ...  \n",
       "219087                                  [Computer Vision]  2020.0  \n",
       "219088                                  [Computer Vision]  2020.0  \n",
       "219293                         [Medical, Computer Vision]  2017.0  \n",
       "219370                                  [Computer Vision]  2018.0  \n",
       "219855  [Knowledge Base, Methodology, Graphs, Computer...  2021.0  \n",
       "\n",
       "[2137 rows x 19 columns]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_citing_papers_pwc[dataset_citing_papers_pwc.task=='Image Generation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c84a9582-5a2d-49f9-a9d6-28896e5317e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-92-0d3c0921d5d1>:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D Object Detection\n",
      "3D Face Reconstruction\n",
      "3D Human Pose Estimation\n",
      "3D Object Detection\n",
      "3D Reconstruction\n",
      "3D Semantic Segmentation\n",
      "Action Classification\n",
      "Action Detection\n",
      "Action Recognition\n",
      "Anomaly Detection\n",
      "Atari Games\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-0d3c0921d5d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mtasks_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mtasks_borrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtasks_homegrown\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mtasks_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtasks_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'task'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtasks_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'task'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtasks_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'source'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'tasks/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mout_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmethods_tasks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/data/lib/python3.8/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   2178\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2180\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/data/lib/python3.8/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2084\u001b[0;31m                 result = print_method(\n\u001b[0m\u001b[1;32m   2085\u001b[0m                     \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2086\u001b[0m                     \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/data/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_jpg\u001b[0;34m(self, filename_or_obj, dryrun, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0mpil_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"quality\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"savefig.jpeg_quality\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0mpil_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dpi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m             return background.save(\n\u001b[0m\u001b[1;32m    597\u001b[0m                 filename_or_obj, format='jpeg', **pil_kwargs)\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/data/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2237\u001b[0m             \u001b[0;31m# do what we can to clean up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2238\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mopen_fp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2239\u001b[0;31m                 \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#annual_data[['task','date','size','task_age','pwc_size']]\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "methods_tasks=pd.read_csv(\"MethodTasksfromEmily.txt\",header=None).squeeze().tolist()\n",
    "outpath='/mnt/c/Users/berna/Documents/GoogleDataProject/ImportPlots/'\n",
    "completed=os.listdir('/mnt/c/Users/berna/Documents/GoogleDataProject/ImportPlots/tasks')\n",
    "\n",
    "modality_dict=datasets[['name','modalities']]\n",
    "modality_dict['modes']=modality_dict['modalities'].apply(lambda x: x if x!= [] else ['Unknown'])\n",
    "modality_dict=modality_dict.drop('modalities',axis=1).set_index('name').squeeze()\n",
    "\n",
    "for p in median_parent_tasks:\n",
    "    print(p)\n",
    "    out_name=p.replace('/','_').replace(' ','_')\n",
    "    '''\n",
    "    if out_name+'.jpg' in completed:\n",
    "        print(\"COMPLETED\")\n",
    "        continue\n",
    "    '''\n",
    "    datasets_borrow=source_dest_edgelist_parents[source_dest_edgelist_parents.dest_task==p].drop_duplicates(['name','title']).groupby('name').size().sort_values().to_frame()\n",
    "    datasets_borrow['source']='blue'\n",
    "    datasets_homegrown=homegrown_edgelist_parents[homegrown_edgelist_parents.task==p].drop_duplicates(['name','title']).groupby('name').size().sort_values().to_frame()\n",
    "    datasets_homegrown['source']='orange'\n",
    "    dataset_df=pd.concat([ datasets_borrow,datasets_homegrown]).reset_index().sort_values(0,ascending=False)\n",
    "    if len(dataset_df)==0:continue\n",
    "    dataset_df=dataset_df.rename({0:'count'},axis=1)\n",
    "    d=dataset_df.plot.barh(x='name',y='count',color=dataset_df['source'],figsize=(20, 20)).figure.savefig(outpath+'datasets/'+out_name+'.jpg')\n",
    "    plt.clf();plt.close()\n",
    "    if p in methods_tasks:\n",
    "            d=dataset_df.plot.barh(x='name',y='count',color=dataset_df['source'],figsize=(20, 20)).figure.savefig(outpath+'methods_datasets/'+out_name+'.jpg')\n",
    "            plt.clf();plt.close()\n",
    "    tasks_borrow=source_dest_edgelist_parents[source_dest_edgelist_parents.dest_task==p].drop_duplicates(['name','title']).groupby('source_task').size().sort_values().to_frame()\n",
    "    tasks_borrow['source']='blue'\n",
    "    tasks_homegrown=homegrown_edgelist_parents[homegrown_edgelist_parents.task==p].drop_duplicates(['name','title']).groupby('task').size().sort_values().to_frame()\n",
    "    tasks_homegrown['source']='orange'\n",
    "    tasks_df=pd.concat([ tasks_borrow,tasks_homegrown]).reset_index().sort_values(0,ascending=False)\n",
    "    tasks_df=tasks_df.rename({0:'count','index':'task'},axis=1)\n",
    "    t=tasks_df.plot.barh(x='task',y='count',color=tasks_df['source'],figsize=(20, 20)).figure.savefig(outpath+'tasks/'+out_name+'.jpg')\n",
    "    plt.clf();plt.close()\n",
    "    if p in methods_tasks:\n",
    "            t=tasks_df.plot.barh(x='task',y='count',color=tasks_df['source'],figsize=(20, 20)).figure.savefig(outpath+'methods_tasks/'+out_name+'.jpg')\n",
    "            plt.clf();plt.close()\n",
    "    if p not in methods_tasks: continue\n",
    "    modalities=[]\n",
    "    for i,row in dataset_df.iterrows(): modalities+=modality_dict[row['name']]*row['count']\n",
    "    modalities=pd.Series(modalities).value_counts().sort_values(ascending=False)\n",
    "    m=modalities.plot.barh(figsize=(20, 20)).figure.savefig(outpath+'methods_modalities/'+out_name+'.jpg')\n",
    "    plt.clf();plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f566a1be-a772-4396-b21c-74815c178124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.0"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_usage_hist.quantile(.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eeea9a56-4e3d-4f09-9a9f-f90991ded088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_task</th>\n",
       "      <th>dest_task</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>Images</th>\n",
       "      <th>Texts</th>\n",
       "      <th>Parent_Transfer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [source_task, dest_task, name, title, date, Images, Texts, Parent_Transfer]\n",
       "Index: []"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_dest_edgelist_parents[source_dest_edgelist_parents.dest_task==p].drop_duplicates(['name','title']).groupby('name').size().sort_values().to_frame()\n",
    "source_dest_edgelist_parents[source_dest_edgelist_parents.source_task=='Adversarial Attack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b5da71d4-eb23-4d08-8157-05a8c9d1bb36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>task</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>Images</th>\n",
       "      <th>Texts</th>\n",
       "      <th>Parent</th>\n",
       "      <th>introduced_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Image Classification</td>\n",
       "      <td>MNIST</td>\n",
       "      <td>Image classification and retrieval with random...</td>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Optical Character Recognition</td>\n",
       "      <td>MNIST</td>\n",
       "      <td>Image classification and retrieval with random...</td>\n",
       "      <td>2018-06-15</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Image Classification</td>\n",
       "      <td>MNIST</td>\n",
       "      <td>ASP:A Fast Adversarial Attack Example Generati...</td>\n",
       "      <td>2018-02-15</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Optical Character Recognition</td>\n",
       "      <td>MNIST</td>\n",
       "      <td>ASP:A Fast Adversarial Attack Example Generati...</td>\n",
       "      <td>2018-02-15</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Image Classification</td>\n",
       "      <td>MNIST</td>\n",
       "      <td>Dual Pattern Learning Networks by Empirical Du...</td>\n",
       "      <td>2018-06-11</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26319</th>\n",
       "      <td>259614</td>\n",
       "      <td>Image Retrieval</td>\n",
       "      <td>Google Landmarks</td>\n",
       "      <td>Two-stage Discriminative Re-ranking for Large-...</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2016-12-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26320</th>\n",
       "      <td>259615</td>\n",
       "      <td>Music Generation</td>\n",
       "      <td>Lakh Pianoroll Dataset</td>\n",
       "      <td>A Comprehensive Survey on Deep Music Generatio...</td>\n",
       "      <td>2020-11-13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-09-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26321</th>\n",
       "      <td>259617</td>\n",
       "      <td>Music Generation</td>\n",
       "      <td>Lakh Pianoroll Dataset</td>\n",
       "      <td>Convolutional Generative Adversarial Networks ...</td>\n",
       "      <td>2018-04-25</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-09-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26322</th>\n",
       "      <td>259618</td>\n",
       "      <td>Music Generation</td>\n",
       "      <td>Lakh Pianoroll Dataset</td>\n",
       "      <td>Lead Sheet Generation and Arrangement by Condi...</td>\n",
       "      <td>2018-07-30</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-09-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26323</th>\n",
       "      <td>259619</td>\n",
       "      <td>Music Generation</td>\n",
       "      <td>Lakh Pianoroll Dataset</td>\n",
       "      <td>MIDI-Sandwich2: RNN-based Hierarchical Multi-m...</td>\n",
       "      <td>2019-09-08</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-09-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26324 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                           task                    name  \\\n",
       "0               0           Image Classification                   MNIST   \n",
       "1               1  Optical Character Recognition                   MNIST   \n",
       "2               4           Image Classification                   MNIST   \n",
       "3               5  Optical Character Recognition                   MNIST   \n",
       "4              10           Image Classification                   MNIST   \n",
       "...           ...                            ...                     ...   \n",
       "26319      259614                Image Retrieval        Google Landmarks   \n",
       "26320      259615               Music Generation  Lakh Pianoroll Dataset   \n",
       "26321      259617               Music Generation  Lakh Pianoroll Dataset   \n",
       "26322      259618               Music Generation  Lakh Pianoroll Dataset   \n",
       "26323      259619               Music Generation  Lakh Pianoroll Dataset   \n",
       "\n",
       "                                                   title        date  Images  \\\n",
       "0      Image classification and retrieval with random...  2018-06-15    True   \n",
       "1      Image classification and retrieval with random...  2018-06-15    True   \n",
       "2      ASP:A Fast Adversarial Attack Example Generati...  2018-02-15    True   \n",
       "3      ASP:A Fast Adversarial Attack Example Generati...  2018-02-15    True   \n",
       "4      Dual Pattern Learning Networks by Empirical Du...  2018-06-11    True   \n",
       "...                                                  ...         ...     ...   \n",
       "26319  Two-stage Discriminative Re-ranking for Large-...  2020-03-25    True   \n",
       "26320  A Comprehensive Survey on Deep Music Generatio...  2020-11-13   False   \n",
       "26321  Convolutional Generative Adversarial Networks ...  2018-04-25   False   \n",
       "26322  Lead Sheet Generation and Arrangement by Condi...  2018-07-30   False   \n",
       "26323  MIDI-Sandwich2: RNN-based Hierarchical Multi-m...  2019-09-08   False   \n",
       "\n",
       "       Texts  Parent introduced_date  \n",
       "0      False   False             NaN  \n",
       "1      False    True             NaN  \n",
       "2      False   False             NaN  \n",
       "3      False    True             NaN  \n",
       "4      False   False             NaN  \n",
       "...      ...     ...             ...  \n",
       "26319  False   False      2016-12-19  \n",
       "26320  False   False      2017-09-19  \n",
       "26321  False   False      2017-09-19  \n",
       "26322  False   False      2017-09-19  \n",
       "26323  False   False      2017-09-19  \n",
       "\n",
       "[26324 rows x 9 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_dest_edgelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7672056-9e91-4f09-a888-26cc3b8decd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "p='Image Generation'\n",
    "datasets_borrow=source_dest_edgelist[source_dest_edgelist.dest_task==p].drop_duplicates(['name','title']).groupby('name').size().sort_values().to_frame()\n",
    "datasets_borrow['source']='blue'\n",
    "datasets_homegrown=homegrown_edgelist[homegrown_edgelist.task==p].drop_duplicates(['name','title']).groupby('name').size().sort_values().to_frame()\n",
    "datasets_homegrown['source']='orange'\n",
    "dataset_df=pd.concat([ datasets_borrow,datasets_homegrown]).reset_index().sort_values(0,ascending=False)\n",
    "dataset_df=dataset_df.rename({0:'count'},axis=1)\n",
    "\n",
    "tasks_borrow=source_dest_edgelist[source_dest_edgelist.dest_task==p].drop_duplicates(['name','title']).groupby('source_task').size().sort_values().to_frame()\n",
    "tasks_borrow['source']='blue'\n",
    "tasks_homegrown=homegrown_edgelist[homegrown_edgelist.task==p].drop_duplicates(['name','title']).groupby('task').size().sort_values().to_frame()\n",
    "tasks_homegrown['source']='orange'\n",
    "tasks_df=pd.concat([ tasks_borrow,tasks_homegrown]).reset_index().sort_values(0,ascending=False)\n",
    "tasks_df=tasks_df.rename({0:'count','index':'task'},axis=1)\n",
    "\n",
    "dataset_df['cumulative']=dataset_df.sort_values('count',ascending=False)['count'].cumsum()/dataset_df.sort_values('count',ascending=False)['count'].sum()\n",
    "#tasks_df.set_index('task').plot.pie(y='count')\n",
    "other_count=dataset_df[dataset_df['cumulative']>.90]['count'].sum()\n",
    "dataset_df=dataset_df[dataset_df['cumulative']<.90]\n",
    "dataset_df=dataset_df.append({'name':'Other','count':other_count,'cumulative':1,'source':'gray'},ignore_index=True)\n",
    "\n",
    "tasks_df['cumulative']=tasks_df.sort_values('count',ascending=False)['count'].cumsum()/tasks_df.sort_values('count',ascending=False)['count'].sum()\n",
    "#tasks_df.set_index('task').plot.pie(y='count')\n",
    "other_count=tasks_df[tasks_df['cumulative']>.90]['count'].sum()\n",
    "tasks_df=tasks_df[tasks_df['cumulative']<.90]\n",
    "tasks_df=tasks_df.append({'task':'Other','count':other_count,'cumulative':1,'source':'gray'},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ec8ed91-8489-45be-8103-060a71630d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "labels": [
          "Face Detection",
          "Scene Understanding",
          "Object Recognition",
          "Scene Parsing",
          "Image Generation",
          "Handwriting Recognition",
          "Image Classification",
          "Other"
         ],
         "marker": {
          "colors": [
           "rgb(228,26,28)",
           "rgb(55,126,184)",
           "rgb(77,175,74)",
           "rgb(152,78,163)",
           "rgb(255,127,0)",
           "rgb(255,255,51)",
           "rgb(166,86,40)",
           "rgb(247,129,191)",
           "rgb(153,153,153)"
          ],
          "line": {
           "color": "#000000",
           "width": 1
          }
         },
         "pull": [
          0,
          0,
          0,
          0,
          0.2,
          0,
          0
         ],
         "textfont": {
          "color": "black"
         },
         "type": "pie",
         "values": [
          189,
          167,
          161,
          88,
          88,
          73,
          67,
          94
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "font": {
         "color": "black",
         "family": "Arial"
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "family": "Arial"
         }
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>                            <div id=\"40504b0f-4731-448b-b99a-e4cb3d8b7e4f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"40504b0f-4731-448b-b99a-e4cb3d8b7e4f\")) {                    Plotly.newPlot(                        \"40504b0f-4731-448b-b99a-e4cb3d8b7e4f\",                        [{\"labels\":[\"Face Detection\",\"Scene Understanding\",\"Object Recognition\",\"Scene Parsing\",\"Image Generation\",\"Handwriting Recognition\",\"Image Classification\",\"Other\"],\"marker\":{\"colors\":[\"rgb(228,26,28)\",\"rgb(55,126,184)\",\"rgb(77,175,74)\",\"rgb(152,78,163)\",\"rgb(255,127,0)\",\"rgb(255,255,51)\",\"rgb(166,86,40)\",\"rgb(247,129,191)\",\"rgb(153,153,153)\"],\"line\":{\"color\":\"#000000\",\"width\":1}},\"pull\":[0,0,0,0.0,0.2,0,0],\"textfont\":{\"color\":\"black\"},\"type\":\"pie\",\"values\":[189,167,161,88,88,73,67,94]}],                        {\"font\":{\"color\":\"black\",\"family\":\"Arial\"},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"font\":{\"family\":\"Arial\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('40504b0f-4731-448b-b99a-e4cb3d8b7e4f');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "labels": [
          "CelebA",
          "Cityscapes",
          "ImageNet",
          "MNIST",
          "LSUN",
          "FFHQ",
          "CUB-200-2011",
          "Other"
         ],
         "marker": {
          "colors": [
           "rgb(141,211,199)",
           "rgb(255,255,179)",
           "rgb(190,186,218)",
           "rgb(251,128,114)",
           "rgb(128,177,211)",
           "rgb(253,180,98)",
           "rgb(179,222,105)",
           "rgb(252,205,229)",
           "rgb(217,217,217)",
           "rgb(188,128,189)",
           "rgb(204,235,197)",
           "rgb(255,237,111)"
          ],
          "line": {
           "color": "#000000",
           "width": 1
          }
         },
         "pull": [
          0,
          0,
          0,
          0,
          0,
          0.2,
          0
         ],
         "textfont": {
          "color": "black"
         },
         "type": "pie",
         "values": [
          189,
          163,
          134,
          95,
          92,
          81,
          60,
          113
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "font": {
         "color": "black",
         "family": "Arial"
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "family": "Arial"
         }
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>                            <div id=\"be92cf84-8786-42c7-9b7e-4c27172ef4c4\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"be92cf84-8786-42c7-9b7e-4c27172ef4c4\")) {                    Plotly.newPlot(                        \"be92cf84-8786-42c7-9b7e-4c27172ef4c4\",                        [{\"labels\":[\"CelebA\",\"Cityscapes\",\"ImageNet\",\"MNIST\",\"LSUN\",\"FFHQ\",\"CUB-200-2011\",\"Other\"],\"marker\":{\"colors\":[\"rgb(141,211,199)\",\"rgb(255,255,179)\",\"rgb(190,186,218)\",\"rgb(251,128,114)\",\"rgb(128,177,211)\",\"rgb(253,180,98)\",\"rgb(179,222,105)\",\"rgb(252,205,229)\",\"rgb(217,217,217)\",\"rgb(188,128,189)\",\"rgb(204,235,197)\",\"rgb(255,237,111)\"],\"line\":{\"color\":\"#000000\",\"width\":1}},\"pull\":[0,0,0,0.0,0,0.2,0],\"textfont\":{\"color\":\"black\"},\"type\":\"pie\",\"values\":[189,163,134,95,92,81,60,113]}],                        {\"font\":{\"color\":\"black\",\"family\":\"Arial\"},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"font\":{\"family\":\"Arial\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('be92cf84-8786-42c7-9b7e-4c27172ef4c4');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "fig = go.Figure(data=[go.Pie(labels=tasks_df['task'], \n",
    "                             values=tasks_df['count'],\n",
    "                            pull=[0, 0, 0, 0.0,0.2,0,0])])\n",
    "fig.update_layout(\n",
    "    font_family=\"Arial\",\n",
    "    title_font_family=\"Arial\",\n",
    "    font_color='black',\n",
    ")\n",
    "fig.update_traces(marker=dict(colors=px.colors.qualitative.Set1,line=dict(color='#000000', width=1)),textfont_color='black')\n",
    "fig.show()\n",
    "fig.write_image(\"/mnt/c/Users/berna/Documents/GoogleDataProject/ImportPlots/ImageGenerationTasks.svg\")\n",
    "fig = go.Figure(data=[go.Pie(labels=dataset_df['name'], \n",
    "                             values=dataset_df['count'],\n",
    "                            pull=[0, 0, 0, 0.0,0,0.2,0])])\n",
    "fig.update_layout(\n",
    "    font_family=\"Arial\",\n",
    "    title_font_family=\"Arial\",\n",
    "    font_color='black',\n",
    ")\n",
    "fig.update_traces(marker=dict(colors=px.colors.qualitative.Set3,line=dict(color='#000000', width=1)),textfont_color='black')\n",
    "#fig.write_image(\"ImageGenDatasets.svg\")\n",
    "fig.show()\n",
    "fig.write_image(\"/mnt/c/Users/berna/Documents/GoogleDataProject/ImportPlots/ImageGenerationDatasets.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6ede41d2-1024-4bc1-82df-a38897513321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaleido in /home/bkoch/miniconda3/envs/data/lib/python3.8/site-packages (0.2.1)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1306c978-39a7-4a9a-a68f-6123dfcfd149",
   "metadata": {},
   "outputs": [],
   "source": [
    "p='Face Recognition'\n",
    "datasets_borrow=source_dest_edgelist[source_dest_edgelist.dest_task==p].drop_duplicates(['name','title']).groupby('name').size().sort_values().to_frame()\n",
    "datasets_borrow['source']='blue'\n",
    "datasets_homegrown=homegrown_edgelist[homegrown_edgelist.task==p].drop_duplicates(['name','title']).groupby('name').size().sort_values().to_frame()\n",
    "datasets_homegrown['source']='orange'\n",
    "dataset_df=pd.concat([ datasets_borrow,datasets_homegrown]).reset_index().sort_values(0,ascending=False)\n",
    "dataset_df=dataset_df.rename({0:'count'},axis=1)\n",
    "\n",
    "tasks_borrow=source_dest_edgelist[source_dest_edgelist.dest_task==p].drop_duplicates(['name','title']).groupby('source_task').size().sort_values().to_frame()\n",
    "tasks_borrow['source']='blue'\n",
    "tasks_homegrown=homegrown_edgelist[homegrown_edgelist.task==p].drop_duplicates(['name','title']).groupby('task').size().sort_values().to_frame()\n",
    "tasks_homegrown['source']='orange'\n",
    "tasks_df=pd.concat([ tasks_borrow,tasks_homegrown]).reset_index().sort_values(0,ascending=False)\n",
    "tasks_df=tasks_df.rename({0:'count','index':'task'},axis=1)\n",
    "\n",
    "dataset_df['cumulative']=dataset_df.sort_values('count',ascending=False)['count'].cumsum()/dataset_df.sort_values('count',ascending=False)['count'].sum()\n",
    "#tasks_df.set_index('task').plot.pie(y='count')\n",
    "other_count=dataset_df[dataset_df['cumulative']>.85]['count'].sum()\n",
    "dataset_df=dataset_df[dataset_df['cumulative']<.85]\n",
    "dataset_df=dataset_df.append({'name':'Other','count':other_count,'cumulative':1,'source':'gray'},ignore_index=True)\n",
    "\n",
    "tasks_df['cumulative']=tasks_df.sort_values('count',ascending=False)['count'].cumsum()/tasks_df.sort_values('count',ascending=False)['count'].sum()\n",
    "#tasks_df.set_index('task').plot.pie(y='count')\n",
    "other_count=tasks_df[tasks_df['cumulative']>.85]['count'].sum()\n",
    "tasks_df=tasks_df[tasks_df['cumulative']<.85]\n",
    "tasks_df=tasks_df.append({'task':'Other','count':other_count,'cumulative':1,'source':'gray'},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "05ece0fb-18d4-42f0-b443-9d3f6782498e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "labels": [
          "Face Recognition",
          "Other"
         ],
         "marker": {
          "colors": [
           "rgb(228,26,28)",
           "rgb(55,126,184)",
           "rgb(77,175,74)",
           "rgb(152,78,163)",
           "rgb(255,127,0)",
           "rgb(255,255,51)",
           "rgb(166,86,40)",
           "rgb(247,129,191)",
           "rgb(153,153,153)"
          ],
          "line": {
           "color": "#000000",
           "width": 1
          }
         },
         "pull": [
          0,
          0,
          0,
          0.2,
          0,
          0,
          0
         ],
         "textfont": {
          "color": "black"
         },
         "type": "pie",
         "values": [
          776,
          453
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "font": {
         "color": "black",
         "family": "Arial"
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "family": "Arial"
         }
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>                            <div id=\"4473fff5-1316-4d58-9969-f9455b86e815\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4473fff5-1316-4d58-9969-f9455b86e815\")) {                    Plotly.newPlot(                        \"4473fff5-1316-4d58-9969-f9455b86e815\",                        [{\"labels\":[\"Face Recognition\",\"Other\"],\"marker\":{\"colors\":[\"rgb(228,26,28)\",\"rgb(55,126,184)\",\"rgb(77,175,74)\",\"rgb(152,78,163)\",\"rgb(255,127,0)\",\"rgb(255,255,51)\",\"rgb(166,86,40)\",\"rgb(247,129,191)\",\"rgb(153,153,153)\"],\"line\":{\"color\":\"#000000\",\"width\":1}},\"pull\":[0,0,0,0.2,0,0,0],\"textfont\":{\"color\":\"black\"},\"type\":\"pie\",\"values\":[776,453]}],                        {\"font\":{\"color\":\"black\",\"family\":\"Arial\"},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"font\":{\"family\":\"Arial\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('4473fff5-1316-4d58-9969-f9455b86e815');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "labels": [
          "LFW",
          "CASIA-WebFace",
          "VGGFace2",
          "MegaFace",
          "MS-Celeb-1M",
          "IJB-A",
          "Multi-PIE",
          "Other"
         ],
         "marker": {
          "colors": [
           "rgb(228,26,28)",
           "rgb(55,126,184)",
           "rgb(77,175,74)",
           "rgb(255,255,,255)",
           "rgb(255,255,255)",
           "rgb(255,255,51)",
           "rgb(166,86,40)",
           "rgb(247,129,191)",
           "rgb(153,153,153)"
          ],
          "line": {
           "color": "#000000",
           "width": 1
          }
         },
         "pull": [
          0,
          0,
          0,
          0.2,
          0.2,
          0,
          0
         ],
         "textfont": {
          "color": "black"
         },
         "type": "pie",
         "values": [
          301,
          158,
          130,
          110,
          110,
          108,
          93,
          219
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "font": {
         "color": "black",
         "family": "Arial"
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "family": "Arial"
         }
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>                            <div id=\"99aa5ea9-910b-40d6-97e6-898b2b8ff454\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"99aa5ea9-910b-40d6-97e6-898b2b8ff454\")) {                    Plotly.newPlot(                        \"99aa5ea9-910b-40d6-97e6-898b2b8ff454\",                        [{\"labels\":[\"LFW\",\"CASIA-WebFace\",\"VGGFace2\",\"MegaFace\",\"MS-Celeb-1M\",\"IJB-A\",\"Multi-PIE\",\"Other\"],\"marker\":{\"colors\":[\"rgb(228,26,28)\",\"rgb(55,126,184)\",\"rgb(77,175,74)\",\"rgb(255,255,,255)\",\"rgb(255,255,255)\",\"rgb(255,255,51)\",\"rgb(166,86,40)\",\"rgb(247,129,191)\",\"rgb(153,153,153)\"],\"line\":{\"color\":\"#000000\",\"width\":1}},\"pull\":[0,0,0,0.2,0.2,0,0],\"textfont\":{\"color\":\"black\"},\"type\":\"pie\",\"values\":[301,158,130,110,110,108,93,219]}],                        {\"font\":{\"color\":\"black\",\"family\":\"Arial\"},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"font\":{\"family\":\"Arial\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('99aa5ea9-910b-40d6-97e6-898b2b8ff454');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[go.Pie(labels=tasks_df['task'], \n",
    "                             values=tasks_df['count'],\n",
    "                            pull=[0, 0, 0, 0.2,0,0,0])])\n",
    "fig.update_layout(\n",
    "    font_family=\"Arial\",\n",
    "    title_font_family=\"Arial\",\n",
    "    font_color='black',\n",
    ")\n",
    "fig.update_traces(marker=dict(colors=px.colors.qualitative.Set1,line=dict(color='#000000', width=1)),textfont_color='black')\n",
    "fig.show()\n",
    "temp=[i for i in px.colors.qualitative.Set1]\n",
    "temp[3]='rgb(255,255,,255)'\n",
    "temp[4]='rgb(255,255,255)'\n",
    "temp\n",
    "fig = go.Figure(data=[go.Pie(labels=dataset_df['name'], \n",
    "                             values=dataset_df['count'],\n",
    "                            pull=[0, 0, 0,.2,.2,0,0])])\n",
    "fig.update_layout(\n",
    "    font_family=\"Arial\",\n",
    "    title_font_family=\"Arial\",\n",
    "    font_color='black',\n",
    ")\n",
    "fig.update_traces(marker=dict(colors=temp,line=dict(color='#000000', width=1)),textfont_color='black')\n",
    "fig.show()\n",
    "fig.write_image(\"/mnt/c/Users/berna/Documents/GoogleDataProject/ImportPlots/FaceRecognitionDatasets.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8cc2a650-2ebe-4d87-b045-8f310f93988f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rgb(228,26,28)',\n",
       " 'rgb(55,126,184)',\n",
       " 'rgb(77,175,74)',\n",
       " 'rgb(0,0,0)',\n",
       " 'rgb(0,0,0)',\n",
       " 'rgb(255,255,51)',\n",
       " 'rgb(166,86,40)',\n",
       " 'rgb(247,129,191)',\n",
       " 'rgb(153,153,153)']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88e7c9e4-8e4b-4fb0-af27-4e10958a2748",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "tasks_df['cumulative']=tasks_df.sort_values('count',ascending=False)['count'].cumsum()/tasks_df.sort_values('count',ascending=False)['count'].sum()\n",
    "#tasks_df.set_index('task').plot.pie(y='count')\n",
    "other_count=tasks_df[tasks_df['cumulative']>.99]['count'].sum()\n",
    "tasks_df=tasks_df[tasks_df['cumulative']<.99]\n",
    "tasks_df=tasks_df.append({'task':'Other','count':other_count,'cumulative':1,'source':'gray'},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7cd31219-fd7d-4142-bf9b-90f7c96604e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>count</th>\n",
       "      <th>source</th>\n",
       "      <th>cumulative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CASIA-WebFace</td>\n",
       "      <td>158</td>\n",
       "      <td>orange</td>\n",
       "      <td>0.208995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VGGFace2</td>\n",
       "      <td>129</td>\n",
       "      <td>orange</td>\n",
       "      <td>0.379630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MS-Celeb-1M</td>\n",
       "      <td>109</td>\n",
       "      <td>orange</td>\n",
       "      <td>0.523810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MegaFace</td>\n",
       "      <td>108</td>\n",
       "      <td>orange</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IJB-A</td>\n",
       "      <td>108</td>\n",
       "      <td>orange</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CelebA</td>\n",
       "      <td>75</td>\n",
       "      <td>blue</td>\n",
       "      <td>0.908730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Other</td>\n",
       "      <td>50</td>\n",
       "      <td>gray</td>\n",
       "      <td>0.974868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Other</td>\n",
       "      <td>19</td>\n",
       "      <td>gray</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name  count  source  cumulative\n",
       "0  CASIA-WebFace    158  orange    0.208995\n",
       "1       VGGFace2    129  orange    0.379630\n",
       "2    MS-Celeb-1M    109  orange    0.523810\n",
       "3       MegaFace    108  orange    0.666667\n",
       "4          IJB-A    108  orange    0.809524\n",
       "5         CelebA     75    blue    0.908730\n",
       "6          Other     50    gray    0.974868\n",
       "7          Other     19    gray    1.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df['cumulative']=dataset_df.sort_values('count',ascending=False)['count'].cumsum()/dataset_df.sort_values('count',ascending=False)['count'].sum()\n",
    "#tasks_df.set_index('task').plot.pie(y='count')\n",
    "other_count=dataset_df[dataset_df['cumulative']>.99]['count'].sum()\n",
    "dataset_df=dataset_df[dataset_df['cumulative']<.99]\n",
    "dataset_df=dataset_df.append({'name':'Other','count':other_count,'cumulative':1,'source':'gray'},ignore_index=True)\n",
    "dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f378afb9-5ccf-4896-91fe-0323b6b788c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "labels": [
          "Face Recognition",
          "Face Detection",
          "Other"
         ],
         "marker": {
          "colors": [
           "rgb(228,26,28)",
           "rgb(55,126,184)",
           "rgb(77,175,74)",
           "rgb(152,78,163)",
           "rgb(255,127,0)",
           "rgb(255,255,51)",
           "rgb(166,86,40)",
           "rgb(247,129,191)",
           "rgb(153,153,153)"
          ],
          "line": {
           "color": "#000000",
           "width": 1
          }
         },
         "pull": [
          0,
          0,
          0,
          0.2,
          0,
          0,
          0
         ],
         "textfont": {
          "color": "black"
         },
         "type": "pie",
         "values": [
          618,
          94,
          44
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "font": {
         "color": "black",
         "family": "Arial"
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "family": "Arial"
         }
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>                            <div id=\"6d47029f-5610-4c87-94b5-5e1da02bbbeb\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6d47029f-5610-4c87-94b5-5e1da02bbbeb\")) {                    Plotly.newPlot(                        \"6d47029f-5610-4c87-94b5-5e1da02bbbeb\",                        [{\"labels\":[\"Face Recognition\",\"Face Detection\",\"Other\"],\"marker\":{\"colors\":[\"rgb(228,26,28)\",\"rgb(55,126,184)\",\"rgb(77,175,74)\",\"rgb(152,78,163)\",\"rgb(255,127,0)\",\"rgb(255,255,51)\",\"rgb(166,86,40)\",\"rgb(247,129,191)\",\"rgb(153,153,153)\"],\"line\":{\"color\":\"#000000\",\"width\":1}},\"pull\":[0,0,0,0.2,0,0,0],\"textfont\":{\"color\":\"black\"},\"type\":\"pie\",\"values\":[618,94,44]}],                        {\"font\":{\"color\":\"black\",\"family\":\"Arial\"},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"font\":{\"family\":\"Arial\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('6d47029f-5610-4c87-94b5-5e1da02bbbeb');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "labels": [
          "CASIA-WebFace",
          "VGGFace2",
          "MS-Celeb-1M",
          "MegaFace",
          "IJB-A",
          "CelebA",
          "Other",
          "Other"
         ],
         "marker": {
          "colors": [
           "rgb(228,26,28)",
           "rgb(55,126,184)",
           "rgb(77,175,74)",
           "rgb(152,78,163)",
           "rgb(255,127,0)",
           "rgb(255,255,51)",
           "rgb(166,86,40)",
           "rgb(247,129,191)",
           "rgb(153,153,153)"
          ],
          "line": {
           "color": "#000000",
           "width": 1
          }
         },
         "pull": [
          0,
          0,
          0,
          0.2,
          0,
          0,
          0
         ],
         "textfont": {
          "color": "black"
         },
         "type": "pie",
         "values": [
          158,
          129,
          109,
          108,
          108,
          75,
          50,
          19
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "font": {
         "color": "black",
         "family": "Arial"
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "family": "Arial"
         }
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>                            <div id=\"798e660d-9926-41ce-9be4-8dbf7589358c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"798e660d-9926-41ce-9be4-8dbf7589358c\")) {                    Plotly.newPlot(                        \"798e660d-9926-41ce-9be4-8dbf7589358c\",                        [{\"labels\":[\"CASIA-WebFace\",\"VGGFace2\",\"MS-Celeb-1M\",\"MegaFace\",\"IJB-A\",\"CelebA\",\"Other\",\"Other\"],\"marker\":{\"colors\":[\"rgb(228,26,28)\",\"rgb(55,126,184)\",\"rgb(77,175,74)\",\"rgb(152,78,163)\",\"rgb(255,127,0)\",\"rgb(255,255,51)\",\"rgb(166,86,40)\",\"rgb(247,129,191)\",\"rgb(153,153,153)\"],\"line\":{\"color\":\"#000000\",\"width\":1}},\"pull\":[0,0,0,0.2,0,0,0],\"textfont\":{\"color\":\"black\"},\"type\":\"pie\",\"values\":[158,129,109,108,108,75,50,19]}],                        {\"font\":{\"color\":\"black\",\"family\":\"Arial\"},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"font\":{\"family\":\"Arial\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('798e660d-9926-41ce-9be4-8dbf7589358c');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[go.Pie(labels=tasks_df['task'], \n",
    "                             values=tasks_df['count'],\n",
    "                            pull=[0, 0, 0, 0.2,0,0,0])])\n",
    "fig.update_layout(\n",
    "    font_family=\"Arial\",\n",
    "    title_font_family=\"Arial\",\n",
    "    font_color='black',\n",
    ")\n",
    "fig.update_traces(marker=dict(colors=px.colors.qualitative.Set1,line=dict(color='#000000', width=1)),textfont_color='black')\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure(data=[go.Pie(labels=dataset_df['name'], \n",
    "                             values=dataset_df['count'],\n",
    "                            pull=[0, 0, 0, 0.2,0,0,0])])\n",
    "fig.update_layout(\n",
    "    font_family=\"Arial\",\n",
    "    title_font_family=\"Arial\",\n",
    "    font_color='black',\n",
    ")\n",
    "fig.update_traces(marker=dict(colors=px.colors.qualitative.Set1,line=dict(color='#000000', width=1)),textfont_color='black')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a470ae8-5e7f-45ed-bb1a-fbb61ac5457a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_task</th>\n",
       "      <th>dest_task</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>Images</th>\n",
       "      <th>Texts</th>\n",
       "      <th>Parent_Transfer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3892</th>\n",
       "      <td>Object Recognition</td>\n",
       "      <td>Face Recognition</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>Physical Attribute Prediction Using Deep Resid...</td>\n",
       "      <td>2018-12-19</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3895</th>\n",
       "      <td>Image Classification</td>\n",
       "      <td>Face Recognition</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>Physical Attribute Prediction Using Deep Resid...</td>\n",
       "      <td>2018-12-19</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3898</th>\n",
       "      <td>Object Localization</td>\n",
       "      <td>Face Recognition</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>Physical Attribute Prediction Using Deep Resid...</td>\n",
       "      <td>2018-12-19</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>Object Recognition</td>\n",
       "      <td>Face Recognition</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>FaceGuard: A Self-Supervised Defense Against A...</td>\n",
       "      <td>2020-11-28</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>Image Classification</td>\n",
       "      <td>Face Recognition</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>FaceGuard: A Self-Supervised Defense Against A...</td>\n",
       "      <td>2020-11-28</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23021</th>\n",
       "      <td>Image Classification</td>\n",
       "      <td>Face Recognition</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>RepMLP: Re-parameterizing Convolutions into Fu...</td>\n",
       "      <td>2021-05-05</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23023</th>\n",
       "      <td>Object Localization</td>\n",
       "      <td>Face Recognition</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>RepMLP: Re-parameterizing Convolutions into Fu...</td>\n",
       "      <td>2021-05-05</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24193</th>\n",
       "      <td>Object Recognition</td>\n",
       "      <td>Face Recognition</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>Quality-Agnostic Image Recognition via Inverti...</td>\n",
       "      <td>2021-06-19</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24195</th>\n",
       "      <td>Image Classification</td>\n",
       "      <td>Face Recognition</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>Quality-Agnostic Image Recognition via Inverti...</td>\n",
       "      <td>2021-06-19</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24197</th>\n",
       "      <td>Object Localization</td>\n",
       "      <td>Face Recognition</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>Quality-Agnostic Image Recognition via Inverti...</td>\n",
       "      <td>2021-06-19</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                source_task         dest_task      name  \\\n",
       "3892     Object Recognition  Face Recognition  ImageNet   \n",
       "3895   Image Classification  Face Recognition  ImageNet   \n",
       "3898    Object Localization  Face Recognition  ImageNet   \n",
       "3998     Object Recognition  Face Recognition  ImageNet   \n",
       "4001   Image Classification  Face Recognition  ImageNet   \n",
       "...                     ...               ...       ...   \n",
       "23021  Image Classification  Face Recognition  ImageNet   \n",
       "23023   Object Localization  Face Recognition  ImageNet   \n",
       "24193    Object Recognition  Face Recognition  ImageNet   \n",
       "24195  Image Classification  Face Recognition  ImageNet   \n",
       "24197   Object Localization  Face Recognition  ImageNet   \n",
       "\n",
       "                                                   title       date  Images  \\\n",
       "3892   Physical Attribute Prediction Using Deep Resid... 2018-12-19    True   \n",
       "3895   Physical Attribute Prediction Using Deep Resid... 2018-12-19    True   \n",
       "3898   Physical Attribute Prediction Using Deep Resid... 2018-12-19    True   \n",
       "3998   FaceGuard: A Self-Supervised Defense Against A... 2020-11-28    True   \n",
       "4001   FaceGuard: A Self-Supervised Defense Against A... 2020-11-28    True   \n",
       "...                                                  ...        ...     ...   \n",
       "23021  RepMLP: Re-parameterizing Convolutions into Fu... 2021-05-05    True   \n",
       "23023  RepMLP: Re-parameterizing Convolutions into Fu... 2021-05-05    True   \n",
       "24193  Quality-Agnostic Image Recognition via Inverti... 2021-06-19    True   \n",
       "24195  Quality-Agnostic Image Recognition via Inverti... 2021-06-19    True   \n",
       "24197  Quality-Agnostic Image Recognition via Inverti... 2021-06-19    True   \n",
       "\n",
       "       Texts  Parent_Transfer  \n",
       "3892   False            False  \n",
       "3895   False            False  \n",
       "3898   False            False  \n",
       "3998   False            False  \n",
       "4001   False            False  \n",
       "...      ...              ...  \n",
       "23021  False            False  \n",
       "23023  False            False  \n",
       "24193  False            False  \n",
       "24195  False            False  \n",
       "24197  False            False  \n",
       "\n",
       "[96 rows x 8 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_dest_edgelist_parents[(source_dest_edgelist_parents.dest_task=='Face Recognition')&(source_dest_edgelist_parents.name=='ImageNet')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10de947-a474-45d1-9c03-e76efc609815",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[go.Pie(labels=['Oxygen','Hydrogen','Carbon_Dioxide','Nitrogen'],\n",
    "                             values=[4500,2500,1053,500])])\n",
    "fig.update_traces(hoverinfo='label+percent', textinfo='value', textfont_size=20,\n",
    "                  marker=dict(colors=colors, line=dict(color='#000000', width=2)))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "7278f376-6238-4a6b-86eb-575529d53079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>year</th>\n",
       "      <th>num_dataset_births</th>\n",
       "      <th>num_papers_adopting</th>\n",
       "      <th>num_dataset_imports</th>\n",
       "      <th>num_papers_growing</th>\n",
       "      <th>size</th>\n",
       "      <th>task_age</th>\n",
       "      <th>adoption_ratio</th>\n",
       "      <th>creation_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>adoption_pct</th>\n",
       "      <th>creation_pct</th>\n",
       "      <th>conversion_pct</th>\n",
       "      <th>cvmethods</th>\n",
       "      <th>Images</th>\n",
       "      <th>Texts</th>\n",
       "      <th>pwc_size</th>\n",
       "      <th>CV</th>\n",
       "      <th>NLP</th>\n",
       "      <th>Methodology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3440</th>\n",
       "      <td>Object Detection</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12110</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  task  year  num_dataset_births  num_papers_adopting  \\\n",
       "3440  Object Detection  2015                 0.0                148.0   \n",
       "\n",
       "      num_dataset_imports  num_papers_growing   size  task_age  \\\n",
       "3440                  0.0                 1.0  149.0    2007.0   \n",
       "\n",
       "      adoption_ratio  creation_ratio  ...  adoption_pct  creation_pct  \\\n",
       "3440           148.0             NaN  ...      0.993289           NaN   \n",
       "\n",
       "      conversion_pct  cvmethods  Images  Texts  pwc_size  CV  NLP  Methodology  \n",
       "3440             0.0      False       1      1     12110   1    0            0  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pwc_papers2=pwc_papers.copy()\n",
    "#pwc_papers2['year']=pwc_papers2['year'].apply(lambda x: x if x % 2==0 else x-1)\n",
    "pwc_papers2.year.unique()\n",
    "\n",
    "annual_data2[(annual_data2.task=='Object Detection') &(annual_data2.year==2014)]\n",
    "annual_data2[(annual_data2.task=='Object Detection') &(annual_data2.year==2015)]\n",
    "\n",
    "annual_data[(annual_data.task=='Object Detection') &(annual_data.year==2014)]\n",
    "annual_data[(annual_data.task=='Object Detection') &(annual_data.year==2015)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4887636d-0e97-4f0e-9a1c-5ac455d19897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skbio.diversity import alpha\n",
    "dataset_name=[]\n",
    "paper_title=[]\n",
    "paper_date=[]\n",
    "paper_tasks=[]\n",
    "paper_CV=[]\n",
    "paper_NLP=[]\n",
    "paper_Methods=[]\n",
    "paper_parent=[]\n",
    "def in_category(x,cat):\n",
    "    if x in task_category_dict and cat in task_category_dict[x]:\n",
    "        return 1\n",
    "    if x in parent_child_dict and any([cat in task_category_dict[p] for p in child_parent_dict[x]]):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "for i, row in dataset_citing_papers_pwc.drop_duplicates(['name','title']).iterrows():\n",
    "    if row['name']=='PRID2011':continue\n",
    "    valid_tasks= set(datasets[datasets.name==row['name']]['dataset_tasks'].iloc[0]+\\\n",
    "                     datasets[datasets.name==row['name']]['dataset_tasks_children'].iloc[0]+\\\n",
    "                     datasets[datasets.name==row['name']]['dataset_tasks_siblings'].iloc[0]\n",
    "                    )\n",
    "    for t in row['all_tasks']:\n",
    "        if t not in valid_tasks: continue \n",
    "        #if t not in focal_tasks:continue\n",
    "        dataset_name.append(row['name'])\n",
    "        paper_title.append(row['title'])\n",
    "        paper_date.append(row['date'].year)\n",
    "        paper_tasks.append(t)\n",
    "        paper_parent.append(False)\n",
    "    for t in row['all_parents']:\n",
    "        if t not in valid_tasks: continue\n",
    "        #if t not in focal_tasks:continue\n",
    "        dataset_name.append(row['name'])\n",
    "        paper_title.append(row['title'])\n",
    "        paper_date.append(row['date'].year)\n",
    "        paper_tasks.append(t)\n",
    "        paper_parent.append(True)\n",
    "entropy_dataset=pd.DataFrame({'task':paper_tasks,'name':dataset_name,'title':paper_title,'date':paper_date}).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fda5e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from skbio.diversity import alpha\n",
    "from math import log\n",
    "#right now I am just saying having 1 or 0 datasets is meaningless\n",
    "def gini(x):\n",
    "    if len(x)<2:return None\n",
    "    x=np.array(x)\n",
    "    \"\"\"Compute Gini coefficient of array of values\"\"\"\n",
    "    diffsum = 0\n",
    "    for i, xi in enumerate(x[:-1], 1):\n",
    "        diffsum += np.sum(np.abs(xi - x[i:]))\n",
    "    return diffsum / (len(x)**2 * np.mean(x))\n",
    "\n",
    "def corrected_gini(x):\n",
    "    if len(x)<2:return None\n",
    "    x=np.array(x)\n",
    "    \"\"\"Compute Gini coefficient of array of values\"\"\"\n",
    "    diffsum = 0\n",
    "    for i, xi in enumerate(x[:-1], 1):\n",
    "        diffsum += np.sum(np.abs(xi - x[i:]))\n",
    "    gini = diffsum / (len(x)**2 * np.mean(x))\n",
    "    return len(x)*gini/(len(x)-1) \n",
    "\n",
    "\n",
    "def pielou(x):\n",
    "    if len(x)<2:return None\n",
    "    x=np.array(x)\n",
    "    return entropy(x,base=2)/log(len(x),2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70fe2280",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_ds_ycounts=entropy_dataset.groupby(['task','name',entropy_dataset.date]).size().reset_index()\n",
    "task_ds_ycounts.columns=['task', 'name','year','count']\n",
    "ginis=task_ds_ycounts.groupby(['task','year'])['count'].agg(corrected_gini).reset_index()\n",
    "ginis.columns=['task','year','gini']\n",
    "pielous=task_ds_ycounts.groupby(['task','year'])['count'].agg(pielou).reset_index()\n",
    "pielous.columns=['task','year','pielou']\n",
    "simpson=task_ds_ycounts.groupby(['task','year'])['count'].agg(alpha.simpson_e).reset_index()\n",
    "simpson.columns=['task','year','simpson']\n",
    "size=task_ds_ycounts.groupby(['task','year'])['count'].sum().reset_index()\n",
    "size.columns=['task','year','task_size']\n",
    "inequity_years_df=pd.merge(ginis,pielous,on=['task','year'])\n",
    "inequity_years_df=pd.merge(inequity_years_df,simpson,on=['task','year'],how='left')\n",
    "inequity_years_df=pd.merge(inequity_years_df,size,on=['task','year'],how='left')\n",
    "inequity_years_df=pd.merge(inequity_years_df,\n",
    "                           annual_data[['task','year','task_age','pwc_size','Images','Texts','cvmethods','CV','NLP','Methodology']],\n",
    "                           on=['task','year'], how='left')\n",
    "inequity_years_df['CV']=inequity_years_df['task'].apply(lambda x: in_category(x,'Computer Vision'))\n",
    "inequity_years_df['NLP']=inequity_years_df['task'].apply(lambda x: in_category(x,'Natural Language Processing'))\n",
    "inequity_years_df['Methodology']=inequity_years_df['task'].apply(lambda x: in_category(x,'Methodology'))\n",
    "inequity_years_df['Methodology']=inequity_years_df['Methodology'].apply(lambda x: 0 if x in Methodologies_to_Drop else x)\n",
    "inequity_years_df.to_csv(\"/mnt/c/Users/berna/Documents/GoogleDataProject/EntropyInputs/EntropyDatasetforR.txt\",sep='\\t',quoting=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6b8fdd0-8ae3-4fd1-b0b4-8ad26db10b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1           2D Object Detection\n",
       "5        3D Face Reconstruction\n",
       "7      3D Human Pose Estimation\n",
       "9           3D Object Detection\n",
       "10            3D Reconstruction\n",
       "                 ...           \n",
       "249           Image Compression\n",
       "250            Image Inpainting\n",
       "260      Small Object Detection\n",
       "266            Video Generation\n",
       "268    Visual Place Recognition\n",
       "Name: task, Length: 133, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_parent_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3dc1d43-11cf-4aef-9e35-5e1dbe2a24ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     task  year     count\n",
      "0     2D Object Detection  2011       NaN\n",
      "1     2D Object Detection  2012       NaN\n",
      "2     2D Object Detection  2014  0.666667\n",
      "3     2D Object Detection  2015  0.741935\n",
      "4     2D Object Detection  2016  0.789757\n",
      "...                   ...   ...       ...\n",
      "1079   Zero-Shot Learning  2017  0.516129\n",
      "1080   Zero-Shot Learning  2018  0.727660\n",
      "1081   Zero-Shot Learning  2019  0.740260\n",
      "1082   Zero-Shot Learning  2020  0.753472\n",
      "1083   Zero-Shot Learning  2021  0.728571\n",
      "\n",
      "[1084 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "parent_tasks=[i for i in parent_child_dict if len(parent_child_dict[i])!=0]\n",
    "task_ds_ycounts=entropy_dataset.groupby(['task','name',entropy_dataset.date]).size().reset_index()\n",
    "task_ds_ycounts= task_ds_ycounts[task_ds_ycounts.task.isin(median_parent_tasks)]\n",
    "#task_ds_ycounts= task_ds_ycounts[task_ds_ycounts.task.isin(parent_tasks)]\n",
    "\n",
    "task_ds_ycounts.columns=['task', 'name','year','count']\n",
    "ginis=task_ds_ycounts.groupby(['task','year'])['count'].agg(corrected_gini).reset_index()\n",
    "print(ginis)\n",
    "ginis.columns=['task','year','gini']\n",
    "pielous=task_ds_ycounts.groupby(['task','year'])['count'].agg(pielou).reset_index()\n",
    "pielous.columns=['task','year','pielou']\n",
    "simpson=task_ds_ycounts.groupby(['task','year'])['count'].agg(alpha.simpson_e).reset_index()\n",
    "simpson.columns=['task','year','simpson']\n",
    "size=task_ds_ycounts.groupby(['task','year'])['count'].sum().reset_index()\n",
    "size.columns=['task','year','task_size']\n",
    "inequity_years_df=pd.merge(ginis,pielous,on=['task','year'])\n",
    "inequity_years_df=pd.merge(inequity_years_df,simpson,on=['task','year'],how='left')\n",
    "inequity_years_df=pd.merge(inequity_years_df,size,on=['task','year'],how='left')\n",
    "task_age_df=task_age.reset_index()\n",
    "task_age_df.columns=['task','task_age']\n",
    "inequity_years_df=pd.merge(inequity_years_df,task_age_df,on='task',how='left')\n",
    "pwc_papers['year']=pd.to_datetime(pwc_papers['date']).dt.year\n",
    "annual_size=pwc_papers.groupby('year').size().reset_index()\n",
    "annual_size.columns=['year','pwc_size']\n",
    "inequity_years_df=pd.merge(inequity_years_df,annual_size,on='year',how='left')\n",
    "inequity_years_df['CV']=inequity_years_df['task'].apply(lambda x: in_category(x,'Computer Vision'))\n",
    "inequity_years_df['NLP']=inequity_years_df['task'].apply(lambda x: in_category(x,'Natural Language Processing'))\n",
    "inequity_years_df['Methodology']=inequity_years_df['task'].apply(lambda x: in_category(x,'Methodology'))\n",
    "inequity_years_df['Methodology']=inequity_years_df['Methodology'].apply(lambda x: 0 if x in Methodologies_to_Drop else x)\n",
    "inequity_years_df.to_csv(\"/mnt/c/Users/berna/Documents/GoogleDataProject/EntropyInputs/EntropyDatasetforRParentsOnly.txt\",sep='\\t',quoting=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c84b9e97-5571-4069-a074-73c825bd7d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parent_tasks=[i for i in parent_child_dict if len(parent_child_dict[i])!=0]\n",
    "task_ds_counts=entropy_dataset.groupby(['task','name']).size().reset_index()\n",
    "task_ds_counts= task_ds_counts[task_ds_counts.task.isin(median_parent_tasks)]\n",
    "task_ds_counts.columns=['task', 'name','count']\n",
    "ginis=task_ds_counts.groupby(['task'])['count'].agg(corrected_gini).reset_index()\n",
    "ginis.columns=['task','gini']\n",
    "pielous=task_ds_counts.groupby(['task'])['count'].agg(pielou).reset_index()\n",
    "pielous.columns=['task','pielou']\n",
    "simpson=task_ds_counts.groupby(['task'])['count'].agg(alpha.simpson_e).reset_index()\n",
    "simpson.columns=['task','simpson']\n",
    "size=task_ds_counts.groupby(['task'])['count'].sum().reset_index()\n",
    "size.columns=['task','task_size']\n",
    "inequity_df=pd.merge(ginis,pielous,on=['task'])\n",
    "inequity_df=pd.merge(inequity_df,simpson,on=['task'],how='left')\n",
    "inequity_df=pd.merge(inequity_df,size,on=['task'],how='left')\n",
    "inequity_df['CV']=inequity_df['task'].apply(lambda x: in_category(x,'Computer Vision'))\n",
    "inequity_df['NLP']=inequity_df['task'].apply(lambda x: in_category(x,'Natural Language Processing'))\n",
    "inequity_df['Methodology']=inequity_df['task'].apply(lambda x: in_category(x,'Methodology'))\n",
    "inequity_df.to_csv(\"/mnt/c/Users/berna/Documents/GoogleDataProject/EntropyInputs/EntropyDatasetforRParentsOnly.AllYears.txt\",sep='\\t',quoting=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "e5a0afb9-0cd3-4bf6-90e9-d56d09a6ed04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>gini</th>\n",
       "      <th>pielou</th>\n",
       "      <th>simpson</th>\n",
       "      <th>task_size</th>\n",
       "      <th>CV</th>\n",
       "      <th>NLP</th>\n",
       "      <th>Methodology</th>\n",
       "      <th>cvmethods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D Human Pose Estimation</td>\n",
       "      <td>0.729564</td>\n",
       "      <td>0.717602</td>\n",
       "      <td>0.244357</td>\n",
       "      <td>572</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3D Reconstruction</td>\n",
       "      <td>0.798951</td>\n",
       "      <td>0.508718</td>\n",
       "      <td>0.109737</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abstractive Text Summarization</td>\n",
       "      <td>0.713778</td>\n",
       "      <td>0.666146</td>\n",
       "      <td>0.115863</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Action Classification</td>\n",
       "      <td>0.742728</td>\n",
       "      <td>0.655283</td>\n",
       "      <td>0.215259</td>\n",
       "      <td>273</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Action Detection</td>\n",
       "      <td>0.760732</td>\n",
       "      <td>0.644857</td>\n",
       "      <td>0.251102</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Visual Relationship Detection</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.162326</td>\n",
       "      <td>0.524376</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Visual Tracking</td>\n",
       "      <td>0.710470</td>\n",
       "      <td>0.679660</td>\n",
       "      <td>0.367190</td>\n",
       "      <td>422</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Word Embeddings</td>\n",
       "      <td>0.700752</td>\n",
       "      <td>0.705129</td>\n",
       "      <td>0.160159</td>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Word Sense Disambiguation</td>\n",
       "      <td>0.686333</td>\n",
       "      <td>0.700433</td>\n",
       "      <td>0.289784</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Zero-Shot Learning</td>\n",
       "      <td>0.844504</td>\n",
       "      <td>0.487425</td>\n",
       "      <td>0.205516</td>\n",
       "      <td>373</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               task      gini    pielou   simpson  task_size  \\\n",
       "0          3D Human Pose Estimation  0.729564  0.717602  0.244357        572   \n",
       "1                 3D Reconstruction  0.798951  0.508718  0.109737        156   \n",
       "2    Abstractive Text Summarization  0.713778  0.666146  0.115863        225   \n",
       "3             Action Classification  0.742728  0.655283  0.215259        273   \n",
       "4                  Action Detection  0.760732  0.644857  0.251102        198   \n",
       "..                              ...       ...       ...       ...        ...   \n",
       "151   Visual Relationship Detection  0.952381  0.162326  0.524376         42   \n",
       "152                 Visual Tracking  0.710470  0.679660  0.367190        422   \n",
       "153                 Word Embeddings  0.700752  0.705129  0.160159        194   \n",
       "154       Word Sense Disambiguation  0.686333  0.700433  0.289784        103   \n",
       "155              Zero-Shot Learning  0.844504  0.487425  0.205516        373   \n",
       "\n",
       "     CV  NLP  Methodology  cvmethods  \n",
       "0     1    0            0          0  \n",
       "1     1    0            0          0  \n",
       "2     0    1            0          0  \n",
       "3     1    0            0          0  \n",
       "4     1    0            0          0  \n",
       "..   ..  ...          ...        ...  \n",
       "151   1    0            0          0  \n",
       "152   1    0            0          0  \n",
       "153   0    0            1          0  \n",
       "154   0    1            0          0  \n",
       "155   1    0            1          1  \n",
       "\n",
       "[156 rows x 9 columns]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inequity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb33f0aa-bdc0-4a81-aa43-e58598928f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_ds_ycounts[(task_ds_ycounts.year==2015) & (task_ds_ycounts.task=='3D Human Pose Estimation')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
