{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5af1aaed-9b9a-4ea3-b52e-f2ea71345db1",
   "metadata": {},
   "source": [
    "# Dataset Construction: RQ1 and RQ2\n",
    "\n",
    "This notebook constructs the datasets used in the analyses for research questions 1 and 2. To see the actual statistical analyses, see the R scripts.\n",
    "\n",
    "First load the PWC provided data. \"evaluation-tables.json\" and \"papers-with-abstracts.json\" were downloaded from [PWC's Github](https://github.com/paperswithcode/paperswithcode-data) on 06/16/2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096cd869",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH=\"/home/bkoch/Documents/GitHub/Life_of_a_Benchmark/Dataset_Curation\"\n",
    "%cd DATASET_PATH\n",
    "import pandas as pd\n",
    "import json\n",
    "with open('./PWC_Data/papers-with-abstracts.json') as f:\n",
    "    pwc=json.load(f)\n",
    "with open('./PWC_Data/evaluation-tables.json') as f:\n",
    "    benchmark_tables=json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dba6cb7-1125-481b-8205-a1178e8e9ea1",
   "metadata": {},
   "source": [
    "### Construct Task Ontology\n",
    "\n",
    "This block parses \"evaluation-tables.json\" to create a task ontology. Benchmarks in this file are organized by task and subtask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5118e98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rows=[] #used to construct benchmark_papers df\n",
    "parent_child_dict={} #dictionary capturing parent-child task relations used to create task_relations df\n",
    "child_parent_dict={} #inverse of above\n",
    "task_category_dict={} #captures task category relations: categories in PWC are larger domains like \"NLP\",\"CV\",\"Methodology\n",
    "paper_titles_tasks={} #paper titles to tasks\n",
    "paper_titles_parent_tasks={} #paper totiles to parent tasks\n",
    "dataset_associated_tasks={} # tasks associated with the dataset\n",
    "\n",
    "for i, task in enumerate(benchmark_tables):\n",
    "    task_dict={} # A dictionary for each task that will ultimately be a row in the benchmark_papers dataframe\n",
    "    task_dict['task']=task['task']\n",
    "    task_dict['task_categories']=task['categories']\n",
    "    task_dict['task_description']=task['description']\n",
    "    task_dict['parent_task']=task['task']\n",
    "    if task['task'] not in parent_child_dict: parent_child_dict[task['task']]=[]\n",
    "    if task['task'] not in child_parent_dict: child_parent_dict[task['task']]=[]\n",
    "    task_category_dict[task['task']]=task['categories']\n",
    "    if len(task['datasets'])!=0: #if there are datasets associated with task\n",
    "        for j,d in enumerate(task['datasets']):\n",
    "            if d['dataset'] not in dataset_associated_tasks:dataset_associated_tasks[d['dataset']]=[]\n",
    "            parent_dataset=d['dataset'] # variations of datasets can be listed as \"children\"\n",
    "            dataset_associated_tasks[d['dataset']].append(task['task'])\n",
    "            dataset_dict={}\n",
    "            dataset_dict.update(task_dict)\n",
    "            dataset_dict['dataset']=d['dataset']\n",
    "            dataset_dict['dataset_citations']=d['dataset_citations']\n",
    "            dataset_dict['dataset_links']=d['dataset_links']\n",
    "            dataset_dict['dataset_subdatasets']=d['subdatasets']\n",
    "            dataset_dict['task']=task['task']\n",
    "            for row in d['sota']['rows']:\n",
    "                for m in row['metrics']:\n",
    "                    row_dict=dict(row)\n",
    "                    row_dict['metrics']=m\n",
    "                    row_dict['score']=row['metrics'][m]\n",
    "                    row_dict.update(dataset_dict)\n",
    "                    all_rows.append(row_dict)\n",
    "                if row['paper_title'] not in paper_titles_tasks:paper_titles_tasks[row['paper_title']]=[]\n",
    "                if row['paper_title'] not in paper_titles_parent_tasks:paper_titles_parent_tasks[row['paper_title']]=[]\n",
    "                paper_titles_tasks[row['paper_title']]+=[task['task']]\n",
    "                paper_titles_parent_tasks[row['paper_title']]+=[task['task']]\n",
    "    if len(task['subtasks'])!=0: #tasks can have subtasks. This is not tree. A subtask could have multiple parents or be a parent itself.\n",
    "        for t in task['subtasks']:\n",
    "            task_dict={} #Each subtask is it's own row also\n",
    "            if t['task'] not in child_parent_dict: child_parent_dict[t['task']]=[]\n",
    "            if t['task'] not in parent_child_dict: parent_child_dict[t['task']]=[]\n",
    "            task_category_dict[t['task']]=t['categories']\n",
    "            parent_child_dict[task['task']].append(t['task'])\n",
    "            child_parent_dict[t['task']].append(task['task'])\n",
    "            \n",
    "            task_dict['parent_task']=task['task']\n",
    "            task_dict['task']=t['task']\n",
    "            task_dict['task_categories']=','.join(t['categories'])\n",
    "            task_dict['task_description']=t['description']\n",
    "            \n",
    "            if len(t['datasets'])!=0:\n",
    "                for d in t['datasets']:\n",
    "                    if d['dataset'] not in dataset_associated_tasks:dataset_associated_tasks[d['dataset']]=[]\n",
    "                    dataset_associated_tasks[d['dataset']].append(t['task'])\n",
    "                    dataset_associated_tasks[parent_dataset].append(t['task'])\n",
    "                    dataset_dict={}\n",
    "                    dataset_dict.update(task_dict)\n",
    "                    dataset_dict['dataset']=d['dataset']\n",
    "                    dataset_dict['dataset_citations']=d['dataset_citations']\n",
    "                    dataset_dict['dataset_links']=d['dataset_links']\n",
    "                    dataset_dict['dataset_subdatasets']=d['subdatasets']\n",
    "                    dataset_dict['task']=t['task']\n",
    "                    for row in d['sota']['rows']:\n",
    "                        for m in row['metrics']:\n",
    "                            row_dict=dict(row)\n",
    "                            row_dict['metrics']=m\n",
    "                            row_dict['score']=row['metrics'][m]\n",
    "                            row_dict.update(dataset_dict)\n",
    "                            all_rows.append(row_dict)\n",
    "                        if row['paper_title'] not in paper_titles_tasks:paper_titles_tasks[row['paper_title']]=[]\n",
    "                        paper_titles_tasks[row['paper_title']]+=[t['task']] \n",
    "                        if row['paper_title'] not in paper_titles_parent_tasks:paper_titles_parent_tasks[row['paper_title']]=[]\n",
    "                        paper_titles_parent_tasks[row['paper_title']]+=[task['task']] \n",
    "\n",
    "#contains all relevant info at papers used in benchmarks\n",
    "benchmark_papers=pd.DataFrame(all_rows)\n",
    "benchmark_papers=benchmark_papers.drop_duplicates(['model_name','dataset','task','metrics','score'])\n",
    "benchmark_papers['benchmark_id']=benchmark_papers.groupby(['task','dataset','metrics']).ngroup()\n",
    "benchmark_papers=benchmark_papers[['paper_title','paper_date','task','parent_task','dataset','score','benchmark_id','metrics','task_categories']]\n",
    "benchmark_papers=benchmark_papers.drop_duplicates(['paper_title','paper_date','task','parent_task','dataset','score','benchmark_id','metrics'])\n",
    "benchmark_papers['CV']=benchmark_papers.apply(lambda row: 'Computer Vision' in row['task_categories'] and len(row['task_categories'])==1,axis=1 )\n",
    "benchmark_papers['NLP']=benchmark_papers.apply(lambda row: 'Natural Language Processing' in row['task_categories'] and len(row['task_categories'])==1,axis=1 )\n",
    "print(benchmark_papers.shape)\n",
    "\n",
    "#constructs sibling relationships from all tasks,\n",
    "#Note that because it is not a tree, sibling relations do not correspond exactly to parent child\n",
    "sibling_dict={i:[] for i in child_parent_dict.keys()}\n",
    "for k in sibling_dict.keys():\n",
    "    parents=child_parent_dict[k]\n",
    "    for i in parents:\n",
    "        sibling_dict[k]+=parent_child_dict[i]\n",
    "    sibling_dict[k]=list(set(sibling_dict[k]))\n",
    "\n",
    "# Create the ontology of task relations\n",
    "task_relations=pd.DataFrame({'categories':task_category_dict,'parents':child_parent_dict,'children':parent_child_dict,'siblings':sibling_dict})\n",
    "task_relations.index=task_relations.index.rename('task')\n",
    "task_relations=task_relations.reset_index()\n",
    "\n",
    "#Create a df labeling papers with tasks and parent tasks\n",
    "paper_relations=pd.DataFrame({'all_tasks':paper_titles_tasks,'all_parent_tasks':paper_titles_parent_tasks})\n",
    "paper_relations.index=paper_relations.index.rename('title')\n",
    "paper_relations=paper_relations.reset_index()\n",
    "task_relations.to_csv('task_relations.tsv',sep='\\t',quoting=1)\n",
    "\n",
    "print(\"Number of papers used to construct task ontology: \",benchmark_papers['paper_title'].drop_duplicates().shape)\n",
    "print(\"Number of tasks: \", task_relations.shape[0])\n",
    "print(\"Mean number of parents/children for a task: \", task_relations['parents'].apply(lambda x: len(x)).mean())\n",
    "print(\"Mean number of siblings for a task: \", task_relations['siblings'].apply(lambda x: len(x)).mean())\n",
    "#At least in the benchmark relations, it appears that PWC does have a tree like structure\n",
    "\n",
    "benchmark_papers.to_json('./PWC_Data/Derivative_Datasets/benchmarks_with_datasets.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702d3947-fc01-4067-b668-3b0ada681327",
   "metadata": {},
   "source": [
    "This block goes through papers with abstracts, constructs a DF with unique task-papers (not unique papers) and annotates task relations from previous block.\n",
    "\n",
    "Furthermore, we add our additional manual annotations for papers that introduced datasets and were either not in papers-with-abstracts.json or had no tasks labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbb0f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are all columns in the df for each paper\n",
    "title=[]\n",
    "pdf_url=[]\n",
    "paper_url=[]\n",
    "date=[]\n",
    "task=[]\n",
    "all_tasks=[]\n",
    "all_parents=[]\n",
    "all_children=[]\n",
    "all_categories=[]\n",
    "all_siblings=[]\n",
    "\n",
    "#These are used later but they note the number of papers per task and the first appearance of a paper with a task\n",
    "task_hist={}\n",
    "task_age={}\n",
    "\n",
    "\n",
    "#These are the datset-introducing papers that two authors manually annotated.\n",
    "#Note that only papers with the \"Justification\" column are those we both reviewed. \n",
    "sheet_id = '1Y3DDI6ySi9A6l3ZMET29EWSxBr8Uw-kvKn8RF2zYpzQ'\n",
    "sheet_name = 'untasked_datasets'\n",
    "url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
    "manual_task_labels=pd.read_csv(url)\n",
    "manual_tasks_not_labeled=manual_task_labels[manual_task_labels.Justification.isnull()]\n",
    "manual_task_labels=manual_task_labels[~manual_task_labels.Justification.isnull()]\n",
    "print(\"Number of manually annotated dataset-introducing papers: \",manual_task_labels.shape[0])\n",
    "\n",
    "for i in pwc:\n",
    "    if i['title'] in list(manual_task_labels.title.str.strip()):\n",
    "        proposed_tasks=manual_task_labels[manual_task_labels.title==i['title']]['Proposed Tasks'].iloc[0]\n",
    "        #in addition to any tasks that were already there (although shouldn't be any), add the manually annotated ones\n",
    "        i['tasks']+=[j.strip() for j in proposed_tasks.split(',')]\n",
    "    if len(i['tasks'])==0: continue\n",
    "    #these comprehensions pool all parents,children, and children for ALL tasks the paper is labeled with\n",
    "    ap=[]\n",
    "    [ ap.extend(child_parent_dict[t]) for t in i['tasks'] if t in child_parent_dict]\n",
    "    ac =[]\n",
    "    [ ac.extend(task_category_dict[t]) for t in i['tasks'] if t in task_category_dict]\n",
    "    ah=[]\n",
    "    [ ah.extend(parent_child_dict[t]) for t in i['tasks'] if t in parent_child_dict]\n",
    "    asib=[]\n",
    "    [ asib.extend(sibling_dict[t]) for t in i['tasks'] if t in sibling_dict]\n",
    "\n",
    "    for t in i['tasks']:\n",
    "        #just keep up with task ages and counts\n",
    "        if t not in task_hist: task_hist[t]=0\n",
    "        task_hist[t]+=1\n",
    "        if t not in task_age: task_age[t] = pd.to_datetime(i['date']).year\n",
    "        else: task_age[t]= min(task_age[t],pd.to_datetime(i['date']).year)\n",
    "        \n",
    "        #add a row for each task-paper\n",
    "        title.append(i['title'])\n",
    "        pdf_url.append(i['url_pdf'])\n",
    "        paper_url.append(i['paper_url'])\n",
    "        date.append(i['date'])\n",
    "        task.append(t)\n",
    "        all_tasks.append(i['tasks'])\n",
    "        all_parents.append(list(set(ap)))\n",
    "        all_categories.append(list(set(ac)))\n",
    "        all_children.append(list(set(ah)))\n",
    "        all_siblings.append(list(set(asib)))\n",
    "\n",
    "#There are some mannually annotated dataset introducing papers that are not in papers-with-abstracts.json\n",
    "for i,row in manual_task_labels.iterrows():\n",
    "    if row['title'] in title: continue\n",
    "    if type(row['Proposed Tasks'])==float:continue\n",
    "    tasks=[j.strip() for j in row['Proposed Tasks'].split(',')]\n",
    "    ap=[]\n",
    "    [ ap.extend(child_parent_dict[t]) for t in tasks if t in child_parent_dict]\n",
    "    ac =[]\n",
    "    [ ac.extend(task_category_dict[t]) for t in tasks if t in task_category_dict]\n",
    "    ah=[]\n",
    "    [ ah.extend(parent_child_dict[t]) for t in tasks if t in parent_child_dict]\n",
    "    asib=[]\n",
    "    [ asib.extend(sibling_dict[t]) for t in tasks if t in sibling_dict]\n",
    "    for t in tasks:\n",
    "        if t not in task_category_dict: print(\"TASK NOT FOUND\",t)\n",
    "\n",
    "        if t not in task_hist: task_hist[t]=0\n",
    "        task_hist[t]+=1\n",
    "        if t not in task_age: task_age[t] = pd.to_datetime(row['introduced_date']).year\n",
    "        else: task_age[t]= min(task_age[t],pd.to_datetime(row['introduced_date']).year)\n",
    "        title.append(row['title'])\n",
    "        pdf_url.append(None)\n",
    "        paper_url.append(row['paper_url'])\n",
    "        date.append(row['introduced_date'])\n",
    "        task.append(t)\n",
    "        all_tasks.append(tasks)\n",
    "        all_parents.append(list(set(ap)))\n",
    "        all_categories.append(list(set(ac)))\n",
    "        all_children.append(list(set(ah)))\n",
    "        all_siblings.append(list(set(asib)))\n",
    "\n",
    "pwc_papers=pd.DataFrame({'title':title,'pdf_url':pdf_url,'paper_url':paper_url,'date':date,'task':task,\n",
    "                         'all_tasks':all_tasks,'all_parents':all_parents,'all_children':all_children,\n",
    "                         'all_siblings':all_siblings,'all_categories':all_categories,})\n",
    "\n",
    "print(\"Total PWC papers in papers with abstracts that have tasks: \",pwc_papers['title'].drop_duplicates().shape)\n",
    "task_hist=pd.Series(task_hist)\n",
    "#task_hist=task_hist[task_hist>task_hist.quantile(.3)]\n",
    "task_age=pd.Series(task_age)\n",
    "task_age.name='task_age'\n",
    "\n",
    "pwc_papers.to_json('./PWC_Data/Derivative_Datasets/pwc_papers.json')\n",
    "\n",
    "# Here we merge with task relations from the benchmarks\n",
    "pwc_papers_task=pd.merge(task_relations,pwc_papers,on='task')\n",
    "print(\"PWC papers lost because none of it's tasks are in the benchmarks dataset: \",\n",
    "      pwc_papers_task['title'].drop_duplicates().shape[0]-pwc_papers_task['title'].drop_duplicates().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952b82b7-764a-4d8f-ad1b-8991d30a6c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78b4a3e-dc79-41d3-9d30-7785afd470ec",
   "metadata": {},
   "source": [
    "Third step is to load and clean the datasets from the PWC file datasets.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a29c596",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#This is available from PWC\n",
    "with open('/home/bkoch/Projects/DataProject/analyses/04-PWC/PWC_2021_06_16/datasets.json') as f:\n",
    "    datasets=pd.DataFrame(json.load(f))\n",
    "\n",
    "#Basic cleaning\n",
    "datasets['title']=datasets['paper'].apply(lambda js: js['title'] if js is not None else None)\n",
    "datasets['paper_url']=datasets['paper'].apply(lambda js: js['url'] if js is not None else None)\n",
    "datasets['introduced_date']=pd.to_datetime(datasets['introduced_date'])\n",
    "datasets['Texts']=datasets['modalities'].apply(lambda r: 'Texts' in r)\n",
    "datasets['Images']=datasets['modalities'].apply(lambda r: 'Images' in r)\n",
    "datasets['dataset_tasks']=datasets['tasks'].apply(lambda js: [ j['task'] for j in js])\n",
    "\n",
    "#Again add tasks from manually labeled dataset-papers\n",
    "manual_dict=manual_task_labels[['name','Proposed Tasks']]\n",
    "manual_dict['Proposed Tasks']=manual_dict['Proposed Tasks'].apply(lambda x: [j.strip() for j in x.split(',')] if type(x)!=float else [])\n",
    "manual_dict=manual_dict.set_index('name').to_dict()['Proposed Tasks']\n",
    "datasets['dataset_tasks']=datasets.apply(lambda row: row['dataset_tasks']+manual_dict[row['name']] if row['name'] in manual_dict else row['dataset_tasks'],axis=1)\n",
    "datasets=datasets.drop(['tasks','paper'],axis=1)\n",
    "\n",
    "#add all task relations to datasets\n",
    "all_parents=[]\n",
    "all_children=[]\n",
    "all_categories=[]\n",
    "all_siblings=[]\n",
    "for i,row in datasets.iterrows():\n",
    "    ap=[]\n",
    "    [ ap.extend(child_parent_dict[t]) for t in row['dataset_tasks'] if t in child_parent_dict]\n",
    "    ac =[]\n",
    "    [ ac.extend(task_category_dict[t]) for t in row['dataset_tasks'] if t in task_category_dict]\n",
    "    ah=[]\n",
    "    [ ah.extend(parent_child_dict[t]) for t in row['dataset_tasks'] if t in parent_child_dict]\n",
    "    asib=[]\n",
    "    [ asib.extend(sibling_dict[t]) for t in row['dataset_tasks'] if t in sibling_dict]\n",
    "    all_parents.append(ap)\n",
    "    all_categories.append(ac)\n",
    "    all_children.append(ah)\n",
    "    all_siblings.append(asib)\n",
    "datasets['dataset_tasks_parents']=all_parents\n",
    "datasets['dataset_tasks_categories']=all_categories\n",
    "datasets['dataset_tasks_children']=all_children\n",
    "datasets['dataset_tasks_siblings']=all_siblings\n",
    "datasets.to_json('./dataset_with_tasks.json')\n",
    "print(\"Total number of datasets in PWC: \",datasets['name'].drop_duplicates().shape[0])\n",
    "\n",
    "\n",
    "\n",
    "# This is one dataset I noticed that is totally messed up. Going to drop it.\n",
    "datasets=datasets[datasets.name!='PRID2011']\n",
    "\n",
    "\n",
    "#datasets_pwc_total=pd.merge(datasets,pwc_papers_task,on=['title','paper_url'],how='left')\n",
    "#datasets_pwc_total.to_json('./DatawithTasks/datasets_total.json')\n",
    "\n",
    "datasets_pwc=pd.merge(datasets.drop('paper_url',axis=1),pwc_papers_task.drop('paper_url',axis=1),on=['title'])\n",
    "#datasets_pwc['all_tasks']=datasets_pwc.apply(lambda row: list(set(row['all_tasks']+row['dataset_tasks'])) if row['name'] in manual_dict else row['all_tasks'],axis=1)\n",
    "\n",
    "print(\"Datasets affiliated with a paper in PWC: \",datasets_pwc['name'].drop_duplicates().shape[0])\n",
    "datasets_pwc.to_json('./PWC_Data/Derivative_Datasets/datasets_pwc.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf363b5-5b01-4770-86d4-bfb38d8dfa68",
   "metadata": {},
   "source": [
    "4. Load dataset-citing papers. This scraped with an API in the script Get_Dataset_Citing_Papers.ipynb Here we again link to papers-with-abstracts.json in order to get task information. We lose a significant number of papers doing this, but it's hard to say whether these papers are real usages or just keyword hits anyways. It is possible that manual annotation could recover some of these papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca21ae2f-dc82-4c7e-9a3f-6e44bfabd3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_citing_papers=pd.read_csv('./PWC_Data/Derivative_Datasets/datasets_citing_papers.txt',sep='\\t')\n",
    "print(\"Dataset citing papers harvested from PWC internal API:\",dataset_citing_papers['title'].drop_duplicates().shape[0])\n",
    "\n",
    "dataset_citing_papers_pwc=pd.merge(dataset_citing_papers,pwc_papers_task,on=['title','date'])\n",
    "dataset_citing_papers_pwc['date']=pd.to_datetime(dataset_citing_papers_pwc['date'])\n",
    "print(\"Dataset citing papers that are actually labeled wth tasks: \",dataset_citing_papers_pwc['title'].drop_duplicates().shape[0])\n",
    "dataset_citing_papers_pwc.to_json('./PWC_Data/Derivative_Datasets/datasets_citing_papers_pwc.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161f502f-206f-42f4-8b3b-fe6c97159892",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of usages recovered through manual annotation:\", dataset_citing_papers_pwc[dataset_citing_papers_pwc.name.isin(manual_task_labels.name)].shape[0])\n",
    "print(\"Number of usages recovered through manual annotation:\",dataset_citing_papers_pwc[dataset_citing_papers_pwc.name.isin(manual_tasks_not_labeled.name)].shape[0])\n",
    "print(\"Percentage of total usages we're dropping: \",dataset_citing_papers_pwc[dataset_citing_papers_pwc.name.isin(manual_tasks_not_labeled.name)].shape[0]/dataset_citing_papers_pwc.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1caaeb7-10e7-4fe9-aa3d-fb5e05d0d12b",
   "metadata": {},
   "source": [
    "# Curating Transfer Datasets\n",
    "\n",
    "Now we're going to combine our four datasets to do dataset transfers. This block merges each citing task-paper with each dataset's task paper. There are three different lists we keep track of:\n",
    "1. The birth of datasets\n",
    "2. Datasets used by others within the same task\n",
    "3. Datasets used by tasks within another dataset\n",
    "\n",
    "Note this is pretty inefficient for the sake of clarity. I would only run this block once and then reload results in the next block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f02df6-00c7-4622-b72d-7dfe3e5b4871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create infomap inputs\n",
    "\n",
    "# Now create infomap inputs\n",
    "dataset_citing_papers_origins=pd.merge(datasets_pwc,dataset_citing_papers_pwc,on='name')\n",
    "dataset_citing_papers_origins.columns\n",
    "#I realize this is incredibly stupid, I had done it a more elegant way but this works\n",
    "dataset_citing_papers_origins.rename({'title_x':'origin_title',\n",
    "                                     'all_tasks_x':'origin_tasks',\n",
    "                                     'all_parents_x':'origin_parents',\n",
    "                                     'all_siblings_x':'origin_siblings',\n",
    "                                     'all_children_x':'origin_children'},axis=1,inplace=True)\n",
    "dataset_citing_papers_origins.columns=[i.replace('_y','') for i in dataset_citing_papers_origins.columns]\n",
    "dataset_citing_papers_origins=dataset_citing_papers_origins[dataset_citing_papers_origins.title!=dataset_citing_papers_origins.origin_title]\n",
    "\n",
    "task_contains_images={}\n",
    "task_contains_texts={}\n",
    "\n",
    "#external adoptions to siblings and parents\n",
    "sources=[]\n",
    "destinations=[]\n",
    "ds_names=[]\n",
    "paper_titles=[]\n",
    "ds_texts=[]\n",
    "ds_images=[]\n",
    "dest_dates=[]\n",
    "parent_transfer=[]\n",
    "\n",
    "\n",
    "#adoption of homegrown datasets\n",
    "home_tasks=[]\n",
    "home_names=[]\n",
    "home_titles=[]\n",
    "home_dates=[]\n",
    "home_texts=[]\n",
    "home_images=[]\n",
    "home_parent=[]\n",
    "home_introduced=[]\n",
    "\n",
    "#newly created dataset within a task\n",
    "introduced_names=[]\n",
    "introduced_dates=[]\n",
    "introduced_tasks=[]\n",
    "introduced_texts=[]\n",
    "introduced_images=[]\n",
    "introduced_parent=[]\n",
    "introduced_title=[]\n",
    "\n",
    "big_break=False\n",
    "for i,row in dataset_citing_papers_origins.iterrows():\n",
    "    #the task can only be one that the dataset, not the dataset paper has been labeled with.\n",
    "    valid_tasks= set(datasets[datasets.name==row['name']]['dataset_tasks'].iloc[0]+\\\n",
    "                     datasets[datasets.name==row['name']]['dataset_tasks_children'].iloc[0]+\\\n",
    "                    datasets[datasets.name==row['name']]['dataset_tasks_siblings'].iloc[0])\n",
    "    for t in row['origin_tasks']:\n",
    "        if t not in valid_tasks: continue\n",
    "        \n",
    "        introduced_names.append(row['name'])\n",
    "        introduced_dates.append(row['introduced_date'])\n",
    "        introduced_tasks.append(t)\n",
    "        introduced_images.append(row['Images'])\n",
    "        introduced_texts.append(row['Texts'])\n",
    "        introduced_title.append(row['origin_title'])\n",
    "        introduced_parent.append(False)\n",
    "        if t not in task_contains_images: task_contains_images[t]=0\n",
    "        if t not in task_contains_texts: task_contains_texts[t]=0\n",
    "        task_contains_texts[t]+=row['Images']; task_contains_images[t]+=row['Texts']\n",
    "\n",
    "        #Your parent gets credit for introducing datasets as well!\n",
    "        for d in row['origin_parents']:\n",
    "            if d not in valid_tasks: continue\n",
    "            introduced_names.append(row['name'])\n",
    "            introduced_dates.append(row['introduced_date'])\n",
    "            introduced_tasks.append(d)\n",
    "            introduced_images.append(row['Images'])\n",
    "            introduced_texts.append(row['Texts'])\n",
    "            introduced_parent.append(True)\n",
    "            introduced_title.append(row['origin_title'])\n",
    "\n",
    "            if d not in task_contains_images: task_contains_images[d]=0\n",
    "            if d not in task_contains_texts: task_contains_texts[d]=0\n",
    "            task_contains_texts[d]+=row['Images']; task_contains_images[d]+=row['Texts']\n",
    "            \n",
    "\n",
    "        #who are you passing it to?\n",
    "        for d in row['all_tasks']:\n",
    "            if d not in valid_tasks: continue\n",
    "            #if d not in focal_tasks: continue\n",
    "            #Scenario 1: Dest is sources parent\n",
    "            if d in row['origin_parents']: continue\n",
    "            #Scenario 2: Dest is sources child or another origins child:\n",
    "            if d in row['origin_children']: continue\n",
    "            #Scenario 3: Dest is source. (First confirm its not another origin)\n",
    "            if d in row['origin_tasks'] and t!=d: continue\n",
    "            #you've found yourself. Add to home task\n",
    "            if t==d: \n",
    "                home_tasks.append(t)\n",
    "                home_names.append(row['name'])\n",
    "                home_titles.append(row['title'])\n",
    "                home_dates.append(row['date'])\n",
    "                home_images.append(row['Images'])\n",
    "                home_texts.append(row['Texts'])\n",
    "                home_parent.append(False)\n",
    "                home_introduced.append(row['introduced_date'])\n",
    "                if t not in task_contains_images: task_contains_images[t]=0\n",
    "                if t not in task_contains_texts: task_contains_texts[t]=0\n",
    "                task_contains_texts[t]+=row['Images']; task_contains_images[t]+=row['Texts']\n",
    "                #your parents have also homgrown a task\n",
    "                for parent in row['origin_parents']:\n",
    "                    if parent not in valid_tasks: continue\n",
    "                    home_tasks.append(parent)\n",
    "                    home_names.append(row['name'])\n",
    "                    home_titles.append(row['title'])\n",
    "                    home_dates.append(row['date'])\n",
    "                    home_images.append(row['Images'])\n",
    "                    home_texts.append(row['Texts'])\n",
    "                    home_parent.append(True)\n",
    "                    home_introduced.append(row['introduced_date'])\n",
    "                    if parent not in task_contains_images: task_contains_images[parent]=0\n",
    "                    if parent not in task_contains_texts: task_contains_texts[parent]=0\n",
    "                    task_contains_texts[parent]+=row['Images']; task_contains_images[parent]+=row['Texts']\n",
    "            #you haven't found yourself and this is a transfer\n",
    "            else:\n",
    "                #A. pass directly to this tasks\n",
    "                if t not in valid_tasks or d not in valid_tasks: continue\n",
    "                sources.append(t)\n",
    "                destinations.append(d)\n",
    "                ds_names.append(row['name'])\n",
    "                paper_titles.append(row['title'])\n",
    "                dest_dates.append(row['date'])\n",
    "                ds_texts.append(row['Texts'])\n",
    "                ds_images.append(row['Images'])\n",
    "                parent_transfer.append(False)\n",
    "                if t not in task_contains_images: task_contains_images[t]=0\n",
    "                if t not in task_contains_texts: task_contains_texts[t]=0\n",
    "                task_contains_texts[t]+=row['Images']; task_contains_images[t]+=row['Texts']\n",
    "                if d not in task_contains_images: task_contains_images[d]=0\n",
    "                if d not in task_contains_texts: task_contains_texts[d]=0\n",
    "                task_contains_texts[d]+=row['Images']; task_contains_images[d]+=row['Texts'] \n",
    "                #B1. Source has no parents but dest does\n",
    "                for pt in row['origin_parents']:\n",
    "                    if t not in valid_tasks or pt not in valid_tasks: continue\n",
    "                    if t==pt: continue #cant transfer to yourself (this only occurs with self-loops)                        \n",
    "                    for pdest in row['all_parents']:\n",
    "                        if t not in valid_tasks or pdest not in valid_tasks: continue\n",
    "                        #cant transfer to yourself to your own parent or children\n",
    "                        #this is a simplification because in reality, you can transfer to your children but we lack the resolution to resolve that\n",
    "                        if t==pdest or pdest in row['origin_parents'] or pdest in row['origin_children']: continue\n",
    "                        sources.append(pt)\n",
    "                        destinations.append(pdest)\n",
    "                        ds_names.append(row['name'])\n",
    "                        paper_titles.append(row['title'])\n",
    "                        dest_dates.append(row['date'])\n",
    "                        ds_texts.append(row['Texts'])\n",
    "                        ds_images.append(row['Images'])\n",
    "                        parent_transfer.append(True)\n",
    "                        if pt not in task_contains_images: task_contains_images[pt]=0\n",
    "                        if pt not in task_contains_texts: task_contains_texts[pt]=0\n",
    "                        task_contains_texts[pt]+=row['Images']; task_contains_images[pt]+=row['Texts']\n",
    "                        if pdest not in task_contains_images: task_contains_images[pdest]=0\n",
    "                        if pdest not in task_contains_texts: task_contains_texts[pdest]=0\n",
    "                        task_contains_texts[pdest]+=row['Images']; task_contains_images[pdest]+=row['Texts']\n",
    "\n",
    "source_dest_edgelist=pd.DataFrame({'source_task':sources,'dest_task':destinations,'name':ds_names,'title':paper_titles,'date':dest_dates,'Images':ds_images,'Texts':ds_texts,'Parent_Transfer':parent_transfer}).drop_duplicates()\n",
    "homegrown_edgelist=pd.DataFrame({'task':home_tasks,'name':home_names,'title':home_titles,'date':home_dates,'Images':home_images,'Texts':home_texts,'Parent':home_parent,'introduced_date':home_introduced}).drop_duplicates()\n",
    "birth_edgelist=pd.DataFrame({'task':introduced_tasks,'name':introduced_names,'title':introduced_title,'date':introduced_dates,'Images':introduced_images,'Texts':introduced_texts,'Parent':introduced_parent}).drop_duplicates()\n",
    "task_contains_images=pd.Series(task_contains_images)\n",
    "task_contains_images[task_contains_images>0]=1\n",
    "task_contains_texts=pd.Series(task_contains_texts)\n",
    "task_contains_texts[task_contains_texts>0]=1\n",
    "task_contains_images=task_contains_images.reset_index()\n",
    "task_contains_images.columns=['task','Images']\n",
    "task_contains_texts=task_contains_texts.reset_index()\n",
    "task_contains_texts.columns=['task','Texts']\n",
    "source_dest_edgelist.to_csv('source_dest_edgelist.csv',quoting=1)\n",
    "homegrown_edgelist.to_csv('homegrown_edgelist',quoting=1)\n",
    "birth_edgelist.to_csv('birth_edgelist.csv',quoting=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff77ab54-31aa-47fc-a569-67ac5c1d7979",
   "metadata": {},
   "source": [
    "# RQ 3\n",
    "Because the above block is so slow, you can uncommentThis block reloads the dataset and saves it for the Affiliation analysis in another "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119553c4-40da-4620-929e-58ac41ea24ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#source_dest_edgelist=pd.read_csv('source_dest_edgelist.csv')\n",
    "#homegrown_edgelist=pd.read_csv('source_dest_edgelist.csv')\n",
    "#birth_edgelist=pd.read_csv('birth_edgelist.csv')\n",
    "dataset_papers=datasets_pwc[['name','title']]\n",
    "dataset_papers['date']=None\n",
    "dest_papers=source_dest_edgelist[['name','title','date']]\n",
    "dest_papers.columns=['name','title','date']\n",
    "birth_papers=birth_edgelist[['name','title','date']]\n",
    "homegrown_papers=homegrown_edgelist[['name','title','date']]\n",
    "full_dataset=pd.concat([dataset_papers,dest_papers,birth_papers,homegrown_papers]).drop_duplicates()\n",
    "print(\"Number of datasets born and then used at least once: \",birth_edgelist['name'].drop_duplicates().shape[0])\n",
    "print(\"Total number of unique usages within introducing paper task: \", homegrown_edgelist[['name','title']].drop_duplicates().shape[0])\n",
    "print(\"Total number of unique usages from outside paper introducing task: \", source_dest_edgelist[['name','title']].drop_duplicates().shape[0])\n",
    "print(\"Total number of dataset-usages: \", full_dataset[~full_dataset.date.isnull()][['name','title']].drop_duplicates().shape[0])\n",
    "print(\"Total number of dataset-using papers: \", full_dataset[~full_dataset.date.isnull()][['title']].drop_duplicates().shape[0])\n",
    "print(\"Total number of datasets: \", full_dataset[['name']].drop_duplicates().shape[0])\n",
    "print(\"Total number of tasks involved: \",pd.concat([birth_edgelist['task'],homegrown_edgelist['task'],\n",
    "           source_dest_edgelist['source_task'],source_dest_edgelist['dest_task']]).drop_duplicates().shape[0])\n",
    "full_dataset.to_csv('./PWC_Data/Derivative_Datasets/ValidPaperDataset-Titles.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe8362d-7dfc-46da-aea7-835895832740",
   "metadata": {},
   "source": [
    "These two figures appear in the appendix as summaries of the dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607fd6ce-d221-4d5e-b3fb-0f961a710773",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "temp=full_dataset.groupby('name').size().sort_values()\n",
    "dataset_usage_dist=temp[(temp>5)&(temp<500)].plot(kind='hist',bins=500,figsize=[8,4],title='Truncated Distribution of Dataset Usages')\n",
    "fig = dataset_usage_dist.get_figure()\n",
    "fig.savefig('truncated_dist.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c722a301-107e-4f5c-b226-d5fe9757b973",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_size=pwc_papers.groupby('year').size().reset_index()\n",
    "temp=annual_size.plot(figsize=[8,4],x='year',y=0,title='PWC Corpus papers per year',xlim=[2009,2020],legend=False)\n",
    "fig = temp.get_figure()\n",
    "pwc_papers.title.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ac8276-1822-49eb-ba77-5c5c56a6926c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAGIDs=pd.read_json('MAG_Linking_IDs.json')\n",
    "#MAGIDs=MAGIDs[['MAGID','PWC_Clean_Title','PWC_Title']]\n",
    "dataset_papers_MAG=pd.merge(MAGIDs,birth_papers.drop_duplicates(),left_on='PWC_Title',right_on='title')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737ed5d1-b6c1-4e89-8795-7f7156469e50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32ab1f30-275f-4bd4-9cb8-bd1a0d8504fe",
   "metadata": {},
   "source": [
    "Because we were interested in tasks labeled under the Methodology section and removed these tasks which were anomolous compared to other methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5189814e-9ff1-4d58-b54f-d2957696c652",
   "metadata": {},
   "outputs": [],
   "source": [
    "Methodologies_to_Drop=[\n",
    "'Word Embeddings',\n",
    "'Anomaly Detection',\n",
    "'Multivariate Time Series Forecasting',\n",
    "'EEG',\n",
    "'Chatbot',\n",
    "'Computed Tomography (CT)',\n",
    "'Electrocardiography (ECG)',\n",
    "'Electrocardiography (ECG)',\n",
    "'Multi-Label Text Classification'    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b815132-e67d-48f7-8b8f-3bbaaefd618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34908600-70de-4143-964a-88af4edcb159",
   "metadata": {},
   "source": [
    "# RQ2: Creating ratio datasets\n",
    "\n",
    "Below are three largely similar blocks that create ratio datasets:\n",
    "    \n",
    "1. Calculates ratios for transfers between parent tasks, aggregated across all years (Figure 2)\n",
    "2. Calculates ratios for transfers between parent tasks, disaggregated by year (Figure 1)\n",
    "3. Calculates ratios for transfers between all tasks, disaggregated by year (not shown)\n",
    "\n",
    "We do not use 3 because it double counts transfers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9b6992-dc7e-4b92-88ef-e511661bc493",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all tasks that are a parent of some other task\n",
    "parent_tasks=[i for i in parent_child_dict if len(parent_child_dict[i])!=0]\n",
    "parent_tasks=median_parent_tasks\n",
    "source_dest_edgelist_parents= source_dest_edgelist[(source_dest_edgelist.source_task.isin(parent_tasks)) &\\\n",
    "                                                  (source_dest_edgelist.dest_task.isin(parent_tasks))]\n",
    "homegrown_edgelist_parents= homegrown_edgelist[homegrown_edgelist.task.isin(parent_tasks)]\n",
    "birth_edgelist_parents= birth_edgelist[birth_edgelist.task.isin(parent_tasks)]\n",
    "print(\"Number of datasets born and then used at least once: \",birth_edgelist_parents['name'].drop_duplicates().shape[0])\n",
    "print(\"Total number of unique usages within introducing paper task: \", homegrown_edgelist_parents[['name','title']].drop_duplicates().shape[0])\n",
    "print(\"Total number of unique usages from outside paper introducing task: \", source_dest_edgelist_parents[['name','title']].drop_duplicates().shape[0])\n",
    "print(\"Total number of parent tasks involved: \",pd.concat([birth_edgelist_parents['task'],homegrown_edgelist_parents['task'],\n",
    "           source_dest_edgelist_parents['source_task'],source_dest_edgelist_parents['dest_task']]).drop_duplicates().shape[0])\n",
    "print(\"Total number of papers involved: \",pd.concat([birth_edgelist_parents['title'],homegrown_edgelist_parents['title'],\n",
    "           source_dest_edgelist_parents['title'],source_dest_edgelist_parents['title']]).drop_duplicates().shape[0])\n",
    "\n",
    "num_papers_adopting=source_dest_edgelist_parents.groupby(['dest_task']).size() #counts the number of adopting papers within tasks\n",
    "num_papers_adopting.index.names=['task']\n",
    "num_papers_growing=homegrown_edgelist_parents.groupby(['task']).size() #counts the number of papers that use a \"homegrown\" dataset within tasks\n",
    "num_dataset_births=birth_edgelist_parents.groupby(['task']).size() #number of datasets created within a task that are used at least once\n",
    "#num_homegrown_datasets=num_dataset_births.shift(1).cumsum() #num datasets born in previous year\n",
    "temp=source_dest_edgelist_parents.groupby(['dest_task','name']).size().reset_index().drop(0,axis=1)\n",
    "num_dataset_imports=temp.groupby(['dest_task']).size()\n",
    "#num_converted_growing=homegrown_edgelist_parents[(homegrown_edgelist_parents.introduced_date.dt.year==homegrown_edgelist_parents.date.dt.year)|\\\n",
    "#                                         (homegrown_edgelist_parents.introduced_date.dt.year==homegrown_edgelist_parents.date.dt.year-1)|\\\n",
    "#                                        (homegrown_edgelist_parents.introduced_date.dt.year==homegrown_edgelist_parents.date.dt.year-2)]\n",
    "#num_converted_growing_year=num_converted_growing.groupby(['task',num_converted_growing.date.dt.year]).size()\n",
    "#num_papers_growing_year=homegrown_edgelist_parents.groupby(['task',homegrown_edgelist_parents.date.dt.year]).size()\n",
    "#conversion_pct\n",
    "num_dataset_imports.columns=['imported_datasets']\n",
    "num_dataset_imports.index.names=['task']\n",
    "num_dataset_births.name='num_dataset_births'\n",
    "num_papers_adopting.name='num_papers_adopting'\n",
    "num_dataset_imports.name='num_dataset_imports'\n",
    "num_papers_growing.name='num_papers_growing'\n",
    "#num_homegrown_datasets.name='num_dataset_homegrown'\n",
    "#num_converted_growing.name='num_converted_growing'\n",
    "\n",
    "full_data=pd.merge(num_dataset_births.reset_index(),num_papers_adopting.reset_index(),how='outer')\n",
    "#full_data=pd.merge(full_data,num_homegrown_datasets.reset_index(),how='outer')\n",
    "full_data=pd.merge(full_data,num_dataset_imports.reset_index(),how='outer')\n",
    "full_data=pd.merge(full_data,num_papers_growing.reset_index(),how='outer')\n",
    "#full_data=pd.merge(full_data,num_converted_growing.reset_index(),how='outer')\n",
    "full_data=full_data.fillna(0)\n",
    "full_data['size']=full_data.num_papers_adopting+full_data.num_papers_growing+full_data.num_dataset_births\n",
    "task_age_df=task_age.reset_index()\n",
    "task_age_df.columns=['task','task_age']\n",
    "full_data=pd.merge(full_data,task_age_df,on='task',how='left')\n",
    "\n",
    "full_data['adoption_ratio']=full_data.num_papers_adopting.divide(full_data.num_papers_growing)\n",
    "full_data['creation_ratio']=full_data.num_dataset_births.divide(full_data.num_dataset_imports)\n",
    "#same as above but adding the numerator to the denominator to add stability\n",
    "full_data['adoption_pct']=full_data.num_papers_adopting.divide(full_data.num_papers_adopting+full_data.num_papers_growing)\n",
    "full_data['creation_pct']=full_data.num_dataset_births.divide(full_data.num_dataset_births+full_data.num_dataset_imports)\n",
    "#full_data=pd.merge(full_data,task_contains_images,on='task',how='left')\n",
    "#full_data=pd.merge(full_data,task_contains_texts,on='task',how='left')\n",
    "\n",
    "def in_category(x,cat):\n",
    "    if x in task_category_dict and cat in task_category_dict[x]:\n",
    "        return 1\n",
    "    if x in parent_child_dict and any([cat in task_category_dict[p] for p in child_parent_dict[x]]):\n",
    "        return 1\n",
    "    return 0\n",
    "full_data['CV']=full_data['task'].apply(lambda x: in_category(x,'Computer Vision'))\n",
    "full_data['NLP']=full_data['task'].apply(lambda x: in_category(x,'Natural Language Processing'))\n",
    "full_data['Methodology']=full_data['task'].apply(lambda x: in_category(x,'Methodology'))\n",
    "full_data['Methodology']=full_data['Methodology'].apply(lambda x: 0 if x in Methodologies_to_Drop else x)\n",
    "median_parent_task_size=full_data['size'].median()\n",
    "full_data=full_data[full_data['size']>median_parent_task_size]\n",
    "print(\"Median parent task size: \",median_parent_task_size)\n",
    "print(\"Number of tasks for final analysis (Figure 2): \",full_data['task'].unique().shape[0])\n",
    "median_parent_tasks=full_data.task\n",
    "median_parent_tasks.to_csv('median_parent_tasks')\n",
    "\n",
    "full_data.to_csv(\"./PWC_Data/Derivative_Datasets/FullDatasetforR.ParentsOnly.AllYears.txt\",sep='\\t',quoting=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe1b555-49ae-4e2c-9f91-ff3c7d160462",
   "metadata": {},
   "source": [
    "This block imposes no restrictions on tasks but if we're not using only parent transfers, that means there can be double counts...\n",
    "It's not used in the paper but the results are similar (CHECK TO MAKE SURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8e7e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_papers_adopting=source_dest_edgelist.groupby(['dest_task',source_dest_edgelist.date.dt.year]).size()\n",
    "num_papers_adopting.index.names=['task','date']\n",
    "num_papers_growing=homegrown_edgelist.groupby(['task',homegrown_edgelist.date.dt.year]).size()\n",
    "num_dataset_births=birth_edgelist.groupby(['task', birth_edgelist.date.dt.year]).size()\n",
    "num_homegrown_datasets=num_dataset_births.shift(1).cumsum()\n",
    "temp=source_dest_edgelist.groupby(['dest_task','name',source_dest_edgelist.date.dt.year]).size().reset_index().drop(0,axis=1)\n",
    "num_dataset_imports=temp.groupby(['dest_task',source_dest_edgelist.date.dt.year]).size()\n",
    "num_converted_growing=homegrown_edgelist[(homegrown_edgelist.introduced_date.dt.year==homegrown_edgelist.date.dt.year)|\\\n",
    "                                         (homegrown_edgelist.introduced_date.dt.year==homegrown_edgelist.date.dt.year-1)]\n",
    "num_converted_growing=num_converted_growing.groupby(['task',num_converted_growing.date.dt.year]).size()\n",
    "\n",
    "num_dataset_imports.columns=['imported_datasets']\n",
    "num_dataset_imports.index.names=['task','date']\n",
    "num_dataset_births.name='num_dataset_births'\n",
    "num_papers_adopting.name='num_papers_adopting'\n",
    "num_dataset_imports.name='num_dataset_imports'\n",
    "num_papers_growing.name='num_papers_growing'\n",
    "num_homegrown_datasets.name='num_dataset_homegrown'\n",
    "num_converted_growing.name='num_converted_growing'\n",
    "annual_data=pd.merge(num_dataset_births.reset_index(),num_papers_adopting.reset_index(),how='outer')\n",
    "annual_data=pd.merge(annual_data,num_homegrown_datasets.reset_index(),how='outer')\n",
    "annual_data=pd.merge(annual_data,num_dataset_imports.reset_index(),how='outer')\n",
    "annual_data=pd.merge(annual_data,num_papers_growing.reset_index(),how='outer')\n",
    "annual_data=pd.merge(annual_data,num_converted_growing.reset_index(),how='outer')\n",
    "annual_data=annual_data.fillna(0)\n",
    "annual_data['size']=annual_data.num_papers_adopting+annual_data.num_papers_growing+annual_data.num_dataset_births\n",
    "task_age_df=task_age.reset_index()\n",
    "task_age_df.columns=['task','task_age']\n",
    "annual_data=pd.merge(annual_data,task_age_df,on='task',how='left')\n",
    "annual_data['adoption_ratio']=annual_data.num_papers_adopting.divide(annual_data.num_papers_growing)\n",
    "annual_data['creation_ratio']=annual_data.num_dataset_births.divide(annual_data.num_dataset_imports)\n",
    "#annual_data['conversion_ratio']=annual_data.num_dataset_homegrown.divide(annual_data.num_papers_growing)\n",
    "annual_data['adoption_pct']=annual_data.num_papers_adopting.divide(annual_data.num_papers_adopting+annual_data.num_papers_growing)\n",
    "annual_data['creation_pct']=annual_data.num_dataset_births.divide(annual_data.num_dataset_births+annual_data.num_dataset_imports)\n",
    "annual_data['conversion_pct']=annual_data.num_converted_growing.divide(annual_data.num_papers_growing)\n",
    "#annual_data=pd.merge(annual_data,task_contains_images,on='task',how='left')\n",
    "#annual_data=pd.merge(annual_data,task_contains_texts,on='task',how='left')\n",
    "pwc_papers['year']=pd.to_datetime(pwc_papers['date']).dt.year\n",
    "annual_size=pwc_papers.groupby('year').size().reset_index()\n",
    "annual_data=pd.merge(annual_data,annual_size,left_on='date',right_on='year',how='left')\n",
    "annual_data=annual_data.drop('year',axis=1).rename({0:'pwc_size'},axis=1)\n",
    "annual_data.rename({'date':'year'},axis=1,inplace=True)\n",
    "\n",
    "def in_category(x,cat):\n",
    "    if x in task_category_dict and cat in task_category_dict[x]:\n",
    "        return 1\n",
    "    if x in parent_child_dict and any([cat in task_category_dict[p] for p in child_parent_dict[x]]):\n",
    "        return 1\n",
    "    return 0\n",
    "annual_data['CV']=annual_data['task'].apply(lambda x: in_category(x,'Computer Vision'))\n",
    "annual_data['NLP']=annual_data['task'].apply(lambda x: in_category(x,'Natural Language Processing'))\n",
    "annual_data['Methodology']=annual_data['task'].apply(lambda x: in_category(x,'Methodology'))\n",
    "annual_data['Methodology']=annual_data['Methodology'].apply(lambda x: 0 if x in Methodologies_to_Drop else x)\n",
    "annual_data=annual_data[annual_data.year>=annual_data.task_age]\n",
    "annual_data.to_csv(\"./PWC_Data/Derivative_Datasets/FullDatasetforR.txt\",sep='\\t',quoting=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4f78fb-160f-4f2f-9105-59890140c98d",
   "metadata": {},
   "source": [
    "This block allows you to print out histograms of dataset usages by task. It's not presented in the paper, but may be interesting to readers. It was used to select interesting cases for Figure 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84a9582-5a2d-49f9-a9d6-28896e5317e4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#annual_data[['task','date','size','task_age','pwc_size']]\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#This is just a subset \n",
    "methods_tasks=pd.read_csv(\"MethodTasksfromEmily.txt\",header=None).squeeze().tolist()\n",
    "outpath='/mnt/c/Users/berna/Documents/GoogleDataProject/ImportPlots/'\n",
    "completed=os.listdir('/mnt/c/Users/berna/Documents/GoogleDataProject/ImportPlots/tasks')\n",
    "\n",
    "modality_dict=datasets[['name','modalities']]\n",
    "modality_dict['modes']=modality_dict['modalities'].apply(lambda x: x if x!= [] else ['Unknown'])\n",
    "modality_dict=modality_dict.drop('modalities',axis=1).set_index('name').squeeze()\n",
    "\n",
    "for p in median_parent_tasks:\n",
    "    print(p)\n",
    "    out_name=p.replace('/','_').replace(' ','_')\n",
    "    '''\n",
    "    if out_name+'.jpg' in completed:\n",
    "        print(\"COMPLETED\")\n",
    "        continue\n",
    "    '''\n",
    "    datasets_borrow=source_dest_edgelist_parents[source_dest_edgelist_parents.dest_task==p].drop_duplicates(['name','title']).groupby('name').size().sort_values().to_frame()\n",
    "    datasets_borrow['source']='blue'\n",
    "    datasets_homegrown=homegrown_edgelist_parents[homegrown_edgelist_parents.task==p].drop_duplicates(['name','title']).groupby('name').size().sort_values().to_frame()\n",
    "    datasets_homegrown['source']='orange'\n",
    "    dataset_df=pd.concat([ datasets_borrow,datasets_homegrown]).reset_index().sort_values(0,ascending=False)\n",
    "    if len(dataset_df)==0:continue\n",
    "    dataset_df=dataset_df.rename({0:'count'},axis=1)\n",
    "    d=dataset_df.plot.barh(x='name',y='count',color=dataset_df['source'],figsize=(20, 20)).figure.savefig(outpath+'datasets/'+out_name+'.jpg')\n",
    "    plt.clf();plt.close()\n",
    "    if p in methods_tasks:\n",
    "            d=dataset_df.plot.barh(x='name',y='count',color=dataset_df['source'],figsize=(20, 20)).figure.savefig(outpath+'methods_datasets/'+out_name+'.jpg')\n",
    "            plt.clf();plt.close()\n",
    "    tasks_borrow=source_dest_edgelist_parents[source_dest_edgelist_parents.dest_task==p].drop_duplicates(['name','title']).groupby('source_task').size().sort_values().to_frame()\n",
    "    tasks_borrow['source']='blue'\n",
    "    tasks_homegrown=homegrown_edgelist_parents[homegrown_edgelist_parents.task==p].drop_duplicates(['name','title']).groupby('task').size().sort_values().to_frame()\n",
    "    tasks_homegrown['source']='orange'\n",
    "    tasks_df=pd.concat([ tasks_borrow,tasks_homegrown]).reset_index().sort_values(0,ascending=False)\n",
    "    tasks_df=tasks_df.rename({0:'count','index':'task'},axis=1)\n",
    "    t=tasks_df.plot.barh(x='task',y='count',color=tasks_df['source'],figsize=(20, 20)).figure.savefig(outpath+'tasks/'+out_name+'.jpg')\n",
    "    plt.clf();plt.close()\n",
    "    if p in methods_tasks:\n",
    "            t=tasks_df.plot.barh(x='task',y='count',color=tasks_df['source'],figsize=(20, 20)).figure.savefig(outpath+'methods_tasks/'+out_name+'.jpg')\n",
    "            plt.clf();plt.close()\n",
    "    if p not in methods_tasks: continue\n",
    "    modalities=[]\n",
    "    for i,row in dataset_df.iterrows(): modalities+=modality_dict[row['name']]*row['count']\n",
    "    modalities=pd.Series(modalities).value_counts().sort_values(ascending=False)\n",
    "    m=modalities.plot.barh(figsize=(20, 20)).figure.savefig(outpath+'methods_modalities/'+out_name+'.jpg')\n",
    "    plt.clf();plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdce313-26a3-4aec-a386-2e7b01e2546f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Figure 4: Pie charts for Figure 4\n",
    "\n",
    "The following blocks create the pie charts for figure 4..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7672056-9e91-4f09-a888-26cc3b8decd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "p='Image Generation'\n",
    "datasets_borrow=source_dest_edgelist[source_dest_edgelist.dest_task==p].drop_duplicates(['name','title']).groupby('name').size().sort_values().to_frame()\n",
    "datasets_borrow['source']='blue'\n",
    "datasets_homegrown=homegrown_edgelist[homegrown_edgelist.task==p].drop_duplicates(['name','title']).groupby('name').size().sort_values().to_frame()\n",
    "datasets_homegrown['source']='orange'\n",
    "dataset_df=pd.concat([ datasets_borrow,datasets_homegrown]).reset_index().sort_values(0,ascending=False)\n",
    "dataset_df=dataset_df.rename({0:'count'},axis=1)\n",
    "\n",
    "tasks_borrow=source_dest_edgelist[source_dest_edgelist.dest_task==p].drop_duplicates(['name','title']).groupby('source_task').size().sort_values().to_frame()\n",
    "tasks_borrow['source']='blue'\n",
    "tasks_homegrown=homegrown_edgelist[homegrown_edgelist.task==p].drop_duplicates(['name','title']).groupby('task').size().sort_values().to_frame()\n",
    "tasks_homegrown['source']='orange'\n",
    "tasks_df=pd.concat([ tasks_borrow,tasks_homegrown]).reset_index().sort_values(0,ascending=False)\n",
    "tasks_df=tasks_df.rename({0:'count','index':'task'},axis=1)\n",
    "\n",
    "dataset_df['cumulative']=dataset_df.sort_values('count',ascending=False)['count'].cumsum()/dataset_df.sort_values('count',ascending=False)['count'].sum()\n",
    "#tasks_df.set_index('task').plot.pie(y='count')\n",
    "other_count=dataset_df[dataset_df['cumulative']>.90]['count'].sum()\n",
    "dataset_df=dataset_df[dataset_df['cumulative']<.90]\n",
    "dataset_df=dataset_df.append({'name':'Other','count':other_count,'cumulative':1,'source':'gray'},ignore_index=True)\n",
    "\n",
    "tasks_df['cumulative']=tasks_df.sort_values('count',ascending=False)['count'].cumsum()/tasks_df.sort_values('count',ascending=False)['count'].sum()\n",
    "#tasks_df.set_index('task').plot.pie(y='count')\n",
    "other_count=tasks_df[tasks_df['cumulative']>.90]['count'].sum()\n",
    "tasks_df=tasks_df[tasks_df['cumulative']<.90]\n",
    "tasks_df=tasks_df.append({'task':'Other','count':other_count,'cumulative':1,'source':'gray'},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec8ed91-8489-45be-8103-060a71630d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "fig = go.Figure(data=[go.Pie(labels=tasks_df['task'], \n",
    "                             values=tasks_df['count'],\n",
    "                            pull=[0, 0, 0, 0.0,0.2,0,0])])\n",
    "fig.update_layout(\n",
    "    font_family=\"Arial\",\n",
    "    title_font_family=\"Arial\",\n",
    "    font_color='black',\n",
    ")\n",
    "fig.update_traces(marker=dict(colors=px.colors.qualitative.Set1,line=dict(color='#000000', width=1)),textfont_color='black')\n",
    "fig.show()\n",
    "fig.write_image(\"/mnt/c/Users/berna/Documents/GoogleDataProject/ImportPlots/ImageGenerationTasks.svg\")\n",
    "fig = go.Figure(data=[go.Pie(labels=dataset_df['name'], \n",
    "                             values=dataset_df['count'],\n",
    "                            pull=[0, 0, 0, 0.0,0,0.2,0])])\n",
    "fig.update_layout(\n",
    "    font_family=\"Arial\",\n",
    "    title_font_family=\"Arial\",\n",
    "    font_color='black',\n",
    ")\n",
    "fig.update_traces(marker=dict(colors=px.colors.qualitative.Set3,line=dict(color='#000000', width=1)),textfont_color='black')\n",
    "#fig.write_image(\"ImageGenDatasets.svg\")\n",
    "fig.show()\n",
    "fig.write_image(\"/mnt/c/Users/berna/Documents/GoogleDataProject/ImportPlots/ImageGenerationDatasets.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1306c978-39a7-4a9a-a68f-6123dfcfd149",
   "metadata": {},
   "outputs": [],
   "source": [
    "p='Face Recognition'\n",
    "datasets_borrow=source_dest_edgelist[source_dest_edgelist.dest_task==p].drop_duplicates(['name','title']).groupby('name').size().sort_values().to_frame()\n",
    "datasets_borrow['source']='blue'\n",
    "datasets_homegrown=homegrown_edgelist[homegrown_edgelist.task==p].drop_duplicates(['name','title']).groupby('name').size().sort_values().to_frame()\n",
    "datasets_homegrown['source']='orange'\n",
    "dataset_df=pd.concat([ datasets_borrow,datasets_homegrown]).reset_index().sort_values(0,ascending=False)\n",
    "dataset_df=dataset_df.rename({0:'count'},axis=1)\n",
    "\n",
    "tasks_borrow=source_dest_edgelist[source_dest_edgelist.dest_task==p].drop_duplicates(['name','title']).groupby('source_task').size().sort_values().to_frame()\n",
    "tasks_borrow['source']='blue'\n",
    "tasks_homegrown=homegrown_edgelist[homegrown_edgelist.task==p].drop_duplicates(['name','title']).groupby('task').size().sort_values().to_frame()\n",
    "tasks_homegrown['source']='orange'\n",
    "tasks_df=pd.concat([ tasks_borrow,tasks_homegrown]).reset_index().sort_values(0,ascending=False)\n",
    "tasks_df=tasks_df.rename({0:'count','index':'task'},axis=1)\n",
    "\n",
    "dataset_df['cumulative']=dataset_df.sort_values('count',ascending=False)['count'].cumsum()/dataset_df.sort_values('count',ascending=False)['count'].sum()\n",
    "#tasks_df.set_index('task').plot.pie(y='count')\n",
    "other_count=dataset_df[dataset_df['cumulative']>.85]['count'].sum()\n",
    "dataset_df=dataset_df[dataset_df['cumulative']<.85]\n",
    "dataset_df=dataset_df.append({'name':'Other','count':other_count,'cumulative':1,'source':'gray'},ignore_index=True)\n",
    "\n",
    "tasks_df['cumulative']=tasks_df.sort_values('count',ascending=False)['count'].cumsum()/tasks_df.sort_values('count',ascending=False)['count'].sum()\n",
    "#tasks_df.set_index('task').plot.pie(y='count')\n",
    "other_count=tasks_df[tasks_df['cumulative']>.85]['count'].sum()\n",
    "tasks_df=tasks_df[tasks_df['cumulative']<.85]\n",
    "tasks_df=tasks_df.append({'task':'Other','count':other_count,'cumulative':1,'source':'gray'},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ece0fb-18d4-42f0-b443-9d3f6782498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[go.Pie(labels=tasks_df['task'], \n",
    "                             values=tasks_df['count'],\n",
    "                            pull=[0, 0, 0, 0.2,0,0,0])])\n",
    "fig.update_layout(\n",
    "    font_family=\"Arial\",\n",
    "    title_font_family=\"Arial\",\n",
    "    font_color='black',\n",
    ")\n",
    "fig.update_traces(marker=dict(colors=px.colors.qualitative.Set1,line=dict(color='#000000', width=1)),textfont_color='black')\n",
    "fig.show()\n",
    "temp=[i for i in px.colors.qualitative.Set1]\n",
    "temp[3]='rgb(255,255,,255)'\n",
    "temp[4]='rgb(255,255,255)'\n",
    "temp\n",
    "fig = go.Figure(data=[go.Pie(labels=dataset_df['name'], \n",
    "                             values=dataset_df['count'],\n",
    "                            pull=[0, 0, 0,.2,.2,0,0])])\n",
    "fig.update_layout(\n",
    "    font_family=\"Arial\",\n",
    "    title_font_family=\"Arial\",\n",
    "    font_color='black',\n",
    ")\n",
    "fig.update_traces(marker=dict(colors=temp,line=dict(color='#000000', width=1)),textfont_color='black')\n",
    "fig.show()\n",
    "fig.write_image(\"/mnt/c/Users/berna/Documents/GoogleDataProject/ImportPlots/FaceRecognitionDatasets.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e7c9e4-8e4b-4fb0-af27-4e10958a2748",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "tasks_df['cumulative']=tasks_df.sort_values('count',ascending=False)['count'].cumsum()/tasks_df.sort_values('count',ascending=False)['count'].sum()\n",
    "#tasks_df.set_index('task').plot.pie(y='count')\n",
    "other_count=tasks_df[tasks_df['cumulative']>.99]['count'].sum()\n",
    "tasks_df=tasks_df[tasks_df['cumulative']<.99]\n",
    "tasks_df=tasks_df.append({'task':'Other','count':other_count,'cumulative':1,'source':'gray'},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd31219-fd7d-4142-bf9b-90f7c96604e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df['cumulative']=dataset_df.sort_values('count',ascending=False)['count'].cumsum()/dataset_df.sort_values('count',ascending=False)['count'].sum()\n",
    "#tasks_df.set_index('task').plot.pie(y='count')\n",
    "other_count=dataset_df[dataset_df['cumulative']>.99]['count'].sum()\n",
    "dataset_df=dataset_df[dataset_df['cumulative']<.99]\n",
    "dataset_df=dataset_df.append({'name':'Other','count':other_count,'cumulative':1,'source':'gray'},ignore_index=True)\n",
    "dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f378afb9-5ccf-4896-91fe-0323b6b788c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[go.Pie(labels=tasks_df['task'], \n",
    "                             values=tasks_df['count'],\n",
    "                            pull=[0, 0, 0, 0.2,0,0,0])])\n",
    "fig.update_layout(\n",
    "    font_family=\"Arial\",\n",
    "    title_font_family=\"Arial\",\n",
    "    font_color='black',\n",
    ")\n",
    "fig.update_traces(marker=dict(colors=px.colors.qualitative.Set1,line=dict(color='#000000', width=1)),textfont_color='black')\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure(data=[go.Pie(labels=dataset_df['name'], \n",
    "                             values=dataset_df['count'],\n",
    "                            pull=[0, 0, 0, 0.2,0,0,0])])\n",
    "fig.update_layout(\n",
    "    font_family=\"Arial\",\n",
    "    title_font_family=\"Arial\",\n",
    "    font_color='black',\n",
    ")\n",
    "fig.update_traces(marker=dict(colors=px.colors.qualitative.Set1,line=dict(color='#000000', width=1)),textfont_color='black')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad0e573-e99a-41a8-b931-e86cad3dd919",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create Gini Data for RQ 1\n",
    "This last section of code creates data for the Gini analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4887636d-0e97-4f0e-9a1c-5ac455d19897",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name=[]\n",
    "paper_title=[]\n",
    "paper_date=[]\n",
    "paper_tasks=[]\n",
    "paper_CV=[]\n",
    "paper_NLP=[]\n",
    "paper_Methods=[]\n",
    "paper_parent=[]\n",
    "def in_category(x,cat):\n",
    "    if x in task_category_dict and cat in task_category_dict[x]:\n",
    "        return 1\n",
    "    if x in parent_child_dict and any([cat in task_category_dict[p] for p in child_parent_dict[x]]):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "for i, row in dataset_citing_papers_pwc.drop_duplicates(['name','title']).iterrows():\n",
    "    #again we're skipping this dataset because there is some wonky labeling in PWC\n",
    "    if row['name']=='PRID2011':continue\n",
    "    #restrict ourselves to valid tasks\n",
    "    valid_tasks= set(datasets[datasets.name==row['name']]['dataset_tasks'].iloc[0]+\\\n",
    "                     datasets[datasets.name==row['name']]['dataset_tasks_children'].iloc[0]+\\\n",
    "                     datasets[datasets.name==row['name']]['dataset_tasks_siblings'].iloc[0]\n",
    "                    )\n",
    "    for t in row['all_tasks']:\n",
    "        if t not in valid_tasks: continue \n",
    "        #if t not in focal_tasks:continue\n",
    "        dataset_name.append(row['name'])\n",
    "        paper_title.append(row['title'])\n",
    "        paper_date.append(row['date'].year)\n",
    "        paper_tasks.append(t)\n",
    "        paper_parent.append(False)\n",
    "    for t in row['all_parents']:\n",
    "        if t not in valid_tasks: continue\n",
    "        #if t not in focal_tasks:continue\n",
    "        dataset_name.append(row['name'])\n",
    "        paper_title.append(row['title'])\n",
    "        paper_date.append(row['date'].year)\n",
    "        paper_tasks.append(t)\n",
    "        paper_parent.append(True)\n",
    "entropy_dataset=pd.DataFrame({'task':paper_tasks,'name':dataset_name,'title':paper_title,'date':paper_date}).drop_duplicates()\n",
    "print(\"Number of tasks: \",entropy_dataset.task.drop_duplicates().shape[0])\n",
    "print(\"Number of datasets: \",entropy_dataset.name.drop_duplicates().shape[0])\n",
    "print(\"Number of papers: \",entropy_dataset.title.drop_duplicates().shape[0])\n",
    "entropy_dataset.to_csv('./EntropyDataset.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f19aa3-29df-417f-8343-b4ac1237f110",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tasks= set(datasets_pwc[datasets_pwc.name==row['name']]['dataset_tasks'].iloc[0]+\\\n",
    "                 datasets_pwc[datasets_pwc.name==row['name']]['dataset_tasks_children'].iloc[0]+\\\n",
    "                 datasets_pwc[datasets_pwc.name==row['name']]['dataset_tasks_siblings'].iloc[0]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92f63cc-de98-43f1-9047-a260f2cd27bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of usages recovered through manual annotation:\", entropy_dataset[entropy_dataset.name.isin(manual_task_labels.name)].shape[0])\n",
    "print(\"Number of usages still tossed:\",entropy_dataset[entropy_dataset.name.isin(manual_tasks_not_labeled.name)].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182c6cb1-603b-4ac1-8410-f167ab42339b",
   "metadata": {},
   "source": [
    "These are the metrics used in the analyses. Note we do not report the Pielou evenness, which is information-theoretic metric, but performs similary.\n",
    "\n",
    "I also experimented with the Simpson index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fda5e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from math import log\n",
    "#right now I am just saying having 1 or 0 datasets is meaningless\n",
    "def gini(x):\n",
    "    if len(x)<2:return None\n",
    "    x=np.array(x)\n",
    "    \"\"\"Compute Gini coefficient of array of values\"\"\"\n",
    "    diffsum = 0\n",
    "    for i, xi in enumerate(x[:-1], 1):\n",
    "        diffsum += np.sum(np.abs(xi - x[i:]))\n",
    "    return diffsum / (len(x)**2 * np.mean(x))\n",
    "\n",
    "def corrected_gini(x):\n",
    "    if len(x)<2:return None\n",
    "    x=np.array(x)\n",
    "    \"\"\"Compute Gini coefficient of array of values\"\"\"\n",
    "    diffsum = 0\n",
    "    for i, xi in enumerate(x[:-1], 1):\n",
    "        diffsum += np.sum(np.abs(xi - x[i:]))\n",
    "    gini = diffsum / (len(x)**2 * np.mean(x))\n",
    "    return len(x)*gini/(len(x)-1) \n",
    "\n",
    "\n",
    "def pielou(x):\n",
    "    if len(x)<2:return None\n",
    "    x=np.array(x)\n",
    "    return entropy(x,base=2)/log(len(x),2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ddf2ac-a9a8-4ba6-af2f-c0ff01e7f28b",
   "metadata": {},
   "source": [
    "Below is the entropy for all tasks, with no restrictions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fe2280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skbio.diversity import alpha\n",
    "task_ds_ycounts=entropy_dataset.groupby(['task','name',entropy_dataset.date]).size().reset_index()\n",
    "task_ds_ycounts.columns=['task', 'name','year','count']\n",
    "ginis=task_ds_ycounts.groupby(['task','year'])['count'].agg(corrected_gini).reset_index()\n",
    "ginis.columns=['task','year','gini']\n",
    "pielous=task_ds_ycounts.groupby(['task','year'])['count'].agg(pielou).reset_index()\n",
    "pielous.columns=['task','year','pielou']\n",
    "simpson=task_ds_ycounts.groupby(['task','year'])['count'].agg(alpha.simpson_e).reset_index()\n",
    "simpson.columns=['task','year','simpson']\n",
    "size=task_ds_ycounts.groupby(['task','year'])['count'].sum().reset_index()\n",
    "size.columns=['task','year','task_size']\n",
    "inequity_years_df=pd.merge(ginis,pielous,on=['task','year'])\n",
    "inequity_years_df=pd.merge(inequity_years_df,simpson,on=['task','year'],how='left')\n",
    "inequity_years_df=pd.merge(inequity_years_df,size,on=['task','year'],how='left')\n",
    "inequity_years_df=pd.merge(inequity_years_df,\n",
    "                           annual_data[['task','year','task_age','pwc_size','Images','Texts','CV','NLP','Methodology']],\n",
    "                           on=['task','year'], how='left')\n",
    "inequity_years_df['CV']=inequity_years_df['task'].apply(lambda x: in_category(x,'Computer Vision'))\n",
    "inequity_years_df['NLP']=inequity_years_df['task'].apply(lambda x: in_category(x,'Natural Language Processing'))\n",
    "inequity_years_df['Methodology']=inequity_years_df['task'].apply(lambda x: in_category(x,'Methodology'))\n",
    "inequity_years_df['Methodology']=inequity_years_df['Methodology'].apply(lambda x: 0 if x in Methodologies_to_Drop else x)\n",
    "inequity_years_df.to_csv(\"/mnt/c/Users/berna/Documents/./EntropyInputs/EntropyDatasetforR.txt\",sep='\\t',quoting=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea2ec4a-eebc-4f21-b7b7-cfb5991a109e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inequity_years_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310d86ef-2927-4f62-b7af-678637849430",
   "metadata": {},
   "source": [
    "This dataset is only for the tasks that are larger than the median size and are parent tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dc1d43-11cf-4aef-9e35-5e1dbe2a24ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=entropy_dataset[entropy_dataset.task.isin(median_parent_tasks)]\n",
    "print(\"Number of tasks (parent-tasks only): \",temp.task.drop_duplicates().shape[0])\n",
    "print(\"Number of datasets (parent-tasks only): \",temp.name.drop_duplicates().shape[0])\n",
    "print(\"Number of papers (parent-tasks only): \",temp.title.drop_duplicates().shape[0])\n",
    "\n",
    "task_ds_ycounts=entropy_dataset.groupby(['task','name',entropy_dataset.date]).size().reset_index()\n",
    "#this is the important line\n",
    "task_ds_ycounts= task_ds_ycounts[task_ds_ycounts.task.isin(median_parent_tasks)]\n",
    "#task_ds_ycounts= task_ds_ycounts[task_ds_ycounts.task.isin(parent_tasks)]\n",
    "\n",
    "task_ds_ycounts.columns=['task', 'name','year','count']\n",
    "ginis=task_ds_ycounts.groupby(['task','year'])['count'].agg(corrected_gini).reset_index()\n",
    "ginis.columns=['task','year','gini']\n",
    "pielous=task_ds_ycounts.groupby(['task','year'])['count'].agg(pielou).reset_index()\n",
    "pielous.columns=['task','year','pielou']\n",
    "simpson=task_ds_ycounts.groupby(['task','year'])['count'].agg(alpha.simpson_e).reset_index()\n",
    "simpson.columns=['task','year','simpson']\n",
    "size=task_ds_ycounts.groupby(['task','year'])['count'].sum().reset_index()\n",
    "size.columns=['task','year','task_size']\n",
    "inequity_years_df=pd.merge(ginis,pielous,on=['task','year'])\n",
    "inequity_years_df=pd.merge(inequity_years_df,simpson,on=['task','year'],how='left')\n",
    "inequity_years_df=pd.merge(inequity_years_df,size,on=['task','year'],how='left')\n",
    "task_age_df=task_age.reset_index()\n",
    "task_age_df.columns=['task','task_age']\n",
    "inequity_years_df=pd.merge(inequity_years_df,task_age_df,on='task',how='left')\n",
    "pwc_papers['year']=pd.to_datetime(pwc_papers['date']).dt.year\n",
    "annual_size=pwc_papers.groupby('year').size().reset_index()\n",
    "annual_size.columns=['year','pwc_size']\n",
    "inequity_years_df=pd.merge(inequity_years_df,annual_size,on='year',how='left')\n",
    "inequity_years_df['CV']=inequity_years_df['task'].apply(lambda x: in_category(x,'Computer Vision'))\n",
    "inequity_years_df['NLP']=inequity_years_df['task'].apply(lambda x: in_category(x,'Natural Language Processing'))\n",
    "inequity_years_df['Methodology']=inequity_years_df['task'].apply(lambda x: in_category(x,'Methodology'))\n",
    "inequity_years_df['Methodology']=inequity_years_df['Methodology'].apply(lambda x: 0 if x in Methodologies_to_Drop else x)\n",
    "inequity_years_df.to_csv(\"/mnt/c/Users/berna/Documents/GoogleDataProject/EntropyInputs/EntropyDatasetforRParentsOnly.txt\",sep='\\t',quoting=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def2632c-971b-4e4c-a0b0-42f8dadc57db",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=entropy_dataset[entropy_dataset.task.isin(median_parent_tasks)]\n",
    "\n",
    "temp[['name','title']].drop_duplicates()\n",
    "\n",
    "datasets_w_authors=pd.read_csv(\"/mnt/c/Users/berna/Documents/GitHub/Life_of_a_Benchmark/Dataset_Curation/numdatasets.txt\")\n",
    "temp=entropy_dataset[entropy_dataset.name.isin(datasets_w_authors.Dataset_Name)]\n",
    "print(\"Number of tasks (parent-tasks only): \",temp.task.drop_duplicates().shape[0])\n",
    "print(\"Number of datasets (parent-tasks only): \",temp.name.drop_duplicates().shape[0])\n",
    "print(\"Number of papers (parent-tasks only): \",temp.title.drop_duplicates().shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae18b89b-1130-4400-bb81-bd7cdbdfd7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[['name','title']].drop_duplicates()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84b9e97-5571-4069-a074-73c825bd7d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parent_tasks=[i for i in parent_child_dict if len(parent_child_dict[i])!=0]\n",
    "task_ds_counts=entropy_dataset.groupby(['task','name']).size().reset_index()\n",
    "task_ds_counts= task_ds_counts[task_ds_counts.task.isin(median_parent_tasks)]\n",
    "task_ds_counts.columns=['task', 'name','count']\n",
    "ginis=task_ds_counts.groupby(['task'])['count'].agg(corrected_gini).reset_index()\n",
    "ginis.columns=['task','gini']\n",
    "pielous=task_ds_counts.groupby(['task'])['count'].agg(pielou).reset_index()\n",
    "pielous.columns=['task','pielou']\n",
    "simpson=task_ds_counts.groupby(['task'])['count'].agg(alpha.simpson_e).reset_index()\n",
    "simpson.columns=['task','simpson']\n",
    "size=task_ds_counts.groupby(['task'])['count'].sum().reset_index()\n",
    "size.columns=['task','task_size']\n",
    "inequity_df=pd.merge(ginis,pielous,on=['task'])\n",
    "inequity_df=pd.merge(inequity_df,simpson,on=['task'],how='left')\n",
    "inequity_df=pd.merge(inequity_df,size,on=['task'],how='left')\n",
    "inequity_df['CV']=inequity_df['task'].apply(lambda x: in_category(x,'Computer Vision'))\n",
    "inequity_df['NLP']=inequity_df['task'].apply(lambda x: in_category(x,'Natural Language Processing'))\n",
    "inequity_df['Methodology']=inequity_df['task'].apply(lambda x: in_category(x,'Methodology'))\n",
    "inequity_df.to_csv(\"/mnt/c/Users/berna/Documents/GoogleDataProject/EntropyInputs/EntropyDatasetforRParentsOnly.AllYears.txt\",sep='\\t',quoting=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a0afb9-0cd3-4bf6-90e9-d56d09a6ed04",
   "metadata": {},
   "outputs": [],
   "source": [
    "inequity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb33f0aa-bdc0-4a81-aa43-e58598928f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_ds_ycounts[(task_ds_ycounts.year==2015) & (task_ds_ycounts.task=='3D Human Pose Estimation')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
